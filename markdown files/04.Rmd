
# Comparing many groups

Last chapter we talked about comparing two groups. Although the comparison of two groups is very simple, it also comes up very often: more complicated problems are often broken down into several two-group questions. However, real experiments don't usually *begin* as two-group questions. 

In the last chapter we found a reliable, but noisy, difference between women and girls in average f0. In this chapter, we're going to consider the productions of f0 from all four groups in our data. 

## Data and research questions 

We are going to work with the Hillenbrand et al. data, again focusing on variation in f0, however, this time we are going to work with all four groups of speakers: `b` (boys), `g` (girls), `m` (men), and `w` (women).

```{r, message = FALSE, warning = FALSE, collapse = TRUE}
library (brms)
options (contrasts = c("contr.sum","cont.sum"))

url1 = "https://raw.githubusercontent.com/santiagobarreda"
url2 = "/stats-class/master/data/h95_vowel_data.csv"
h95 = read.csv (url(paste0 (url1, url2)))[,c('f0','speaker','group')]
# set up colors for plotting
devtools::source_url (paste0 (url1, "/stats-class/master/data/colors.R"))
# source functions
devtools::source_url (paste0 (url1, "/stats-class/master/data/functions.R"))

# make variable that indicates if the talker is an adult
h95$adult = ""
h95$adult[h95$group %in% c('w','m')] = "adult"
h95$adult[h95$group %in% c('g','b')] = "child"
# make variable indicating speaker gender
h95$gender = "female"
h95$gender[h95$group %in% c('b','m')] = "male"
# make speaker number a factor
h95$speaker = factor (h95$speaker)  

# see data
head (h95)
```

Our potential research questions are substantially more complicated than in the two-group case. First, there are four groups now, meaning we could potentially make 6 2-group comparisons. Second, the groups differ along multiple dimensions, making it more difficult to make two-group comparisons that ask one single question. For example, the man and girl groups differ according to adultness *and* gender. How could we know what part of their f0 difference we should attribute to adultness and what part we should attribute to maleness?

```{r F4-datacomparison, echo=FALSE,fig.height = 3.5, fig.width = 8, fig.cap = "(left) Comparison of the four groups (middle) Comparison of productions based on whether the speaker is an adult (right) Comparison of all productions based on whether the speaker is male."}

################################################################################
### Figure 4.1
################################################################################

par (mfrow = c(1,3))
boxplot (f0 ~ group, data=h95, main = "Overall", ylim = c(90,330),col=cols[3:6])
boxplot (f0 ~ adult, data=h95, main="Adultness", ylim =c(90,330), col=cols[7:8])
boxplot (f0 ~ gender, data=h95, main="Gender", ylim = c(90,330), col=cols[1:2])
```

We can consider our data in several ways: as four independent groups, or as two 2-groups comparisons (adult vs child, female vs male). We are going to focus on the 4-way comparison first, and later talk about models that make multiple comparisons simultaneously. 

```{r F4-speakerboxplots, fig.height = 3.5, fig.width = 8, echo = FALSE, fig.cap = "(left) Boxplots presenting each speaker's production of f0 for boys (red), girls (yellow), men (green), and women (teal). (right) Densities of the overall distributions for each group."}

################################################################################
### Figure 4.2
################################################################################

colors = cols[c(3,5,4,6)][ apply (table(h95$speaker, h95$group),1,which.max) ]
# speaker boxplots
par (mar = c(4,4,1,1)); layout (mat = t(c(1,2)), widths = c(.7,.3))
boxplot (f0 ~ speaker, data=h95, col = colors, ylim = c(80,330))
# The density figures are rotated 
tmp = density (h95$f0[h95$group=="b"])
plot (tmp$y, tmp$x, lwd = 3, col = cols[3], ylab = "f0",xlab="Density", 
      ylim = c(80,330), xlim = c(0,0.025), type = 'l')
tmp = density (h95$f0[h95$group=="g"]); lines (tmp$y, tmp$x, lwd=3, col=cols[5])
tmp = density (h95$f0[h95$group=="m"]); lines (tmp$y, tmp$x, lwd=3, col=cols[4])
tmp = density (h95$f0[h95$group=="w"]); lines (tmp$y, tmp$x, lwd=3, col=cols[6])
```

R treats verbal predictors as 'factors' and assumes that each different label is a different group. Each group of a factor is called a 'level'. Actually, we've been using factors all along because our `speaker` predictor is a factor and the individual participants are levels! As far as our models are concerned, participant/speaker/subject has no special status as a predictor and it is just a factor with many levels. 

A `factor` is actually a data type in R. It's basically the same as a vector of words (or numbers!), but it has some additional properties that are useful. For example, consider our `group` predictor, which tells us which group each speaker falls into. Initially it is a character vector. We see that the first few tokens are produced by men (`m`), and that there is no numerical value associated with these letter labels. The `unique` function returns all unique labels in the vector, in the order that they appear. 

```{r, collapse = TRUE}
# see the first 6 observations
head (h95$group)   

# class starts as a character vector
class (h95$group)   

head (as.numeric (h95$group))  # no numerical values

unique (h95$group)  # we can see the number of unique groups
```

We can turn the character vector `group` into a factor vector `group_f`. The benefit of this is that these nominal labels now have an inherent ordering, and associated numerical values. R functions such as `brm` turn your nominal (non-numeric) predictors into factors in the process of fitting the model. Doing this yourself gives you control over how they will be handled. 

```{r, collapse = TRUE}
# we can turn it into a factor in R
h95$group_f = factor(h95$group) 

# now it has official levels
levels(h95$group_f)  

# now it has nuerical values
head (as.numeric (h95$group_f))  
```

By default factor levels are ordered alphabetically. This means that if we are using sum coding we will not estimate the `w` parameter (the 'last group') and if we are using treatment coding, the intercept will be equal to `m` (the 'first' group). You can control this behavior by re-ordering the factor levels as below:

```{r, collapse = TRUE}
h95$group_f2 = factor (h95$group_f, levels = c('w','m','g','b'))

levels (h95$group_f2)

# note that 'm' is now the second category
head (as.numeric (h95$group_f2))  
```

After this reordering, we would omit the (last) `b` parameter under sum coding, and the first group (`w`) would be equal to the intercept. 

In general, representing all groups requires about one variable per group. Our single predictor, `group`, has four levels: `b`,`g`,`m`, and `w`. For models where the predictor is a factor with more than two levels, we can represent the predictor in a vector like this, $group_{[i]}$, where $i$ is a counter variable that goes from 1 to the number of groups. 
So the group effects can be represented in a vector as below, representing the effects (deviations from the intercept) for boys, girls, men and women:

```{r, collapse = TRUE}
c(30, 32, -75, 13)
```

We can then make a short factor vector with the same labels used in this experiment. Below we can see the sequence of letter labels I specified, and their corresponding numeric values (based on alphabetical ordering).

```{r, collapse = TRUE}
group_index = factor (c('b','w','m','w','g'))

data.frame (group_index, group_index_number = as.numeric (group_index))
```

We can then take this vector of factor levels and use it to generate a sequence of effects: 

```{r, collapse = TRUE}
as.numeric (group_index)

c(30, 32, -75, 13)[group_index]
```

Notice that the sequence of effects match the sequence of group levels, based on their numerical value. 

If every single group were to get an independent parameter represented in our regression equation, these would become very long and difficult to interpret. Instead, by treating the effects for the level of a factor as a vector, our models can represent a very large number of parameters in a concise way. For example, compare the following two possible implementations of our 4 group model (where $j$ is an index for our group effects):  

\begin{equation}
\begin{split}
\mu_{[i]} = Intercept + group_{1} + group_{2} + group_{3} + group_{4} \\
\mu_{[i]} = Intercept + group_{j} \\
\end{split}
(\#eq:40)
\end{equation}

It may not be too much of a difference now, but later we have have many factors, some with dozens or hundreds of levels. In those cases, representing factor effects using vectors becomes essential. 

## Comparing four (or any number of) groups

We're first going to treat the four groups as if they had no internal structure. It may not be the best approach for this data, but in many cases you will have several groups with no logical internal divisions.   

### The model

Our updated model is now as seen below. 

\begin{equation}
\begin{split}
\textrm{Likelihood:} \\
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = Intercept + group_{[\mathrm{group}_{[i]}]} + \alpha_{speaker_{[i]}} \\\\
\textrm{Priors:} \\
\alpha_{speaker} \sim \mathcal{N}(0,\sigma_{speaker}) \\ \\ 
Intercept \sim t(3, 220, 100) \\ 
group_{[\mathrm{group}]} \sim t(3, 0, 100) \\ 
\sigma_{error} \sim t(3, 0, 100) \\
\sigma_{speaker} \sim t(3, 0, 100) \\ 
\end{split}
(\#eq:41)
\end{equation}

Notice that for each trial number $i$ the group predictor is indexed by a variable called `group`. This is a bit confusing, but I am just trying to be consistent with how R does things. 

As noted above, a factor predictor like `group` is really just a bunch of numbers that represent group effects in a vector. So R really treats `group` as a sequence of numbers representing group numbers. But it also calls the predictor in the model by that name! So, though it may look strange $group_{[\mathrm{group}_{[i]}]}$ just says that you have a predictor in your model called $group$ and it has a few possible values (four in this case). Also, you have a variable in your data with the same name (`group`) that tells you which value of $group$ to use for each observation! 

This may sound convoluted, but it is simply what I demonstrated in the end of the last subsection regarding the behavior of vectors and factors. Our model will estimate 4 $group$ effects. It estimates these from a the prior distribution specified in the model above ($group \sim t(3, 0, 100)$). Our *data* includes a predictor called `group` that simply tells us which value of our group effect to use in each trial (`group[i]` = $\mathrm{group}_{[i]}$). 

For example, above we saw that the first value of the `group` vector is 3. This means this speaker is a member of the `m` group. So, in our model above the equation determining $\mu_{[i]}$ will include the value $group_{[3]}$ in it because $group_{[\mathrm{group}_{[i]}=3]}$.

We can check out the mean and standard deviations for the data to set prior probabilities for the model parameters. 

```{r, collapse = TRUE}
mean (h95$f0)

sd (h95$f0)
```

We're going to use sum coding, which means that the intercept will be the mean of all the groups, and group effects will be represented as differences from this mean. Remember that the missing group effect will be equal to the negative sum of the coefficients that are present. By default, R drops the **last** level from your factor, which in our case will be the `w` level. We can set R to use sum coding with the line below:

```{r}
options (contrasts = c("contr.sum","cont.sum"))
```

And fit the model below: 

```{r, eval = FALSE}
options (contrasts = c("contr.sum","cont.sum"))
# Fit the model yourself, or download pre-fit model from: 
# github.com/santiagobarreda/stats-class/tree/master/models
# and load after placing in working directory
#  model_four_groups = readRDS ('4_model_four_groups.RDS')set.seed (1)

model_four_groups =  
  brm (f0 ~ group + (1|speaker), data = h95, chains = 4, cores = 4, 
       warmup = 1000, iter = 11000, thin = 10, 
       prior = c(set_prior("student_t(3, 200, 100)", class = "Intercept"),
                              set_prior("student_t(3, 0, 100)", class = "b"),
                              set_prior("student_t(3, 0, 100)", class = "sd")))

#  saveRDS (model_four_groups, 'model_four_groups.RDS')
```
```{r, include = FALSE}
model_four_groups = readRDS ('../../models/4_model_four_groups.RDS')
```
```{r, collapse = TRUE}
# inspect model
model_four_groups
```    
    
We can see that the intercept is the average of the group means, and our coefficients are equal to the centered group means:

```{r, collapse = TRUE}
# group means
means = tapply (h95$f0, h95$group, mean)

# overall mean
mean (means)

# group means
means

# centered means
means - mean (means)

# parameters = centered means
hypothesis (model_four_groups, c("group1 = 0",
                                "group2 = 0",
                                "group3 = 0", 
                                "-(group1+group2+group3) = 0"))[[1]][,1:5]
```

In these Bayesian models, we can compare any groups we want by using comparisons of the posterior samples (as shown in chapter 3). For example, the difference between girls and boys can be found by asking if one minus the other equals 0 (which would be true if these were identical): 

```{r, collapse = TRUE}     
hypothesis (model_four_groups, "group1 - group2 = 0")[[1]][,1:5]
```

The result above suggests that the difference is very small (-2 Hz) and the 95% credible intervals spans a huge range (from -15 to +10)). As a result, the measured difference between these groups is not reliable, and may be very small or close to zero. Notice that in this summary I am focused on minimizing [type S and type M errors](https://statmodeling.stat.columbia.edu/2004/12/29/type_1_type_2_t/). This means I am worried about whether the effect is likely to be small or large, and negative or positive, rather than whether it is 'true' or 'false'. 

## Investigating many groups using predictors: Analysis of Variance

### Description of the model

In the previous section, we acted like we just had four different groups with no internal structure. Of course, we know that our groups differ systematically from each other in meaningful ways. For example, we might have chosen to fit two separate models that looked like this:

`brm (f0 ~ gender + (1|speaker)` 

`brm (f0 ~ adult + (1|speaker)` 

For several reasons (some of which we'll see very soon), it's preferable to fit a single model with both predictors at once, rather than fitting two separate models for each one. Our R model formula will now look like this, reflecting the influence of both predictors simultaneously:

`f0 ~ adult + gender + (1|speaker)`

This can be read like "f0 is distributed according to effects for speaker adultness and gender, with random intercepts for each speaker". You may have noticed that our model no longer includes the `group` predictor. This is because the `group` label is perfectly predictable on the basis of `adult` and `gender` (a `g` must have values of `female` and `child`, and so on). Basically, we have decomposed the groups into two components to help us understand the effect of each. This is simply and extension of what we have been doing from the start. For example our model was previously: 

$\mu_{[i]} = Intercept + (group_{\mathrm{group}_{[i]}}) + \alpha_{\mathrm{speaker}_{[i]}}$

However, since group can be exactly represented by combinations of gender and adult, our model sort of always contained this more-complicated model inside of it:

$\mu_{[i]} = Intercept + (adult_{\mathrm{adult}_{[i]}} + gender_{\mathrm{gender}_{[i]}}) + \alpha_{\mathrm{speaker}_{[i]}}$

This is what can be referred to as an 'ANOVA-like' decomposition. ANOVA, the *AN*alysis *O*f *VA*riance, is a technique, or a general approach, to understanding data by focusing on the sources of variance contained in it. We have actually been chipping away at the error variance little by little by making more complicated models.

Recall that our very first approach to understanding f0 looked like this:

$$
\sigma_{total} = \sigma_{error}
$$

In other words, all variation was error. After this we added between-speaker variation to the model, and removed that from the error.

$$
\sigma_{total} = \sigma_{speaker} + \sigma_{error}
$$

Now, our model can individually estimate the variation in observed f0 due adultness, gender, to between-speaker variation and to production error.
 
$$
\sigma_{total} = \sigma_{adult} + \sigma_{gender}+\sigma_{speaker} + \sigma_{error}
$$

Our complete model is now:

\begin{equation}
\begin{split}
\textrm{Likelihood:} \\
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = Intercept + adult_{\mathrm{adult}_{[i]}}+gender_{\mathrm{gender}_{[i]}} + \alpha_{\mathrm{speaker}_{[i]}} \\\\
\textrm{Priors:} \\
\alpha_{speaker} \sim \mathcal{N}(0,\sigma_{speaker}) \\ \\ 
Intercept \sim t(3, 200, 100) \\ 
adult_{\mathrm{adult}} \sim t(3, 0, 100) \\ 
gender_{\mathrm{gender}} \sim t(3, 0, 100) \\ 
\sigma_{error} \sim t(3, 0, 100) \\
\sigma_{speaker} \sim t(3, 0, 100) \\ 
\end{split}
(\#eq:42)
\end{equation}

### Fitting the model and interpreting the results

Below I fit the model using the data statistics outlined above.

```{r, eval = FALSE}
# Fit the model yourself, or download pre-fit model from: 
# github.com/santiagobarreda/stats-class/tree/master/models
# and load after placing in working directory
#  model_both = readRDS ('4_model_both.RDS')

set.seed (1)
model_both =  
  brm (f0 ~ adult + gender + (1|speaker), data = h95, chains = 4, cores = 4, 
       warmup = 1000, iter = 11000, thin = 10, 
       prior = c(set_prior("student_t(3, 200, 100)", class = "Intercept"),
                              set_prior("student_t(3, 0, 100)", class = "b"),
                              set_prior("student_t(3, 0, 100)", class = "sd"))) 
#  saveRDS (model_both, '4_model_both.RDS')
```
```{r, include = FALSE}
model_both = readRDS ('../../models/4_model_both.RDS')
```
```{r, collapse = TRUE}
# inspect model
model_both
```

We can see that the model output is largely familiar, except now we have two non-Intercept 'Population-Level' effects: `adult1` and `gender1`, representing the categories 'adult' and 'female' respectively. Remember that since we used sum coding, the effects for the groups that are not represented ('child', 'male') are just the opposite of the groups that are represented. 

Below we can see that the Intercept is reasonably close to the mean of the group means, and that the adult effect is about half the difference between the mean of the adult and child groups. However, the model seems to overestimate the average differences between male and female groups (30 Hz in model, 23 Hz in the data). 

```{r, collapse = TRUE}
# grop means
means = tapply (h95$f0, h95$group, mean)

# overall mean in data
mean (means)

# group means
means

# average adultness difference in data
((means['b']+means['g'])/2 - (means['m']+means['w'])/2) / 2

# average gender difference in data
((means['g']+means['w'])/2 - (means['m']+means['b'])/2) / 2
```

We can recover the group means by adding up the individual coefficients. This can be tedious and requires you to be careful and methodical, but isn't actually difficult. Remember that each of the four groups is uniquely identified by a combination of gender and adultness. To recover the group means we need to add the right combination of coefficients to the intercept. 

For example, the second hypothesis we are testing below says `Intercept + -adult1 + -gender1 = 0`. This could be read like "take the overall mean, add the effect for 'child/adult2' (`-adult1=adult2`), and add the effect for 'male/gender2' (`-gender1=gender2`). If you start at the overall mean f0 and add the effects for a male and a child, you are estimating the mean f0 for a boy. 

```{r, collapse = TRUE}
tapply (h95$f0, h95$group, mean)

# intercept, boys, girls, men, women
# adult1 = "adult", and gender1="child" because its alphabetical.
# +adult1 = -adult2 since it will be the opposite value
means_pred = hypothesis (model_both, c("Intercept = 0",
                                "Intercept + -adult1 + -gender1 = 0",
                                "Intercept + -adult1 +  gender1 = 0",
                                "Intercept +  adult1 + -gender1 = 0",
                                "Intercept +  adult1 +  gender1 = 0"))[[1]][,1:5]
means_pred
```

The predictions above are actually not a good match for our group means, suggesting that maybe our model is not capturing something important about our data. 

### Investigating model fit 

So far we have been working with very simple models and not worrying much about how well they 'fit', meaning how well they represent our data. Our reconstruction of the group means above suggests our current model may have some issues. 

We can investigate model fit with a 'posterior predictive check'. The 'posterior predictions' made by your model are the values predicted by your model for each data point, for each set of posterior samples. Effectively, these are the $\mu_{[i]}$ predicted by your model for each trial. For example, if our current model looks like this:

$\mu_{[i]} = Intercept + adult_{[\mathrm{adult}_{[i]}]} + gender_{[\mathrm{gender}_{[i]}]} + \alpha_{[\mathrm{speaker}_{[i]}]}$

Then the predicted value ($\mu$) for each trial is the sum of the Intercept and appropriate coefficients for the trial. The `brms` package has a `predict` function which can help you make these predictions easily. 

```{r, cache = TRUE, collapse = TRUE}
y_pred = predict (model_both)

head (y_pred)
```

The output of prediction, `y_pred`, has four columns. These contain a predicted value, but also information about variation in predictions. That is because, our model produces a different prediction for each set of samples. This means that if we have 4000 samples we actually have 4000 slightly different models and 4000 slightly different predictions! So, in addition to information about the most probable estimates, we get information about expected variation around these estimates.

Below, I make predictions without random effects (`re_formula = NA`). 

```{r, cache = TRUE}
y_pred_no_re = predict (model_both, re_formula = NA)
```

This corresponds to a model like below, *without* speaker adjustments:  

$\mu_{[i]} = Intercept + adult_{adult_{[i]}} + gender_{gender_{[i]}}$

The posterior predictions made by this model will help us understand how well our model represents average f0 based only on group averages, without the speaker-dependent adjustments.

Below we can see that the model with speaker adjustments does a very good job of predicting f0, with most credible intervals for most predictions overlapping with the diagonal (diagonal = perfect prediction). On the other hand, the predictions without speaker adjustments show systematic biases: predictions for many high-f0 speakers lie left of the diagonal, meaning our predictions are higher than they should be. 

```{r F4-postpred1, echo = FALSE, fig.height=3.5,fig.width=8,fig.cap="(left) Posterior predicted f0 for the model with speaker random effects. (right) Posterior predicted f0 for the model without speaker random effects"}

################################################################################
### Figure 4.3
################################################################################

par (mfrow = c(1,2), mar = c(4,4,3,1))
brmplot (xs = h95$f0, y_pred, xlim = range(h95$f0), 
         main = "With Random Intercepts",labels="");  axis(side=1);
mtext(side=1,text="f0",line=2.5);mtext(side=2,text="f0_pred",line=2.5)
abline (0,1, col = 2, lwd=2)
brmplot (xs = h95$f0, y_pred_no_re, xlim = range(h95$f0),
         main = "Without Random Intercepts" , labels = ""); axis (side=1);
mtext(side=1,text="f0",line=2.5);mtext(side=2,text="f0_pred",line=2.5)
abline (0,1, col = 2, lwd=2)
```

The above plots are good for basic analysis, but it's hard to get a good idea of the source of our problems using these plots. We can get a much better idea of how our model is performing by using an 'interaction plot'. 

## Interactions and interaction plots

[Interactions](http://glimo.vub.ac.be/downloads/interaction.htm) and understanding their graphical representations is so important that it gets its own subsection. In many if not most models with multiple predictors, researchers will need to at least consider the effects of interactions in their models. 

We can think of a single effect representing a difference between groups as a slope. For example, in the left panel below I plotted the means for males and females at x-axis locations 0 and 1. The difference in the group means is -55 Hz (females 225 Hz, males 170 Hz). As a result, the line formed by joining these groups has a slope of -55 (i.e., it drops 55 Hz from 0 to 1). We can use any arbitrary x axis distance to calculate slopes, as long as we are consistent. However, there are obvious practical advantages to choosing to calculate these slopes over the arbitrary 'distance' of 1. In the middle panel we see the effect for adultness, which shows a positive slope for the difference from adult to child: the f0 increases by about 60 Hz. 

The plots highlighting the effects for adultness and gender are 'main effects' plots. You may have heard things like "the analysis showed a significant main effect for so and so...". Main effects are the average effects for one predictor averaged across everything else. Saying 'averaged across everything else' basically means we are ignoring everything else. A person looking only at the left plot would not realize our data also investigates the effect of adultness. 

Another way to think of main effects are that they are 'marginal' effects. They are the overall average difference. Someone might ask you, "whats the average difference between males and females in your sample?" and you can respond "55 Hz". However, sometimes the answer is not so simple, and it starts more like: "well... it depends". Interactions represent situations like these, where the effect of one variable depends on, or is *conditional* on, the value of some other variable. 

```{r F4-interactionplot, fig.height=3.5,fig.width=8,fig.cap="Plots showing different ways to consider our f0 data.", echo = FALSE}

################################################################################
### Figure 4.4
################################################################################

par (mfrow = c(1,3), mar = c(4,4,3,2))
plot (0:1,tapply (h95$f0,h95$gender,mean), col=3, ylim = c(125,250),xaxt='n',
      lwd=3,type='b',pch=16,cex=1.5,main="Gender",xlim=c(-.2,1.2),ylab='f0',xlab='')
axis (at=0:1, labels = c('female','male'), side=1)

plot (0:1,tapply (h95$f0,h95$adult,mean),col=3, ylim=c(125,250),xaxt='n',lwd=3,
      type='b',pch=16,cex=1.5, main = "Adult",xlim=c(-.2,1.2),ylab='f0',xlab='')
axis (at=0:1, labels = c('adult','child'),side=1)

plot.interaction (h95$gender, h95$adult, h95$f0,col=3:4, lwd = 3, leg.y = 220, 
                  leg.x=1.8,type='b',pch=c(16,17),cex=1.5, ylim = c(125,250),
                  main="Both",ylab='f0', xlim = c(.9,2.5))
```

In the right panel above we see a two-way interaction plot. Interaction plots show you what are called the [simple effects](http://glimo.vub.ac.be/downloads/simpleeffect.htm) of your predictors (sometimes also called the *simple main effects*). The simple effects are the 'conditional probabilities': the effects of your factor, conditional on the level of another factor. For example, the left plot shows the overall (marginal) effect for gender. The right plot also shows the effect for gender. However, it uses a blue line to show the effect for adults (gender given adultness) and a green line to show this effect for children (gender given childness). As a result, we can consider the effects of gender *conditioned* on adultness, and see how these might differ. 

So, main effects show you the effect for a factor, and simple effects show you the effects of the factor *depending* on the value of other things. 

If adultness in no way affected f0, the right panel should look identical to the left panel. If adultness affected f0 in the same way across genders, we would see parallel lines in the right plot. This is because if you are adding a single value to each gender based on adultness, the line indicating the gender effect for adult would just slide up and down the f0 axis but would not change in slope. A change in slope requires that *different* effects exist for adultness for each gender (relative to the effect seen in children). So, an effect for gender that is independent of adultness can only result in parallelism in an interaction plot. 

What we see in the right panel above is that the lines are **not** parallel at all. When we see lines that are not parallel, that means there may be an interaction in our data. In the absence of an interaction, we could just answer the question "whats the average difference between males and females in your sample?" with a number like 55 Hz. In the presence of an interaction we need to consider the *conditional effects* of each predictor, at the levels of the other predictor. 

I think the above may sound complicated, but it's just what we would all do to try to make sense of the plot on the right. There is a large negative slope for gender for adults. This tells us that gender has a large effect on f0 for adults. However, the slope for gender is basically zero for children. So, we might say "there is a large f0 difference for adult males and females in our sample, but basically no gender based difference for children". Alternatively, we might look at the changing effect for gender across adultness levels. If we did this, we might say "there is a small effect for adultness in the average f0 produced by females, but a very large effect for adultness for males".   

In summary, if the answer to "what is the effect of X on Y" is "well, it depends on the values of Z", you have an interaction in your data. When you have substantial interactions present in your data and you do not include these in your model, this can cause a problem for your model fit.

### Interactions in our f0 data

We can take the different posterior predictions we made above and make interaction plots out of them. We can see that when random effects are included, prediction is quite good. This is not surprising since the speaker-specific intercept adjustments allow for each speaker's mean f0 to be modeled effectively. However, we see that the predictions made by our model are substantially and systematically wrong in the absence of the speaker random intercepts. 

It's clear that the problem with our predictions in the right panel is that the lines are parallel. As we've just discussed, in the absence of interactions, interaction plots contain only parallel lines. Well, since our model (`model_both`) does not include interaction terms it cannot represent interactions, and so is only capable of producing predictions that result in parallel lines. This means it is not capable of representing the pattern in our data!

```{r interactionplot3, fig.height=3.5,fig.width=8,fig.cap="Interaction plots showing comparing our f0 data to different posterior predictions, with and without RE (random effects)."}
par (mfrow = c(1,3), mar = c(4,4,3,2))

plot.interaction (h95$gender, h95$adult, h95$f0, col=3:4, ylim=c(130,280),lwd=3,
                  type='b',pch=c(16,17),cex=1.5,main="Data",legend = FALSE)

plot.interaction (h95$gender, h95$adult, y_pred[,1], col = 3:4,lwd=3, type='b',
                  pch = c(16,17), cex = 1.5, ylim = c(130,280),
                  main="Pred. with RE",legend=FALSE)

plot.interaction (h95$gender, h95$adult, y_pred_no_re[,1],col=3:4, lwd=3,
                  type = 'b', pch = c(16,17), cex = 1.5, ylim = c(130,280),
                  main="Pred. with RE", leg.x=1.8,leg.y=270, xlim=c(.95,2.3))
```

In order to properly model the group differences, and the real effects of gender and adultness on average f0, we need to build a model that can represent the interactions in our data. 

## Investigating interactions with a model

The model presented above (`model_both`) requires only a slight tweak to include a term representing the interaction in our data. There are two ways to include interactions in R model formulas, as shown below:

`f0 ~ adult + gender + adult:gender + (1|speaker)` 
&nbsp;

`f0 ~ adult * gender + (1|speaker)`

The first way includes an explicit interaction term, `adult:gender`. The syntax for these is `X:Z` for an interaction between effects `X` and `Z`, `W:X:Z` for a three-way interaction, and so on. The second way uses `*` between our two predictors. This tells R to include those predictors, and the interactions between them This can be much faster then specifying all interactions, but you lose control over which ones you include. For example the first formula implies the second, but cannot represent the third (since it omits one interaction):

`y ~ Z * X * W` 
 &nbsp;

`y ~ Z + X + W + Z:X + Z:W + X:W + Z:X:W` 
&nbsp;
 
`y ~ Z + X + W + Z:X + X:W + Z:X:W`  

Our full model specification now includes an *interaction* term that can help explain variation that cannot be explained by the independent effects of adultness and gender. This interaction term helps us model the *conditional* effect of one predictor given the other. 


\begin{equation}
\begin{split}
\textrm{Likelihood:} \\
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = Intercept + adult_{\textrm{adult}_{[i]}} + gender_{\textrm{gender}_{[i]}}+ adult:gender + \alpha_{speaker_{[i]}} \\\\
\textrm{Priors:} \\
\alpha_{speaker} \sim \mathcal{N}(0,\sigma_{speaker}) \\ \\ 
Intercept \sim t(3, 200, 100) \\ 
adult_{[i]} \sim t(3, 0, 100) \\ 
gender_{[i]} \sim t(3, 0, 100) \\ 
adult:gender \sim t(3, 0, 100) \\ 
\sigma_{error} \sim t(3, 0, 100) \\
\sigma_{speaker} \sim t(3, 0, 100) \\ 
\end{split}
(\#eq:43)
\end{equation}


### Fitting the model and interpreting the results

Below I fit the model which now includes an interaction term representing the changing effect of gender and adultness on average f0. 

```{r, eval = FALSE}
# Fit the model yourself, or download pre-fit model from: 
# github.com/santiagobarreda/stats-class/tree/master/models
# and load after placing in working directory
#  model_interaction = readRDS ('4_model_interaction.RDS')

set.seed (1)
model_interaction =  
  brm (f0 ~ adult + gender + adult:gender + (1|speaker), data = h95, 
       chains = 4, cores = 4, warmup = 1000, iter = 11000, thin = 10, 
       prior = c(set_prior("student_t(3, 200, 100)", class = "Intercept"),
                              set_prior("student_t(3, 0, 100)", class = "b"),
                              set_prior("student_t(3, 0, 100)", class = "sd"))) 

#  saveRDS (model_interaction, '4_model_interaction.RDS')
```
```{r, include = FALSE}
model_interaction = readRDS ('../../models/4_model_interaction.RDS')
```
```{r}
# inspect model
model_interaction
```
Remember that this line `set_prior("student_t(3, 0, 100)", class = "b")` sets the prior for all non-intercept 'Population-Level' predictors. This allows you to efficiently set priors for the adult, gender, and adult:gender predictors in your model in a single line, and becomes more and more useful as our models grow more complex. 

A look at the model output above indicates that we have a large interaction term. In fact, our interaction is as large as the 'main' effect for gender! In cases with large interactions we have to be very careful about interpreting the main effects. In other words, when the answer to a question is "it really depends", you should be wary of making blanket statements. 

We need to talk about why there is only a single interaction term. The reason for this is related to the same reason we can't get estimates for all our group effects (i.e., linear dependence). The number of terms you can estimate is generally one fewer than the number of levels. For interaction terms, the number of parameters is equal to (number of levels of factor (A - 1)x(number of levels of factor B - 1). Since each of our factors have two levels, we can only estimate one parameter, (2-1)x(2-1). 

Our interaction basically says that sometimes being a male *and* being an adult results in a lower f0 than can be predicted independently by maleness and adultness. So, you only need one coefficient to represent the extra combined effects of maleness *and* adultness. This same coefficient can also represent the opposite case: not male and not adult. You don't need an interaction term to model the effect of maleness *or* adultness since that is effectively what the main effects do (i.e., model the effect regardless of the difference of the other value).  

The interaction term is just another element of your prediction equation (i.e., $\mu + x_1+x_2...$) intended to help explain variation that can't be predicted by the independent effects of the other predictors in the model. Recovering the predicted group means based on the coefficient values is straightforward, but a bit tedious: we must now either add or subtract the value of the interaction term (`adult1:gender1`) from each group. We can easily determine which to do for this model because the sign on the interaction term is the product of the signs on the relevant 'main effects' terms.   

For example, the second hypothesis we are testing below says `Intercept + -adult1 + -gender1 + adult1:gender1 = 0`. This could be read like "take the overall mean, add the effect for 'child' (or `adult2`, since `-adult1=adult2`), and add the effect for 'male' (or `gender2` since `-gender1=gender2`), and add the effect for when the speaker is male *and* a child (`-adult1*-gender1 = +adult1:gender1`)". If you look at the hypotheses below, you will see that the sign on the interaction terms solely depends on the signs of the corresponding main effects terms. We can see that the inclusion of an interaction term allows our model to capture group averages more accurately than the model without intercepts.

```{r, collapse = TRUE}
# actual data means
tapply (h95$f0, h95$group, mean)
# intercept, boys, girls, men, women
means_pred_interaction = hypothesis (model_interaction, c("Intercept = 0",
                "Intercept + -adult1 + -gender1 +  adult1:gender1 = 0",
                "Intercept + -adult1 +  gender1 + -adult1:gender1 = 0",
                "Intercept +  adult1 + -gender1 + -adult1:gender1 = 0",
                "Intercept +  adult1 +  gender1 +  adult1:gender1 = 0"))[[1]][,1:5]
# predictions with no interaction term
means_pred

# predictions with interaction term
means_pred_interaction
```

Below I print the estimates of the 'fixed' effects in the model so we can focus on those. If you fit a model like this and are having trouble interpreting it, I would really encourage you to write down an interpretation using pen and paper, focusing on the decomposition of values provided by the regression model.


```{r, collapse = TRUE}
fixef (model_interaction)
```

For example, the average f0 is 206. The gender difference is 44 Hz (22 * 2) between groups, and there is a gender-based 23 Hz deviation from the mean between groups. This means that, overall, the male and female averages are about 183 and 229 Hz (206 Â± 22). 

However, the `adult1:gender1` interaction is 22 Hz. This means that when the speaker was an adult (`adult1`), the gender difference was nearly doubled. We know this because the effect for `gender1` is 22.8, and the effect for `gender1` **given** `adult1` (`adult1:gender1`, which is the same thing as `gender1:adult1`) is 21.7 Hz higher than that. So, the total effect for f0 across adults is about  22.8 + 21.7 = 44.5, suggesting a difference in f0 between the groups of 89 Hz (44.5 * 2). 

I am going to basically restate what I just said because it is very important. The effect for `gender` is 22.8, and the effect for `gender1:adult1` is further 21.7 Hz. As a result, the cumulative effect for gender1 (female) given adult1 (adult) is `gender1 + gender1:adult1 = 44.5`. 

In contrast, the fact that `adult1:gender1 = 21.7` indicates that `adult2:gender1 = -21.7`. This is because since `adult1:gender1` represents the effect of `gender1` *given* `adult1`, the effect given `adult2` must be opposite in sign (because of sum coding). So, we can say that although the effect for gender is 22.9 overall, given that the speaker is a child (`adult2`), this effect is 21.7 Hz lower than the 'main effect' estimate. So, for children we expect an f0 effect of 22.9 - 21.7 = 1.2, suggesting a group difference of 2.2 Hz. In other words, the effect of gender is basically zero given that the speakers are children. 

We can consider the effects the other way. The marginal effect for `adult1` is -30, meaning that when speakers are adults, their f0 is 30 Hz lower than the overall average. However, `adult1:gender1 = 21.7`, meaning that *if* the speaker is female (`gender1`), then the expected effect of adultness is reduced (-30 + 21.7 = -8.3) so that the expected group difference is only 17 Hz. On the other hand, when the speaker is a male (`gender2`) then the interaction term should be flipped in sign (`adult1:gender2 =  -21.7`). This means that the effect of adultness, conditional on the speaker being male is nearly doubled (-30 + -21.7 = -51.7). 

When considered in this way all these coefficients are just telling us what we already knew from looking at the interaction plot: f0 varies substantially based on gender for adults but not for children. Or: f0 varies substantially as a function of adultness for males but much less for females. 

### Assessing model fit

We can asses model fit for the model including interaction terms by making more posterior predictions with our new model.

```{r, cache = TRUE, collapse = TRUE}
y_pred_int = predict (model_interaction)
y_pred_no_re_int = predict (model_interaction, re_formula = NA)
```

We can make more interaction plots using our data and our posterior predictions. Below I compare our data, the predictions of our original model, and the predictions of our model that includes interactions. Whereas the model with no interactions enforced parallelism on the effects, our new model is able to capture the conditional nature of gender given adultness in our data. 

```{r interactionplot2, fig.height=3.5,fig.width=8,fig.cap="Interaction plots showing comparing our f0 data to posterior predictions, with and without interaction terms (neither contains Random Effects)."}
par (mfrow = c(1,3), mar = c(4,4,3,2))

plot.interaction (h95$gender, h95$adult, h95$f0, col=3:4, ylim=c(130,280),lwd=3,
                  type='b',pch=c(16,17),cex=1.5,main="Data",legend = FALSE)

plot.interaction (h95$gender, h95$adult, y_pred_no_re[,1],col=3:4, lwd=3,
                  type = 'b', pch = c(16,17), cex = 1.5, ylim = c(130,280),
                  main="No Int. no RE", legend = FALSE)

plot.interaction (h95$gender, h95$adult, y_pred_no_re_int[,1],col=3:4, lwd=3,
                  type = 'b', pch = c(16,17), cex = 1.5, ylim = c(130,280),
                  main="With Int. no RE", leg.x=1.8,leg.y=270, xlim=c(.95,2.3))
```

For the first time, we have a model that really does a reasonably-good job of representing the information in our data. The model can capture the gender-dependent nature of age-based f0 differences, and separately estimates between group variation and between group variation. 

### Investigating the interactions the easy way

There are built-in functions in `brms` that help you investigate your effects in the presence of interactions. The `conditional_effects` function calculates the values of effects conditional on the Intercept (for continuous variables). This means it adds the value of the Intercept to all its effects estimates. This function is extremely handy but also limited. You can't get the posterior samples from this function, meaning you can't use this output to compare the values of rows. Also, conditioning on the mean introduces noise to our effects estimates and makes their credible intervals larger. 

```{r, collapse = TRUE}
# group means
tapply (h95$f0, h95$group, mean)

# get conditional effects
model_effects = conditional_effects (model_interaction)

# adultness effect (average for adult vs children)
model_effects[[1]][,-c(1:5)]

# gender effect (average for females vs males)
model_effects[[2]][,-c(1:5)]

# recreated group means for w, m, g, b
model_effects[[3]][,-c(1:5)]
```

The `marginal_effects` function returns a list of matrices. Each one contains a different main effect or interaction term. Above I print each one in turn. We can see that these values match those we recreated above using the`hypothesis` function and the individual coefficients:

```{r, collapse = TRUE}
tapply (h95$f0, h95$group, mean)
hypothesis (model_interaction, c("Intercept = 0",
                "Intercept + -adult1 + -gender1 +  adult1:gender1 = 0",
                "Intercept + -adult1 +  gender1 + -adult1:gender1 = 0",
                "Intercept +  adult1 + -gender1 + -adult1:gender1 = 0",
                "Intercept +  adult1 +  gender1 +  adult1:gender1 = 0"))[[1]][,2:5]
```

### Making plots 

There are many ways to make 'nice' graphics using brms models. Many use packages like `ggplot2` and `bayesplot`. In general these figures are nice but sometimes too 'fancy' for many purposes where simple black and white graphics are needed. I also don't really know how to use `ggplot2` ( :| ). As a result, I'm going to focus on making simple line plots (like those common in journal articles) using base R graphics.     

The standard information provided in the output of `brm` model summaries can be used to make plots. These summaries always contain (among other things) these four columns in the same order: the mean estimate, the standard deviation, and the lower and upper credible intervals. I wrote a small function called `brmplot` that will help draw effects plots easily using these summaries. The `brmplot` function takes in a matrix containing these columns and makes plots showing the means and credible intervals of different effects, assuming that each row is an effect.

Below I get a summary of the fixed effects. I make plots of these effects in two orientations. In each one I omit the Intercept estimate as the magnitude of this is so different that it cannot easily be included on the plot. There is nothing special about these plots, but they are extremely effective at quickly communicating model information.

```{r, collapse = TRUE, cache = TRUE}
fixef_interaction = fixef (model_interaction)

fixef_interaction
```

```{r brmsplot, fig.height=3.5,fig.width=8,fig.cap="Horizontal and vertical plots of our fixed effects. Points indicate posterior means and lines indicate span of 95% credible intervals of the posterior distribution of the parameter."}
par (mfrow =c(1,2), mar = c(8,3,1,1))
brmplot (fixef_interaction[-1,]) ; abline (h = 0,lty=3)
par (mar = c(3,8,1,1))
brmplot (fixef_interaction[-1,], horizontal = FALSE) ; abline (v=0,lty=3)
```

In the left panel below, I use the effects calculated using the `marginal_effects` function to draw figures using the `brmplot` function. First I isolate the columns that represent the information I need. Then I plot the effects using repeated calls to `brmplot`. I can add a second plot over the first by setting `add = TRUE`. 

In the right plot, I do the same thing using the output of the hypothesis function. This will be a plot of the group effects centered at 0, since I have not added the overall Intercept to the means. Note that to get the table of interest out of the hypothesis object we have to first select the element named "hypothesis" from the `group_effects` object. In general, you may have to dig around in the structure of the objects created by `brms` to get the information you want. I usually run a `str` on the resulting object to see what's inside it, and what seems likely to contain the information I'm after. 

```{r, collapse = TRUE, cache = TRUE}
# estimates of group means based on model coefficients provided
# by the conditional_effects function.
model_effects[[3]][,8:11]

# the same thing is calculated 'manually' using the hypothesis function
group_effects = 
  hypothesis (model_interaction, hypothesis = 
                c("-adult1 + -gender1 +  adult1:gender1 = 0",
                  "-adult1 +  gender1 + -adult1:gender1 = 0",
                  " adult1 + -gender1 + -adult1:gender1 = 0",
                  " adult1 +  gender1 +  adult1:gender1 = 0"))
group_effects[["hypothesis"]][,2:5]
```

```{r brmsplot2, fig.height=3.5,fig.width=8,fig.cap="The examples of using parameter summaries to draw plots using the brmplot function."}

par (mfrow = c(1,2), mar = c(4,4,1,1))
brmplot (model_effects[[3]][1:2,8:11], type = 'b', ylim = c(120,250), 
         labels=c("Female","Male"), col = 3, xlim = c(.8,2.2))
brmplot (model_effects[[3]][3:4,8:11], type = 'b', add = TRUE, col = 4,
         labels="", pch=17)

brmplot (group_effects[["hypothesis"]][4:3,2:5], type = 'b', ylim = c(-85,40),  
         labels=c("Female","Male"), col = 3, xlim = c(.8,2.2))
brmplot (group_effects[["hypothesis"]][2:1,2:5], type = 'b', add = TRUE, col = 4,
         labels="", pch=17)
```


## Lmer corner

This is going to be a short one! The main shortcoming when it comes to `lmer` and fitting ANOVA-type models, is that there is no easy way to compare group effects within the model. For example, we can fit the model below which encodes the difference between each group mean and the overall mean.

```{r, collapse = TRUE}
lmer_four_groups = lme4::lmer (f0 ~ group + (1|speaker), data = h95)
summary (lmer_four_groups)
```

The results provided by `lmer` are very similar to those provided by `brm`:

```{r, collapse = TRUE}
fixef (model_four_groups)
```

Group 1 (boys) and group 2 (girls) have very similar effects to each other. Are they different? Using our `brm` model this can be answered easily, as shown above (and reproduced below):

```{r, collapse = TRUE}
hypothesis (model_four_groups, "group2 - group1 = 0")[[1]][,1:5]
```

Unfortunately, there is no way to answer this question given the information presented in the `lmer` model above. This is because the effects are only being estimates as differences to the mean, and not to group 1 or group 2). If we *did* want to investigate this difference specifically, we would need to refit the model using a different coding scheme. For example, if we used treatment coding group 1 (boys) would be the intercept, and the group effects would represent differences to this. We fit a model like this below:

```{r, collapse = TRUE}
options (contrasts = rep("contr.treatment",2))
lmer_four_groups_treatment = lme4::lmer (f0 ~ group + (1|speaker), data = h95)
summary (lmer_four_groups_treatment)
```

Notice that our group 2 predictor (`group`) is now equal to 2.3, the Hz difference between boys and girls. The value of the standard error (`Std. Error`) is 6.3, representing the uncertainty in the estimate. These values correspond closely to the estimates provided by our Bayesian model above of 2.3 and 6.4 respectively. 

Obviously this situation is not ideal if you plan to compare many groups. In contrast, with our `brm` model we can easily compare any of the four groups using the method outlined above, without ever having to re-fit the model.

## Plot Code

```{r get-labels, echo = FALSE}
labs = knitr::all_labels()
labs = labs[grep ("F4", labs)]
```

```{r all-code, ref.label=labs, eval=FALSE}
```








