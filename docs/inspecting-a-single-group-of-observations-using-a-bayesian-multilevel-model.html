<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Inspecting a ‘single group’ of observations using a Bayesian multilevel model | A Quick Introduction to Multilevel Bayesian Models for Linguistic Researchers</title>
  <meta name="description" content="Bayesian Models for Linguists" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Inspecting a ‘single group’ of observations using a Bayesian multilevel model | A Quick Introduction to Multilevel Bayesian Models for Linguistic Researchers" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://santiagobarreda.com" />
  
  <meta property="og:description" content="Bayesian Models for Linguists" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Inspecting a ‘single group’ of observations using a Bayesian multilevel model | A Quick Introduction to Multilevel Bayesian Models for Linguistic Researchers" />
  
  <meta name="twitter:description" content="Bayesian Models for Linguists" />
  

<meta name="author" content="Santiago Bareda" />


<meta name="date" content="2021-01-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inspecting-a-single-group-of-observations.html"/>
<link rel="next" href="comparing-two-groups-of-observations.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Models for Linguists</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html"><i class="fa fa-check"></i><b>1</b> Inspecting a single group of observations</a>
<ul>
<li class="chapter" data-level="1.1" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#data-and-research-questions"><i class="fa fa-check"></i><b>1.1</b> Data and research questions</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#inspecting-the-central-location-and-spread-of-values"><i class="fa fa-check"></i><b>1.1.1</b> Inspecting the central location and spread of values</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#probability-distributions"><i class="fa fa-check"></i><b>1.2</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#the-normal-distribution"><i class="fa fa-check"></i><b>1.2.1</b> The normal distribution</a></li>
<li class="chapter" data-level="1.2.2" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#referring-to-the-normal-distribution-to-make-inferences"><i class="fa fa-check"></i><b>1.2.2</b> Referring to the normal distribution to make inferences</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#probabilities-of-events-and-likelihoods-of-parameters"><i class="fa fa-check"></i><b>1.3</b> Probabilities of events and likelihoods of parameters</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#making-inferences-using-likelihoods"><i class="fa fa-check"></i><b>1.3.1</b> Making inferences using likelihoods</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#bayesian-models"><i class="fa fa-check"></i><b>1.4</b> Bayesian models</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#what-are-regression-models"><i class="fa fa-check"></i><b>1.4.1</b> What are regression models?</a></li>
<li class="chapter" data-level="1.4.2" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#whats-bayesian-about-these-models"><i class="fa fa-check"></i><b>1.4.2</b> What’s ‘Bayesian’ about these models?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#posterior-distributions"><i class="fa fa-check"></i><b>1.5</b> Posterior distributions</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#sampling-from-the-posterior"><i class="fa fa-check"></i><b>1.5.1</b> Sampling from the posterior</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="inspecting-a-single-group-of-observations.html"><a href="inspecting-a-single-group-of-observations.html#plot-code"><i class="fa fa-check"></i><b>1.6</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><i class="fa fa-check"></i><b>2</b> Inspecting a ‘single group’ of observations using a Bayesian multilevel model</a>
<ul>
<li class="chapter" data-level="2.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#data-and-research-questions-1"><i class="fa fa-check"></i><b>2.1</b> Data and research questions</a></li>
<li class="chapter" data-level="2.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#estimating-a-single-mean-with-the-brms-package"><i class="fa fa-check"></i><b>2.2</b> Estimating a single mean with the <code>brms</code> package</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#the-model"><i class="fa fa-check"></i><b>2.2.1</b> The model</a></li>
<li class="chapter" data-level="2.2.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#the-model-formula"><i class="fa fa-check"></i><b>2.2.2</b> The model formula</a></li>
<li class="chapter" data-level="2.2.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#calling-the-brm-function"><i class="fa fa-check"></i><b>2.2.3</b> Calling the <code>brm</code> function</a></li>
<li class="chapter" data-level="2.2.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#interpreting-the-model-print-statement"><i class="fa fa-check"></i><b>2.2.4</b> Interpreting the model print statement</a></li>
<li class="chapter" data-level="2.2.5" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#seeing-the-samples"><i class="fa fa-check"></i><b>2.2.5</b> Seeing the samples</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#repeated-measures-data"><i class="fa fa-check"></i><b>2.3</b> Repeated measures data</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#multilevel-models"><i class="fa fa-check"></i><b>2.3.1</b> Multilevel models</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#estimating-a-multilevel-model-with-brms"><i class="fa fa-check"></i><b>2.4</b> Estimating a multilevel model with <code>brms</code></a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#the-model-1"><i class="fa fa-check"></i><b>2.4.1</b> The model</a></li>
<li class="chapter" data-level="2.4.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#fitting-the-model"><i class="fa fa-check"></i><b>2.4.2</b> Fitting the model</a></li>
<li class="chapter" data-level="2.4.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#simulating-data-using-our-model-parameters"><i class="fa fa-check"></i><b>2.4.3</b> Simulating data using our model parameters</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#checking-model-convergence"><i class="fa fa-check"></i><b>2.5</b> Checking model convergence</a></li>
<li class="chapter" data-level="2.6" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#specifying-prior-probabilities"><i class="fa fa-check"></i><b>2.6</b> Specifying prior probabilities</a></li>
<li class="chapter" data-level="2.7" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#answering-our-research-questions"><i class="fa fa-check"></i><b>2.7</b> Answering our research questions</a></li>
<li class="chapter" data-level="2.8" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#lmer-corner"><i class="fa fa-check"></i><b>2.8</b> Lmer corner</a></li>
<li class="chapter" data-level="2.9" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#plot-code-1"><i class="fa fa-check"></i><b>2.9</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html"><i class="fa fa-check"></i><b>3</b> Comparing two groups of observations</a>
<ul>
<li class="chapter" data-level="3.1" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#data-and-research-questions-2"><i class="fa fa-check"></i><b>3.1</b> Data and research questions</a></li>
<li class="chapter" data-level="3.2" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#estimating-the-difference-between-two-means-with-brms"><i class="fa fa-check"></i><b>3.2</b> Estimating the difference between two means with ‘brms’</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#fitting-the-model-1"><i class="fa fa-check"></i><b>3.2.1</b> Fitting the model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#contrasts"><i class="fa fa-check"></i><b>3.3</b> Contrasts</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#treatment-coding"><i class="fa fa-check"></i><b>3.3.1</b> Treatment coding</a></li>
<li class="chapter" data-level="3.3.2" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#sum-coding"><i class="fa fa-check"></i><b>3.3.2</b> Sum coding</a></li>
<li class="chapter" data-level="3.3.3" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#comparison-of-sum-and-treatment-coding"><i class="fa fa-check"></i><b>3.3.3</b> Comparison of sum and treatment coding</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#refitting-the-model-with-sum-coding"><i class="fa fa-check"></i><b>3.4</b> Refitting the model with sum coding</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#fitting-the-model-2"><i class="fa fa-check"></i><b>3.4.1</b> Fitting the model</a></li>
<li class="chapter" data-level="3.4.2" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#the-model-2"><i class="fa fa-check"></i><b>3.4.2</b> The model</a></li>
<li class="chapter" data-level="3.4.3" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#simulating-the-two-group-model"><i class="fa fa-check"></i><b>3.4.3</b> Simulating the two-group model</a></li>
<li class="chapter" data-level="3.4.4" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#interpreting-the-two-group-model"><i class="fa fa-check"></i><b>3.4.4</b> Interpreting the two-group model</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#random-effects"><i class="fa fa-check"></i><b>3.5</b> ‘Random’ Effects</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#random-effects-priors-and-pooling"><i class="fa fa-check"></i><b>3.5.1</b> Random effects, priors and pooling</a></li>
<li class="chapter" data-level="3.5.2" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#inspecting-the-random-effects"><i class="fa fa-check"></i><b>3.5.2</b> Inspecting the random effects</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#but-what-does-it-all-mean"><i class="fa fa-check"></i><b>3.6</b> But what does it all mean?</a></li>
<li class="chapter" data-level="3.7" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#lmer-corner-1"><i class="fa fa-check"></i><b>3.7</b> Lmer corner</a></li>
<li class="chapter" data-level="3.8" data-path="comparing-two-groups-of-observations.html"><a href="comparing-two-groups-of-observations.html#plot-code-2"><i class="fa fa-check"></i><b>3.8</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html"><i class="fa fa-check"></i><b>4</b> Comparing many groups</a>
<ul>
<li class="chapter" data-level="4.1" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#data-and-research-questions-3"><i class="fa fa-check"></i><b>4.1</b> Data and research questions</a></li>
<li class="chapter" data-level="4.2" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#comparing-four-or-any-number-of-groups"><i class="fa fa-check"></i><b>4.2</b> Comparing four (or any number of) groups</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#the-model-3"><i class="fa fa-check"></i><b>4.2.1</b> The model</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#investigating-many-groups-using-predictors-analysis-of-variance"><i class="fa fa-check"></i><b>4.3</b> Investigating many groups using predictors: Analysis of Variance</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#the-model-4"><i class="fa fa-check"></i><b>4.3.1</b> The model</a></li>
<li class="chapter" data-level="4.3.2" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#fitting-the-model-and-interpreting-the-results"><i class="fa fa-check"></i><b>4.3.2</b> Fitting the model and interpreting the results</a></li>
<li class="chapter" data-level="4.3.3" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#investigating-model-fit"><i class="fa fa-check"></i><b>4.3.3</b> Investigating model fit</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#interactions-and-interaction-plots"><i class="fa fa-check"></i><b>4.4</b> Interactions and interaction plots</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#interactions-in-our-f0-data"><i class="fa fa-check"></i><b>4.4.1</b> Interactions in our f0 data</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#investigating-interactions-with-a-model"><i class="fa fa-check"></i><b>4.5</b> Investigating interactions with a model</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#fitting-the-model-and-interpreting-the-results-1"><i class="fa fa-check"></i><b>4.5.1</b> Fitting the model and interpreting the results</a></li>
<li class="chapter" data-level="4.5.2" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#assessing-model-fit"><i class="fa fa-check"></i><b>4.5.2</b> Assessing model fit</a></li>
<li class="chapter" data-level="4.5.3" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#investigating-the-interactions-the-easy-way"><i class="fa fa-check"></i><b>4.5.3</b> Investigating the interactions the easy way</a></li>
<li class="chapter" data-level="4.5.4" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#making-plots"><i class="fa fa-check"></i><b>4.5.4</b> Making plots</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#lmer-corner-2"><i class="fa fa-check"></i><b>4.6</b> Lmer corner</a></li>
<li class="chapter" data-level="4.7" data-path="comparing-many-groups.html"><a href="comparing-many-groups.html#plot-code-3"><i class="fa fa-check"></i><b>4.7</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a></li>
<li class="divider"></li>
<li><a href="http://www.santiagobarreda.com" target="blank">Written by Santiago Barreda</a></li>
<li><a href="A-Quick-Introduction-to-Multilevel-Bayesian-Models-for-Linguistic-Researchers.pdf" target="blank">Download possibly outdated and badly-formatted PDF</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Quick Introduction to Multilevel Bayesian Models for Linguistic Researchers</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Inspecting a ‘single group’ of observations using a Bayesian multilevel model</h1>
<p>In this chapter I am going to discuss how to use the <code>brms</code> package to estimate a population mean given a sample of data. For these models the data:</p>
<ul>
<li>can come from one speaker/subject or many speakers/subjects.</li>
<li>each speaker/subject can contribute multiple data points.</li>
<li>does not need to be ‘balanced’ or ‘complete’ across all subjects.</li>
</ul>
<p>The ‘traditional’ designs equivalent to these models are: one-sample t-test, and repeated-measures one-way ANOVA with only two groups. However, these models won’t be discussed in the chapter below.</p>
<div id="data-and-research-questions-1" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Data and research questions</h2>
<p>We are going to keep analyzing the female f0 data from the Hillenbrand et al. (1995) dataset, discussed in chapter 1.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb52-1" aria-hidden="true" tabindex="-1"></a>url1 <span class="ot">=</span> <span class="st">&quot;https://raw.githubusercontent.com/santiagobarreda&quot;</span></span>
<span id="cb52-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb52-2" aria-hidden="true" tabindex="-1"></a>url2 <span class="ot">=</span> <span class="st">&quot;/stats-class/master/data/h95_vowel_data.csv&quot;</span></span>
<span id="cb52-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb52-3" aria-hidden="true" tabindex="-1"></a>h95 <span class="ot">=</span> <span class="fu">read.csv</span> (<span class="fu">url</span>(<span class="fu">paste0</span> (url1, url2)))</span>
<span id="cb52-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="do">## set up colors for plotting</span></span>
<span id="cb52-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb52-5" aria-hidden="true" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">source_url</span> (<span class="fu">paste0</span> (url1, <span class="st">&quot;/stats-class/master/data/colors.R&quot;</span>))</span></code></pre></div>
<pre><code>## SHA-1 hash of file is 52a05a5ec7455b553b6b56c0aba23548d5844ace</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="do">## source functions</span></span>
<span id="cb54-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb54-2" aria-hidden="true" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">source_url</span> (<span class="fu">paste0</span> (url1, <span class="st">&quot;/stats-class/master/data/functions.R&quot;</span>))</span></code></pre></div>
<pre><code>## SHA-1 hash of file is e9fbb4d1e6b3ec8d7981de963b533acad108f550</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># select women only</span></span>
<span id="cb56-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb56-2" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> h95[h95<span class="sc">$</span>group <span class="sc">==</span> <span class="st">&#39;w&#39;</span>,]</span>
<span id="cb56-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="co"># this is unique subject numbers across all groups</span></span>
<span id="cb56-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb56-4" aria-hidden="true" tabindex="-1"></a>w<span class="sc">$</span>speaker <span class="ot">=</span> <span class="fu">factor</span> (w<span class="sc">$</span>speaker)  </span>
<span id="cb56-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="co"># select only the vector of interest</span></span>
<span id="cb56-6"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb56-6" aria-hidden="true" tabindex="-1"></a>f0 <span class="ot">=</span> w<span class="sc">$</span>f0</span></code></pre></div>
<p>We are going to try to address the same questions we talked about last week:</p>
<ol style="list-style-type: decimal">
<li><p>What is the average f0 of the whole <em>population</em> likely to be?</p></li>
<li><p>Can we set bounds on likely mean f0 values based on the data we collected?</p></li>
</ol>
<p>However, this time we are going to do this with a Bayesian multilevel model.</p>
</div>
<div id="estimating-a-single-mean-with-the-brms-package" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Estimating a single mean with the <code>brms</code> package</h2>
<p>The <code>brms</code> <a href="https://github.com/paul-buerkner/brms">Bayesian regression models</a> package in R lets you fit Bayesian models using the STAN probabilistic programming language using R. The package is really amazing and makes Bayesian multilevel modeling easy and accessible for anyone. It also includes a lot of helper functions that make working with these models very convenient.</p>
<p><code>brms</code> should be installed in R so that the models described below will work. Make sure you have the latest version of R (and Rstudio) and the latest version of the `brms’ package installed. Sometimes using older versions can cause R to crash when fitting models.</p>
<div id="the-model" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> The model</h3>
<p>Model structures are expressed in R using a very specific syntax. Think of writing a model formula as writing a language within R. The good thing about learning to write models is then you can use this knowledge to describe your models in your work, and to interpret other people’s models.</p>
<p>The model formulas resemble regression equations to some extent, but there are some differences. Remember that regression models can be thought of in either of two two ways:</p>
<p><span class="math display" id="eq:21">\[\begin{equation}
\begin{split}
\\
y_{[i]} = \mu_{[i]} + \varepsilon_{[i]} \\ \\
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma) \\ \\
\end{split}
\tag{2.1}
\end{equation}\]</span></p>
<p>The top line says that your observed variable for any given trial <span class="math inline">\(y_{[i]}\)</span> is the sum of some of some average expected value for that trial, (<span class="math inline">\(\mu_{[i]}\)</span>) and some specific random error for that trial (<span class="math inline">\(\mu_{[i]}\)</span>). The random error is expected to be normally distributed with a mean of 0 and some unknown standard deviation (<span class="math inline">\(\varepsilon_{[i]} \sim \mathcal{N}(0,\sigma)\)</span>). The second line presents the <span class="math inline">\(y\)</span> variable as being a normally-distributed variable with a trial-specific mean of <span class="math inline">\(\mu_i\)</span>, and a fixed standard deviation <span class="math inline">\(\sigma_{error}\)</span></p>
<p>In general, in regression models we would really like to understand orderly variation in <span class="math inline">\(\mu_{[i]}\)</span> from trial to trial by breaking it up into predictors (<span class="math inline">\(\mathrm{x}_{1}, \mathrm{x}_{2},...\)</span>) that are combined using some weights (<span class="math inline">\(\alpha_1, \alpha_2,...\)</span>).</p>
<p><span class="math display" id="eq:22">\[
\mu_{[i]} = \alpha_1*\mathrm{x}_{1{[i]}} + \alpha_2*\mathrm{x}_{2i}+...+\alpha_j*\mathrm{x}_{j{[i]}}
\tag{2.2}
\]</span></p>
<p>‘Fitting’ a regression model consists of trying to ‘guess’ the values of the weighing factors (<span class="math inline">\(\alpha\)</span>), called the <em>model coefficients</em>. When we are only trying to estimate a single average, we don’t have any predictors to explain variation in <span class="math inline">\(\mu_{[i]}\)</span>. In fact, our model structure suggests we expect no variation in <span class="math inline">\(\mu_{[i]}\)</span> from trial to trial!.</p>
<p>Mathematically, we can’t just say ‘we have no predictor’ since everything needs to be represented by a number. As a result, we use a single ‘predictor’ <span class="math inline">\(\mathrm{x}\)</span> with a value of 1 so that our regression equation is:</p>
<p><span class="math display" id="eq:23">\[
\mu_{[i]} = \alpha_1*1
\tag{2.3}
\]</span></p>
<p>Now our model is trying to guess the value of a single coefficient (<span class="math inline">\(\alpha_1\)</span>), and we expect this coefficient to be equal to <span class="math inline">\(\mu_{[i]}\)</span> since it is being multiplied by a ‘predictor’ with a constant value of 1.</p>
<p>This kind of model is called an ‘Intercept only’ model. Regression models are really about representing <em>differences</em>, differences between groups and across conditions. When you are encoding differences, you need an overall reference point. For example, saying that something is 5 miles north is only interpretable given some reference point. The ‘reference point’ used by your model is called your ‘Intercept’. Basically, our model consists <em>only</em> of a single reference point, and the <span class="math inline">\(\alpha_1\)</span> parameter reflects its value (as shown in Equation <a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#eq:23">(2.3)</a>).</p>
<p>As a result, the <span class="math inline">\(\alpha_1\)</span> coefficient is called the ‘intercept’ in our model. When a coefficient is just being multiplied by a ‘fake’ predictor that just equals 1, we can omit it from the regression model (but its still secretly there).</p>
<p>Based on the above, our f0 model can be thought of like this:</p>
<p><span class="math display" id="eq:24">\[\begin{equation}
\begin{split}
\\
f0_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma) \\ \\ 
\mu_{[i]} = Intercept \\ \\
\end{split}
\tag{2.4}
\end{equation}\]</span></p>
<p>Put in plain English, each line in the model says the following:</p>
<ul>
<li><p>We expect that f0 for a given observation <span class="math inline">\(i\)</span> is normally distributed according to some trial-specific expected value and some unknown (but fixed) standard deviation.</p></li>
<li><p>The expected value for any given trial (<span class="math inline">\(\mu_{[i]}\)</span>) is equal to the intercept of the model for all trials. This means its fixed and we have the same expected value for all tokens!</p></li>
</ul>
<p>What the model also implicitly says that the error is drawn from a normal distribution with a mean of 0 and a standard deviation of <span class="math inline">\(\sigma\)</span>. This distribution represents all deviations in f0 around the mean f0 for the sample (<span class="math inline">\(\mu_{[i]}\)</span>). In other words, the error for this model is expected to look like:</p>
<p><span class="math display" id="eq:25">\[
\varepsilon_{[i]} \sim \mathcal{N}(0,\sigma)
\tag{2.5}
\]</span></p>
</div>
<div id="the-model-formula" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> The model formula</h3>
<p>Generally, model formulas in R have the form:</p>
<p><code>y ~ predictor</code></p>
<p>where all variables are represented by their names in your data. The variable we are interested in understanding (<span class="math inline">\(y\)</span>) goes on the left hand side, and on our predictors go on the right hand side, separated by a <span class="math inline">\(\sim\)</span>. Notice that the random term (<span class="math inline">\(\varepsilon\)</span>) is not included in the model formula.</p>
<p>The formula above can be read as ‘y is distributed according to some predictor’, which really means “we think there is systematic variation in our y variable that can be understood by considering its joint variation with our predictor variable(s).”</p>
<p>For intercept only models, the number <code>1</code> is included in the model formula to indicate that a single constant value is being estimated (as in <a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#eq:23">(2.3)</a>). As a result, our model formula will have the form <code>f0 ~ 1</code>. This model could be said out loud like “we are trying to estimate the mean of f0” or “we are predicting mean f0 given only an intercept”.</p>
</div>
<div id="calling-the-brm-function" class="section level3" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Calling the <code>brm</code> function</h3>
<p>Below, I load the <code>brms</code> package, which contains the <code>brm</code> function. The <code>brm</code> function takes a model specification, data and some other information, and fits a model that estimates all the model parameters. Unless otherwise specified, <code>brm</code> assumes that the error component (<span class="math inline">\(\varepsilon\)</span>) of your model is normally distributed. The first argument in the function call is the model formula, and the second argument tells the function where to find the data. The other arguments tell the function to estimates a single set of samples (chains = 1) using a single processor on your CPU (cores = 1). These arguments will be discussed more later.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># To ensure predictable results in examples, I will be using the same random  </span></span>
<span id="cb57-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="co"># seed throughout, and resetting it before running any &#39;random&#39; process.  </span></span>
<span id="cb57-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb57-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb57-4" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> brms<span class="sc">::</span><span class="fu">brm</span> (f0 <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> w, <span class="at">chains =</span> <span class="dv">1</span>, <span class="at">cores =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## Compiling Stan program...</code></pre>
<pre><code>## Start sampling</code></pre>
<pre><code>## 
## SAMPLING FOR MODEL &#39;98dae0f1caaef07c210aac2156c73749&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.059 seconds (Warm-up)
## Chain 1:                0.04 seconds (Sampling)
## Chain 1:                0.099 seconds (Total)
## Chain 1:</code></pre>
<p>By default, <code>brms</code> takes 2000 samples, throwing out the first 1000 and returning the last 1000. The output above shows you that the sampler is working, and tells you about the progress as it works.</p>
<p>This is the last time I will be actually fitting a model in the code chunks. I am going to be relying on pre-fit models that you can load after downloading from the book GitHub. Models can be found in the folder corresponding to each chapter.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="do">## download pre-fit model from: </span></span>
<span id="cb61-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="do">## github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb61-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="do">## and load after placing in working directory</span></span>
<span id="cb61-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-4" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">readRDS</span> (<span class="st">&#39;2_model.RDS&#39;</span>)</span></code></pre></div>
<p>recompiling to avoid crashing R session</p>
<p>Warning messages:
1: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
<a href="http://mc-stan.org/misc/warnings.html#bulk-ess" class="uri">http://mc-stan.org/misc/warnings.html#bulk-ess</a>
2: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
<a href="http://mc-stan.org/misc/warnings.html#tail-ess" class="uri">http://mc-stan.org/misc/warnings.html#tail-ess</a></p>
</div>
<div id="interpreting-the-model-print-statement" class="section level3" number="2.2.4">
<h3><span class="header-section-number">2.2.4</span> Interpreting the model print statement</h3>
<p>We can evaluate the model name to show the default <code>brms</code> model print statement:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="do">## inspect model</span></span>
<span id="cb62-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb62-2" aria-hidden="true" tabindex="-1"></a>model</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 
##    Data: w (Number of observations: 576) 
## Samples: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 1000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.40      0.97   218.33   222.30 1.00      851      557
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    23.24      0.69    21.99    24.61 1.00      653      550
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Typing the model name into the console and hitting enter prints the information seen above. The first part just tells you technical details that we don’t have to worry about for now (though some are obvious).</p>
<pre><code>Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: f0 ~ 1 
   Data: w (Number of observations: 576) 
Samples: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 1000</code></pre>
<p>Next we see estimated effects for out predictors, in this case only an intercept. This is a ‘population’ level effect because is is shared by all observations in our sample, and not specific to any one observation.</p>
<pre><code>Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   220.40      0.97   218.33   222.30 1.00      851      557</code></pre>
<p>The information above provides the mean (Estimate) and standard deviation (Est. Error) of the posterior distribution of <span class="math inline">\(\mu\)</span> (Intercept). The values of <code>l-95% CI</code> and <code>u-95% CI</code> represent the upper and lower ‘95% credible intervals’ for the posterior distribution of this parameter.</p>
<p>The <em>x% credible interval</em> for a parameter is the smallest interval that encloses x% of the distribution. This parameter has an x% chance (0.x probability) of falling inside the x% credible interval. So, this means that there is a 95% probability that <span class="math inline">\(\mu\)</span> is between 218 and 222 Hz given our data and model structure.</p>
<p>Notice that the parameter estimate and intervals almost exactly match the estimate and intervals we obtain by referencing the theoretical likelihood function (discussed in Chapter 1):</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="do">## sample mean</span></span>
<span id="cb66-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span> (f0)</span></code></pre></div>
<pre><code>## [1] 220.401</code></pre>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="do">## theoretical quantiles for likelihood of mean</span></span>
<span id="cb68-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span> (<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="fu">mean</span> (f0), <span class="fu">sd</span> (f0) <span class="sc">/</span> <span class="fu">sqrt</span> (<span class="fu">length</span> (f0) ) )</span></code></pre></div>
<pre><code>## [1] 218.5047 222.2974</code></pre>
<p>Our model also provides us an estimate of the error standard deviation(<span class="math inline">\(\sigma\)</span>), under ‘Family Specific Parameters: sigma’. This estimate closely matches our sample standard deviation (<span class="math inline">\(s_{x}\)</span>) estimate of 23.2. In addition, we also get a 95% credible interval for this parameter (2.5% = 21.99, 97.5% = 24.61).</p>
<pre><code>Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    23.24      0.69    21.99    24.61 1.00      653      550</code></pre>
<p>This last section is just boilerplate and contains some basic reminders. This text will look the same after all models.</p>
<pre><code>Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<div id="seeing-the-samples" class="section level3" number="2.2.5">
<h3><span class="header-section-number">2.2.5</span> Seeing the samples</h3>
<p>In Chapter 1 I discussed that samplers (like <code>brm</code>, or STAN) take samples of the posterior distributions of parameters given the data and model structure. It’s helpful to see that this is quite literally what is happening, and that the print statement above just summarizes the information contained in the posterior samples.</p>
<p>Below I get the posterior samples from the model. We have 1000 samples, as indicated in the model output above. The first column represents the model intercept, the middle column is the error, and the third column is a statistic related to model fit.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="do">## get posterior samples from model</span></span>
<span id="cb72-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb72-2" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">=</span> brms<span class="sc">::</span><span class="fu">posterior_samples</span> (model)</span>
<span id="cb72-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span> (samples)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1000 obs. of  3 variables:
##  $ b_Intercept: num  221 221 220 222 220 ...
##  $ sigma      : num  22.1 21.9 23.2 21.9 22.9 ...
##  $ lp__       : num  -2635 -2635 -2634 -2637 -2634 ...</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="do">## inspect values</span></span>
<span id="cb74-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span> (samples)</span></code></pre></div>
<pre><code>##   b_Intercept    sigma      lp__
## 1    220.7860 22.06961 -2634.851
## 2    220.5312 21.93719 -2635.160
## 3    219.6445 23.22390 -2633.588
## 4    222.3286 21.93414 -2637.392
## 5    219.5626 22.87259 -2633.785
## 6    221.2339 23.08532 -2633.672</code></pre>
<p>I can plot the individual samples for the mean parameter on the left below. On the right I plot a histogram of the same samples, superimposed with the theoretical distribution of the likelihood. Although this is not the posterior, with so many data points we expect our posterior to be dominated by the likelihood so they should be similar.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb76-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (samples[,<span class="dv">1</span>], <span class="at">xlab =</span> <span class="st">&#39;Sample number&#39;</span>,<span class="at">ylab =</span> <span class="st">&#39;f0&#39;</span>,<span class="at">col=</span>teal,<span class="at">pch=</span><span class="dv">16</span>)</span>
<span id="cb76-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (samples[,<span class="dv">1</span>], <span class="at">freq =</span> <span class="cn">FALSE</span>, <span class="at">breaks =</span> <span class="dv">20</span>,<span class="at">main=</span><span class="st">&#39;&#39;</span>,<span class="at">xlab=</span><span class="st">&#39;f0&#39;</span>,<span class="at">col=</span>maroon)</span>
<span id="cb76-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb76-4" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dnorm</span> (x, <span class="fu">mean</span> (f0), <span class="fu">sd</span> (f0) <span class="sc">/</span> <span class="fu">sqrt</span> (<span class="fu">length</span> (f0) )), <span class="at">add =</span> <span class="cn">TRUE</span>,</span>
<span id="cb76-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb76-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">4</span>, <span class="at">col =</span> yellow)</span></code></pre></div>
<p><img src="02_files/figure-html/posteriorplot1-1.png" width="768" /></p>
<p>Recall that our model output provides information about expected values for the mean parameter:</p>
<pre><code>Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   220.40      0.97   218.33   222.30 1.00      851      557</code></pre>
<p>These simply correspond to the quantiles of the posterior samples!</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span> (samples[,<span class="dv">1</span>], <span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">5</span>, .<span class="dv">975</span>))</span></code></pre></div>
<pre><code>##     2.5%      50%    97.5% 
## 218.3288 220.3997 222.3001</code></pre>
<p>There is no special status for these quantiles. We can check the values of other ones:</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span> (samples[,<span class="dv">1</span>], <span class="fu">c</span>(.<span class="dv">25</span>, .<span class="dv">75</span>))</span></code></pre></div>
<pre><code>##      25%      75% 
## 219.8043 221.0296</code></pre>
<p>Or even use the posterior distribution to find the probability that the mean parameter is over/under any arbitrary value:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span> (samples[,<span class="dv">1</span>] <span class="sc">&lt;</span> <span class="dv">221</span>)</span></code></pre></div>
<pre><code>## [1] 0.74</code></pre>
<p>For example, given the calculation above we can say that there is a 0.74 probability (a 74% chance) that the mean f0 for female speakers in this population is under 221 Hz, given our data and model structure. We come to this conclusion by finding that 74% of the posterior samples of the parameter of interest are below 221 Hz.</p>
</div>
</div>
<div id="repeated-measures-data" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Repeated measures data</h2>
<p>The model we fit above is a reasonable starting point, but it has many weaknesses. For example, it does not consider the fact that our data was produced by a fixed number of speakers, sampled from a population. It does not consider the variation in f0 inherent between speakers, treating this as ‘noise’.</p>
<p>Importantly, our data consists of 12 productions from each speaker in our sample, meaning we have ‘repeated measures’ data. Treating repeated measures data as if it were <em>not</em> repeated measures data can cause problems for our inferences. This is because it can give us a warped perspective of how much variability there really is in the sample.</p>
<p>For example, if I told you I had 1,000,000 samples of speech from male speakers from Los Angeles, you may be confident that I can estimate the average f0 male speakers from Los Angeles very accurately. But what if I told you that all these samples were from only three different people? You know instinctively that this makes my data less reliable.</p>
<p>The reason repeated-measures data can cause problems is because the measurements are correlated: multiple measurements from the same person are obviously going to be related to each other. If you measure the height of a tall person today, they will still be tall tomorrow. Because of this general principle, although we have 12 productions from each of 48 female speakers, we do not actually have 576=48*12 totally independent observations in our data.</p>
<p>This can be seen quite clearly below. The top panel shows the distribution of all our f0 measurements. The bottom panel shows speaker boxplots (one for each speaker’s data). If we were to ‘push down’ on the bottom panel and collapse all our boxplots into a single distribution, we would end up with the boxplot in the top panel.</p>
<p>These boxplots shows that each speaker has their own average f0, and that their productions tend to vary around their ‘natural average. As a result, we might have closer to 46 observations (one average value per speaker) than 576. For example, the ’outliers’ around 150 Hz may seem like huge ‘errors’ in the top plot. In the bottom plot we see that these productions all come from one speaker, and actually reflect her average f0. These are not errors but systematic between-speaker <em>variation</em>.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">1</span>)); <span class="fu">layout</span> (<span class="at">mat =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">heights =</span> <span class="fu">c</span>(.<span class="dv">3</span>,.<span class="dv">7</span>))</span>
<span id="cb84-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (f0, <span class="at">main =</span> <span class="st">&quot;Overall Boxplot&quot;</span>, <span class="at">col=</span><span class="st">&quot;lavender&quot;</span>, </span>
<span id="cb84-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb84-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">horizontal =</span> <span class="cn">TRUE</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">140</span>,<span class="dv">320</span>)) </span>
<span id="cb84-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (f0 <span class="sc">~</span> speaker, <span class="at">data =</span> w, <span class="at">main =</span> <span class="st">&quot;Speaker Boxplots&quot;</span>, <span class="at">col=</span><span class="fu">c</span>(yellow,coral,</span>
<span id="cb84-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb84-5" aria-hidden="true" tabindex="-1"></a>         deepgreen,teal), <span class="at">horizontal =</span> <span class="cn">TRUE</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">140</span>,<span class="dv">320</span>)) </span>
<span id="cb84-6"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb84-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> <span class="fl">220.4</span>,<span class="at">lty=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;grey&#39;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="02_files/figure-html/unnamed-chunk-11-1.png" width="768" /></p>
<div id="multilevel-models" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Multilevel models</h3>
<p>In linguistics, and many other similar fields, almost all of our data is repeated measures data. The methods most commonly-used by linguists (e.g., experiments, interviews, corpora, … etc.) yield many observations per person, and typically all involve data from multiple people/sources. As a result, the analysis of this data requires that models be able to account for within <em>and</em> between speaker variation in our data. Multilevel models address the correlated nature of repeated measures data by estimating multiple sources of variation simultaneously.</p>
<p>Repeated-measures data leads to random variation in parameters that is <em>indistinguishable</em> from that of our ‘data’. To a large extent, whether something is a parameter or a data point depends somewhat on your perspective. For example, consider the figure below. The top left presents a histogram of all f0 measurements, while the top right presents a boxplot of the same. The bottom left presents the speaker boxplots (one per speaker), each of which resembles the overall boxplot in the top right. We can then zoom in on a single speaker’s productions (bottom right) and produce a histogram that suggests a normal distribution reminiscent in shape to the overall aggregated data (top left).</p>
<p>If you are trying to estimate a speaker’s mean f0, then the individual productions might be ‘data’ and the mean can be thought of as a ‘parameter’. If you were instead only interested in the population average, maybe now your subject mean is actually just a single data point, and the <em>population</em> mean is actually your ‘parameter’.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">1</span>))</span>
<span id="cb85-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (w<span class="sc">$</span>f0, <span class="at">main =</span> <span class="st">&quot;Histogram of all f0&quot;</span>,<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">140</span>, <span class="dv">290</span>), <span class="at">freq =</span> <span class="cn">FALSE</span>,</span>
<span id="cb85-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb85-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">col=</span><span class="dv">4</span>)</span>
<span id="cb85-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb85-4" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (w<span class="sc">$</span>f0, <span class="at">main =</span> <span class="st">&quot;Boxplot of all f0&quot;</span>,<span class="at">col=</span>lavender)</span>
<span id="cb85-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb85-5" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (f0 <span class="sc">~</span> speaker, <span class="at">data =</span> w, <span class="at">main =</span> <span class="st">&quot;Speaker Boxplots&quot;</span>,<span class="at">col=</span>deepgreen) </span>
<span id="cb85-6"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb85-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">v =</span> <span class="dv">16</span>,<span class="at">lty=</span><span class="dv">3</span>)</span>
<span id="cb85-7"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb85-7" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (w<span class="sc">$</span>f0[w<span class="sc">$</span>speaker <span class="sc">==</span> <span class="dv">107</span>], <span class="at">main =</span> <span class="st">&quot;Histogram of speaker 107&quot;</span>,</span>
<span id="cb85-8"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb85-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">160</span>, <span class="dv">260</span>), <span class="at">freq =</span> <span class="cn">FALSE</span>,<span class="at">col=</span>yellow)</span></code></pre></div>
<p><img src="02_files/figure-html/unnamed-chunk-12-1.png" width="768" /></p>
<p>A multilevel model is able to simultaneously model independent variation at multiple ‘levels’. For our f0 data, these are:</p>
<ul>
<li><p>The ‘upper’ level: Between-speaker variation in mean f0. This can be thought of like variation in <span class="math inline">\(\mu_{speaker}\)</span>. Speaker’s have an average f0 (<span class="math inline">\(\mu_{speaker}\)</span>) that they produce over time. However, speakers are chosen randomly from a larger population, and so any given speaker’s <span class="math inline">\(\mu_{speaker}\)</span> is unpredictable a priori.</p></li>
<li><p>The ‘lower’ level: Within-speaker variation, analogous to <span class="math inline">\(\varepsilon\)</span>. When an individual speaker produces speech, their productions will vary around their average from token to token. Our model cannot explain this and so this is ‘error’</p></li>
</ul>
<p>As seen in the figure above, the variation at the lower and upper levels are analogous. Just like individual speakers will rarely have an average f0 exactly like the population average, individual speakers will rarely produce f0 values exactly at their speaker average. Importantly, variation at the two levels is independent and logically distinct: within-speaker variation can be small or large independently of whether between-speaker variation is large or small.</p>
<p>Basically, each subject’s productions form a little normal distribution around their average, and the mix of these little distributions results in the overall ‘big’ distribution of data across all subjects. By using multilevel models, we can estimate the effects of multiple sources of variation at the same time.</p>
</div>
</div>
<div id="estimating-a-multilevel-model-with-brms" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Estimating a multilevel model with <code>brms</code></h2>
<p>We are now going to fit the same model we fit above, but with a structure that reflects the repeated-measures nature of the data.</p>
<div id="the-model-1" class="section level3" number="2.4.1">
<h3><span class="header-section-number">2.4.1</span> The model</h3>
<p>To specify a multilevel model, you need to write a slightly more complicated model formula. This explanation assumes that you have a dataframe or matrix where one column contains the variable you are interested and predicting (in this case <code>f0</code>), and another column contains a vector containing unique labels for each speaker or source of data (in this case a unique speaker label <code>speaker</code>).</p>
<p>To indicate that your model contains an ‘upper’ level where you have clusters of data coming from different individuals, you have to put another model inside your main model!</p>
<p>Before, the model formula looked like this:</p>
<p><code>f0 ~ 1</code></p>
<p>which meant ‘predict f0 using only an intercept’. Now the model formula will look like this:</p>
<p><code>f0 ~ 1 + ( 1 | speaker)</code></p>
<p>When you place a predictor in the formula in parenthesis and on the right-hand-side of a pipe, like this <code>( | predictor )</code>, you tell <code>brm</code> that you expect data to be clustered according to each category represented in the grouping vector. In this case, we are telling <code>brm</code> that each unique speaker is a cluster of data. Whatever you put in the left-hand-side of the parentheses <code>( in here | predictor )</code> is the model for each subcluster!</p>
<p>So what does this model formula mean: <code>f0 ~ 1 + ( 1 | speaker)</code>? It tells <code>brm</code>: predict f0 based on only an intercept, but also allow intercept values to vary separately for each speaker. Effectively, this model formula is telling <code>brm</code> to figure out all the information presented in the figures above.</p>
<p>This regression model is now something like this:</p>
<p><span class="math display" id="eq:26">\[\begin{equation}
\begin{split}
\\
f0_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma) \\ \\
\mu_{[i]} = Intercept + \alpha_{speaker_{[i]}} \\
\\
\end{split}
\tag{2.6}
\end{equation}\]</span></p>
<p>In English, the model above says: we expect f0 to be normally distributed. The f0 value we expect for any given token is equal to some overall average (<span class="math inline">\(Intercept\)</span>), and some value associated with each the individual speaker (<span class="math inline">\(\alpha_{speaker_{[i]}}\)</span>) who uttered the trial.</p>
<p>We now have another term <span class="math inline">\(\alpha_{speaker}\)</span>, in addition to the intercept. This coefficient is actually a set of coefficients since it has a different value for each speaker (it’s a vector). For each trial, the value of <span class="math inline">\(\alpha_{speaker}\)</span> that should be used will vary based on the value of the vector indicating the speaker for that trial (e.g., <code>w[["speaker"]][i]</code> for some value of <code>i</code>). We will talk more coefficients like these later, we don’t really need to worry about it for now.</p>
<p>The value of <span class="math inline">\(\alpha_{speaker}\)</span> has a different value for each speaker because it will reflect variation in <span class="math inline">\(\mu_{speaker}\)</span>, the average f0 value produced by each speaker. However, <span class="math inline">\(\mu_{speaker}\)</span> is a random variable since it reflects the random average f0 of each person drawn from the population. If <span class="math inline">\(\mu_{speaker}\)</span> behaves like a random variable, then the coefficients that reflect this value in our model (<span class="math inline">\(\alpha_{speaker}\)</span>) will behave in the same way.</p>
<p>This means that actually our model has <em>two</em> random variables. The first one is the error term <span class="math inline">\(\varepsilon_{[i]} \sim \mathcal{N}(0,\sigma_{error})\)</span>, which has a mean of 0 and a standard deviation which we can refer to as <span class="math inline">\(\sigma_{error}\)</span>. The second is the random terms that allows for speaker-specific adjustments to the intercept (<span class="math inline">\(\alpha_{speaker}\)</span>), that can also be thought of as random draw from a normal distribution.</p>
<p>A careful consideration of the model in equation 2.4 suggests that the (<span class="math inline">\(\alpha_{speaker}\)</span>) coefficients can’t actually be exactly equal to <span class="math inline">\(\mu_{speaker}\)</span>, the average f0 for a speaker. If the overall mean (the intercept) is 220 Hz and a speaker’s average is 230, this would suggest a predicted average of 450 (<span class="math inline">\(Intercept + \mu_{speaker}\)</span>) for this speaker. Clearly that is not how the model should be working.</p>
<p>Recall that regression models encode <em>differences</em>, rather than absolute values. Our model already represents the overall data average in the intercept parameter. Thus, the speaker-specific averages only need to contain information about <em>differences</em> to this reference value. As a result, the model parameters for mean f0 across all speakers will be centered at 0 (i.e., the average), and will tend to be normally distributed with a population-specific standard deviation.</p>
<p>Since our model coefficients reflect speaker-specific <em>deviations</em> rather than the actual mean f0 of different speakers, people often use this symbol, <span class="math inline">\(\gamma\)</span>, for them instead of <span class="math inline">\(\mu\)</span>, where <span class="math inline">\(\gamma\)</span> reflects the difference between the speaker means and the mean for the population of speakers, <span class="math inline">\(\gamma_{speaker} = \mu_{speaker} - \mu_{population}\)</span>.</p>
<p>We can show the expected distribution of this variable below, where <span class="math inline">\(\sigma_{speakers}\)</span> is a population-specific standard deviation term. Note the similarity of this to the expected variation in our original data in Equation <a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#eq:24">(2.4)</a>.</p>
<p><span class="math display" id="eq:27">\[\begin{equation}
\begin{split}
\\
\gamma_{speaker} \sim \mathcal{N}(0,\sigma_{speakers}) \\ \\ 
\gamma_{speaker} = \alpha_{speaker} \\ \\
\end{split}
\tag{2.7}
\end{equation}\]</span></p>
<p>Our overall model is now as shown below, made specific for the data we have, and using expected parameter names.</p>
<p><span class="math display" id="eq:28">\[\begin{equation}
\begin{split}
\\
f0_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\ \\
\mu_{[i]} = Intercept + \alpha_{speaker_{[i]}} \\ \\
\alpha_{speaker} \sim \mathcal{N}(0,\sigma_{speakers}) \\ \\
\end{split}
\tag{2.8}
\end{equation}\]</span></p>
<p>Each line in the model says the following:</p>
<ul>
<li><p>observed f0 is expected to be normally distributed around a trial-specific mean, with some unknown but fixed standard deviation (<span class="math inline">\(\sigma_{error}\)</span>).</p></li>
<li><p>the expected value for a given trial (<span class="math inline">\(\mu_{[i]}\)</span>) is equal to the model intercept, plus some speaker-specific deviation/difference from the intercept for the speaker that produced that trial (<span class="math inline">\(\alpha_{speaker_{[i]}}\)</span>).</p></li>
<li><p>the speaker effects (<span class="math inline">\(\alpha_{speaker}\)</span>) are also drawn from a normal distribution with a mean of 0 and a standard deviation of <span class="math inline">\(\sigma_{speakers}\)</span>. This distribution represents the random, but systematic, between-speaker variation in average productions that exists within any population of speakers.</p></li>
</ul>
<p>All of this information can be seen in the speaker boxplots below. The observed error around some unknown mean is what causes there to be a <em>distribution</em> of f0 values around each speaker’s mean. The model intercept (horizontal dotted line) represents the overall mean, and the variation in <span class="math inline">\(\alpha_{speaker}\)</span> is what causes the middle of each little box to differ from the mean.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">1</span>))</span>
<span id="cb86-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (f0 <span class="sc">~</span> speaker, <span class="at">data =</span> w, <span class="at">main =</span> <span class="st">&quot;Speaker Boxplots&quot;</span>,<span class="at">col=</span>cols[<span class="dv">3</span><span class="sc">:</span><span class="dv">6</span>]) </span>
<span id="cb86-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> <span class="fl">220.4</span>,<span class="at">lty=</span><span class="dv">3</span>, <span class="at">lwd=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="02_files/figure-html/unnamed-chunk-13-1.png" width="768" /></p>
<p>There is a very important difference in how the initial and final models we fit view and partition the variation in our model. The initial model we fit viewed the variation in the model like this:</p>
<p><span class="math display" id="eq:29">\[
\sigma_{total} = \sigma_{error}
\tag{2.9}
\]</span></p>
<p>In other words, all variation was error. We don’t know why values vary from the mean. Our multilevel model views the variation in our data like this:</p>
<p><span class="math display" id="eq:210">\[
\sigma_{total} = \sigma_{speaker} + \sigma_{error}
\tag{2.10}
\]</span></p>
<p>It sees only <em>some</em> of the variation in data as error. In terms of the boxplot above, only the variation <em>within</em> a speaker’s box is error. The differences from box to box represent random (but systematic) between-speaker variation in f0. Basically, from the perspective of this multilevel model, the random variation in the data is not all noise/error.</p>
</div>
<div id="fitting-the-model" class="section level3" number="2.4.2">
<h3><span class="header-section-number">2.4.2</span> Fitting the model</h3>
<p>We can fit a model with a formula that appropriately specifies the clustering we expect in our data. As a result, this model can estimate both between- and within-speaker variability.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Fit the model yourself, or</span></span>
<span id="cb87-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb87-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb87-3" aria-hidden="true" tabindex="-1"></a>multilevel_model <span class="ot">=</span>  </span>
<span id="cb87-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb87-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> (<span class="dv">1</span><span class="sc">|</span>speaker), <span class="at">data =</span> w, <span class="at">chains =</span> <span class="dv">1</span>, <span class="at">cores =</span> <span class="dv">1</span>)</span>
<span id="cb87-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb87-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-6"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="do">## download pre-fit model from: </span></span>
<span id="cb87-7"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb87-7" aria-hidden="true" tabindex="-1"></a><span class="do">## github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb87-8"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb87-8" aria-hidden="true" tabindex="-1"></a><span class="do">## and load after placing in working directory</span></span>
<span id="cb87-9"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb87-9" aria-hidden="true" tabindex="-1"></a>multilevel_model <span class="ot">=</span> <span class="fu">readRDS</span> (<span class="st">&quot;2_multilevel_model.RDS&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="do">## inspect model</span></span>
<span id="cb88-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb88-2" aria-hidden="true" tabindex="-1"></a>multilevel_model</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ (1 | uspeaker) 
##    Data: w (Number of observations: 576) 
## Samples: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 1000
## 
## Group-Level Effects: 
## ~uspeaker (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    20.19      2.10    16.65    25.06 1.00      135      192
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.39      3.10   214.49   226.13 1.03       51      108
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    12.54      0.39    11.83    13.34 1.01      400      700
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>This new model contains one new chunk its print statement:</p>
<pre><code>Group-Level Effects: 
~speaker (Number of levels: 48) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)    20.19      2.10    16.65    25.06 1.00      135      192</code></pre>
<p>This sections contains information about the standard deviation of between-speaker averages (<span class="math inline">\(\mu_{speaker}\)</span>) in the sample. We can see that the information provided by <code>brms</code> is quite similar to what we can estimate directly using our data. However, <em>brms</em> does this all for us, in addition to giving us a lot more information.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="do">## find mean f0 for each speaker</span></span>
<span id="cb91-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb91-2" aria-hidden="true" tabindex="-1"></a>speaker_means <span class="ot">=</span> <span class="fu">aggregate</span> (f0 <span class="sc">~</span> speaker, <span class="at">data =</span> w, <span class="at">FUN =</span> mean) </span>
<span id="cb91-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="do">## find the within speaker variance. This is the within-talker &#39;error&#39;.</span></span>
<span id="cb91-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb91-4" aria-hidden="true" tabindex="-1"></a>speaker_vars <span class="ot">=</span> <span class="fu">aggregate</span> (f0 <span class="sc">~</span> speaker, <span class="at">data =</span> w, <span class="at">FUN =</span> var) </span>
<span id="cb91-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb91-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-6"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb91-6" aria-hidden="true" tabindex="-1"></a><span class="do">## the mean of the speaker means corresponds to our overall mean estimate</span></span>
<span id="cb91-7"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb91-7" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span> (speaker_means<span class="sc">$</span>f0)</span></code></pre></div>
<pre><code>## [1] 220.401</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="do">## sd(Intercept) in the model reflects the amount of variation in talker </span></span>
<span id="cb93-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="do">## intercepts. This is the between speaker variation in our model. See how it is </span></span>
<span id="cb93-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="do">## similar to the sd of the actual speaker means.</span></span>
<span id="cb93-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb93-4" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span> (speaker_means<span class="sc">$</span>f0)</span></code></pre></div>
<pre><code>## [1] 20.07397</code></pre>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="do">## sigma in the model reflects the amount of variation in talker intercepts.</span></span>
<span id="cb95-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="do">## This is the between speaker variation in our model. </span></span>
<span id="cb95-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span> (<span class="fu">sd</span> (speaker_vars<span class="sc">$</span>f0))</span></code></pre></div>
<pre><code>## [1] 12.42719</code></pre>
<p>The overall mean f0 in our data (220.4) corresponds quite well to our model estimate of 220.4. This reflects the central location of the overall distribution below (the horizontal line in the figure below). The standard deviation of the speaker means (Intercept = 20.1) is again very similar to our model estimate (sd(Intercept) = 20.1). This reflects the average distance from each speaker’s average, and the overall average. Finally, the average of the within speaker standard deviation in our data (12.4) corresponds closely to our model’s error estimate (sigma = 12.5). This reflects the average spread of each speaker’s data relative to their own mean, within their own little boxplot.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">1</span>))</span>
<span id="cb97-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (f0 <span class="sc">~</span> speaker, <span class="at">data =</span> w, <span class="at">main =</span> <span class="st">&quot;Speaker Boxplots&quot;</span>,<span class="at">col=</span><span class="fu">c</span>(yellow,coral,</span>
<span id="cb97-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb97-3" aria-hidden="true" tabindex="-1"></a>         deepgreen,teal)) </span>
<span id="cb97-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb97-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> <span class="fl">220.4</span>, <span class="at">lwd=</span><span class="dv">3</span>,<span class="at">lty=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="02_files/figure-html/unnamed-chunk-18-1.png" width="768" /></p>
</div>
<div id="simulating-data-using-our-model-parameters" class="section level3" number="2.4.3">
<h3><span class="header-section-number">2.4.3</span> Simulating data using our model parameters</h3>
<p>One way to think about what all these numbers mean is to simulate data that has the same characteristics, and build fake data from component parts.</p>
<p>First there is an intercept equal to 220.4 Hz. Then, I create effects representing 48 simulated ‘female talkers’ from a population just like our observed population. These effects are stored in a vector called <code>alpha_speaker</code>, and they represent the values of <span class="math inline">\(\alpha_{speaker}\)</span> for our different speakers. These speaker effects come from a population with a mean of 0 and a standard deviation (<span class="math inline">\(\sigma_{speaker}\)</span>) equal to 20.4 (like our data). Each of these simulated speakers produces 12 productions, and so we need a <code>speakers</code> vector with values that repeat 12 times each to index the <code>alpha_speaker</code> vector containing the effects.</p>
<p>I also draw our error, <span class="math inline">\(\varepsilon\)</span>. This error comes from a distribution with a mean of 0 and a standard deviation equal to <span class="math inline">\(\sigma_{error}\)</span>. It’s important to note that the error is just 48x12 random draws from this population. There is no distinction between one person’s productions and another when it comes to the error. If there were, this would indicate differences in sigma between speakers! Our model assumes a single error population for all speakers (but it doesn’t <em>have</em> to be this way).</p>
<p>After creating our components, we add the Intercept, speaker deflections and random error to make our face ‘replicated’ data. Since this data has the same statistical properties, it should look a lot like our real data.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="do">## don&#39;t run this line if you want a new simulated dataset. </span></span>
<span id="cb98-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5</span>)</span>
<span id="cb98-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="do">## this is the value of our intercept</span></span>
<span id="cb98-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-4" aria-hidden="true" tabindex="-1"></a>Intercept <span class="ot">=</span> <span class="fl">220.4</span></span>
<span id="cb98-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-5" aria-hidden="true" tabindex="-1"></a><span class="do">## this is a vector of 48 speaker effects</span></span>
<span id="cb98-6"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-6" aria-hidden="true" tabindex="-1"></a>alpha_speaker <span class="ot">=</span> <span class="fu">rnorm</span> (<span class="dv">48</span>, <span class="dv">0</span>, <span class="fl">20.2</span>)</span>
<span id="cb98-7"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-7" aria-hidden="true" tabindex="-1"></a><span class="do">## this is a vector indicating which speaker produced which utterance</span></span>
<span id="cb98-8"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-8" aria-hidden="true" tabindex="-1"></a>speaker <span class="ot">=</span> <span class="fu">rep</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">48</span>, <span class="at">each =</span> <span class="dv">12</span>)</span>
<span id="cb98-9"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-9" aria-hidden="true" tabindex="-1"></a><span class="do">## this vector contains the error</span></span>
<span id="cb98-10"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-10" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">=</span> <span class="fu">rnorm</span> (<span class="dv">48</span> <span class="sc">*</span> <span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">12.5</span>)</span>
<span id="cb98-11"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-11" aria-hidden="true" tabindex="-1"></a><span class="do">## the sum of the above components equals our observations</span></span>
<span id="cb98-12"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb98-12" aria-hidden="true" tabindex="-1"></a>f0_rep <span class="ot">=</span> Intercept <span class="sc">+</span> alpha_speaker[speaker] <span class="sc">+</span> epsilon</span></code></pre></div>
<p>Below I compare the results of our simulation to our real data. If you didn’t have a clear impression of what the data looked like, I doubt you could tell which is the real data. This tells us our model is a good reflection of the data!</p>
<div class="figure"><span id="fig:unnamed-chunk-20"></span>
<img src="02_files/figure-html/unnamed-chunk-20-1.png" alt="Comparison of real and simulated f0 production data." width="672" />
<p class="caption">
Figure 2.1: Comparison of real and simulated f0 production data.
</p>
</div>
<p>Below I make two datasets that are ‘incomplete’: the first contains the intercept and noise only, the second contains the intercept and speaker effects only.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb99-1" aria-hidden="true" tabindex="-1"></a>f0_rep_1 <span class="ot">=</span> Intercept <span class="sc">+</span> epsilon</span>
<span id="cb99-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb99-2" aria-hidden="true" tabindex="-1"></a>f0_rep_2 <span class="ot">=</span> Intercept <span class="sc">+</span> alpha_speaker[speaker]</span></code></pre></div>
<p>In the figure below, I compare these ‘incomplete’ datasets to the full simulated data. The top row contains only error (<span class="math inline">\(\varepsilon, \sigma_{error}\)</span>). As a result, f0 varies around the intercept, but there is no speaker to speaker variation. Notice that each little box is not centered at 0. Although the error distribution is centered at 0, the small number of errors added to the speaker mean are <strong>extremely</strong> unlikely to add up to 0. This makes estimations of the <em>real</em> speaker effect impossible in practice.</p>
<p>In the middle plot, the figure shows only between-speaker variation (<span class="math inline">\(\alpha_{speaker}, \sigma_{speaker}\)</span>) but no within-speaker variation (i.e., no noise/error). Now we see that speakers vary from the intercept, but this representation does not show the fact that speakers also vary relative to their own average.</p>
<p>The final plot is the combination of the variation in the top two figures. The final plot shows the simulated data: the sum of the intercept, the within speaker variation and the between-speaker variation reflected in the values of the speaker intercepts.</p>
<div class="figure"><span id="fig:unnamed-chunk-22"></span>
<img src="02_files/figure-html/unnamed-chunk-22-1.png" alt="(top) Simulated error variation around the intercept. (middle) Simulated between-speaker variation, but no production error. (bottom) Simulated data containing both within and between-speaker variation in f0." width="672" />
<p class="caption">
Figure 2.2: (top) Simulated error variation around the intercept. (middle) Simulated between-speaker variation, but no production error. (bottom) Simulated data containing both within and between-speaker variation in f0.
</p>
</div>
</div>
</div>
<div id="checking-model-convergence" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Checking model convergence</h2>
<p>Remember that our model parameter estimates consist of a set of samples from the posterior distribution of a parameter. If we don’t take enough of these samples, our parameter estimates will be unreliable.</p>
<p>For this reason, it’s important to look at the ESS values (the ‘expected sample size’), and the ‘Rhat’ values provided by <code>brm</code>. ESS tells you about how many independent samples you have taken from the likelihood. Bulk ESS is how many samples the sampler took in the thick part of the density, and Tail ESS reflects how much time the sampler spent in the thin part, the ‘tails’. Rhat tells you about whether your ‘chains’ have converged (more on this later). As noted above, values of Rhat near 1 are good, and values higher than around 1.1 are a bad sign.</p>
<p>We haven’t really taken many samples here, so we can’t be confident in our parameter estimates. Ideally we would like several hundred samples (at least) for mean estimates, and thousands to be confident in the 95% confidence intervals. If you fit a model and get a warning message like this:</p>
<pre><code>Warning messages:
1: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
http://mc-stan.org/misc/warnings.html#bulk-ess
2: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
http://mc-stan.org/misc/warnings.html#tail-ess</code></pre>
<p>That is <code>brms</code> telling you that you need to collect more samples in order to be confident in your parameter estimates. To get more samples we can run the model longer, or we can use more <em>chains</em>. A chain is basically a separate set of samples for your parameter values. Just imagine you had estimated the model 4 times in a row and mixed your estimations. A model can be fit in parallel across several chains, and then the estimates can be merged across chains. When you do this across multiple cores, you can get N times as many samples when you use N cores. Since many computers these days have 4-8 (or more) cores, we can take advantage of parallel processing to fit models faster.</p>
<p>Before fitting a model across multiple cores, you should confirm how many you have. You can use the following commend (you may need to install the <code>parallel</code> package):</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb101-1" aria-hidden="true" tabindex="-1"></a>parallel<span class="sc">::</span><span class="fu">detectCores</span>()</span></code></pre></div>
<p>I will be using four cores to fit models throughout. If you only have 4 total cores, consider changing the model fits to 2-3 chains and cores. However, one thing to keep in mind is that these models are computationally intensive to fit. As the datasets become larger and the models become more complicated, more powerful computers are needed in order to fit a model in a reasonable amount of time.</p>
<p>Below, I refit the same model from above but run it on 4 chains, and on 4 cores at once. This doesn’t take any longer but it does give us a higher ESS. Just make sure you leave a couple of cores free on your computer when you fit a model!</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Fit the model yourself, or</span></span>
<span id="cb102-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb102-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-3" aria-hidden="true" tabindex="-1"></a>multilevel_multicore <span class="ot">=</span>  </span>
<span id="cb102-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-4" aria-hidden="true" tabindex="-1"></a>  brms<span class="sc">::</span><span class="fu">brm</span> (f0 <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>speaker), <span class="at">data =</span> w, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>)</span>
<span id="cb102-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-6"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-6" aria-hidden="true" tabindex="-1"></a><span class="do">## download pre-fit model from: </span></span>
<span id="cb102-7"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-7" aria-hidden="true" tabindex="-1"></a><span class="do">## github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb102-8"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-8" aria-hidden="true" tabindex="-1"></a><span class="do">## and load after placing in working directory</span></span>
<span id="cb102-9"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-9" aria-hidden="true" tabindex="-1"></a>multilevel_multicore <span class="ot">=</span> <span class="fu">readRDS</span> (<span class="st">&#39;2_multilevel_multicore.RDS&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="do">## inspect model</span></span>
<span id="cb103-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb103-2" aria-hidden="true" tabindex="-1"></a>multilevel_multicore</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 + (1 | uspeaker) 
##    Data: w (Number of observations: 576) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~uspeaker (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    20.22      2.19    16.54    25.19 1.02      345      615
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.47      2.91   214.67   226.14 1.02      228      543
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    12.54      0.39    11.81    13.34 1.00     3427     2943
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>If we compare the ESS for this new model to the previous model, we see that using 4 chains has substantially increased our ESS, without taking up any more computing time.</p>
<p>One final tweak that I will be using going forward is to ‘thin’ samples. Notice that we have collected ‘total post-warmup samples = 4000’. This means our model has 4000 samples for every parameter in the model. However, we have only about 400 ‘effective samples’ to show for it for some parameters of interest. This means that a lot of our samples are basically dead weight, taking up space and slowing down computations for no good reason.</p>
<p>Sometimes consecutive samples can be too similar and so don’t given you that much independent information. A way to fix this is to run longer chains and keep only every nth one. This lets your models be smaller while containing approximately the same information.</p>
<p>To do this you have to set the <code>iter</code>, <code>warmup</code> and <code>thin</code> parameters. You will keep every sample after the warmup is done, up to the <code>iter</code> maximum. So if <code>iter=3000</code> and <code>warmup=1000</code> you will end up with 2000 samples. After this, you keep only one every <code>thin</code> samples. Basically, you will end up with <span class="math inline">\((iter-warmup) / thin\)</span> samples per chain.</p>
<p>Below, I ask for 11,000 sample per chain, 10,000 post warm-up. However, since I plan to keep only 1/10, I will have 1000 per core, so 4000 samples in total. However, despite having the same number of samples as the <code>multilevel_multicore</code>, the ESS for this model is much higher for important parameters such as the model intercept.</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Fit the model yourself, or</span></span>
<span id="cb105-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb105-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-3" aria-hidden="true" tabindex="-1"></a>multilevel_thinned <span class="ot">=</span>  </span>
<span id="cb105-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>speaker), <span class="at">data =</span> w, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>,</span>
<span id="cb105-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">11000</span>, <span class="at">thin =</span> <span class="dv">10</span>)</span>
<span id="cb105-6"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-7"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-7" aria-hidden="true" tabindex="-1"></a><span class="do">## download pre-fit model from: </span></span>
<span id="cb105-8"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-8" aria-hidden="true" tabindex="-1"></a><span class="do">## github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb105-9"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-9" aria-hidden="true" tabindex="-1"></a><span class="do">## and load after placing in working directory</span></span>
<span id="cb105-10"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-10" aria-hidden="true" tabindex="-1"></a>multilevel_thinned <span class="ot">=</span> <span class="fu">readRDS</span> (<span class="st">&#39;2_multilevel_thinned.RDS&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="do">## inspect model</span></span>
<span id="cb106-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb106-2" aria-hidden="true" tabindex="-1"></a>multilevel_thinned</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 + (1 | uspeaker) 
##    Data: w (Number of observations: 576) 
## Samples: 4 chains, each with iter = 11000; warmup = 1000; thin = 10;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~uspeaker (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    20.06      2.23    16.24    24.98 1.00     2775     3392
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.40      2.95   214.57   226.19 1.00     1987     2625
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    12.54      0.38    11.81    13.31 1.00     3908     3891
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<div id="specifying-prior-probabilities" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> Specifying prior probabilities</h2>
<p>In Chapter 1 we discussed that Bayesian models require that prior probabilities be specified for all parameters. You may have noticed that to this point I haven’t discussed priors at all.</p>
<p>If you don’t specify prior probabilities for your parameters, <code>brm</code> will use a ‘flat’ prior for all parameters. When you do this, you are basically relying only on the likelihood for your analysis. You are also telling your model that, a priori, <em>any</em> value of average f0 is equally believable. Empirically, this is false. As a practical matter this can cause problems for samplers like <code>brm</code> (STAN actually). Basically, the sampler has a harder time figuring out the most likely values when you tell it to look anywhere from positive to negative infinity. Even a bit of guidance can help.</p>
<p><code>brms</code> makes it really easy to specify prior probabilities for specific parameters or whole groups of parameters. First we figure out the overall mean and the standard deviation of the data.</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(f0)</span></code></pre></div>
<pre><code>## [1] 220.401</code></pre>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(f0)</span></code></pre></div>
<pre><code>## [1] 23.22069</code></pre>
<p>In the example below, I use this information to set reasonable bounds on the parameters in the model. I do this by class of parameter:</p>
<ul>
<li>Intercept: this is a unique class, only for intercepts.</li>
<li>b: this is for all the non-intercept predictors. There are none in this model.</li>
<li>sd: this is for all standard deviation parameters. In our example this is <code>sd(Intercept)</code> for <code>speaker</code> (<span class="math inline">\(\sigma_{speakers}\)</span>), and <code>sigma</code> (<span class="math inline">\(\sigma_{error}\)</span>).</li>
</ul>
<p>Both priors below use a ‘t’ distribution, which is just like a normal distribution but it is more pointy, and has more density in the outer parts of the distribution. I use this because it has good properties, but you can use normal priors, or any other priors that you think work for your model. Rather than focusing on the mathematical properties of priors, the most important thing is that their <em>shape</em> reflect the distribution of credible parameter values a priori (before you conducted your experiment).</p>
<p>The format for the priors looks like this <code>student_t(nu, mean, sd)</code>, where <code>nu</code> is a parameter that determines how pointy the distribution is, and <code>mean</code> and <code>sd</code> are the same mean and standard deviation parameters from the normal distribution. The nu parameter ranges from 1 to infinity, and large numbers result in a more normal-like distribution.</p>
<p>So, for the overall intercept (<span class="math inline">\(\mu_{overall}\)</span>) I am using a prior with the same mean as the data mean, and a standard deviation that is twice as large as the data standard deviation. For both the model standard deviation terms (<span class="math inline">\(\sigma_{error}, \sigma_{speaker}\)</span>) I am using a t distribution centered at 0 (explained below), with a standard deviation twice as large as the data standard deviation.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Fit the model yourself, or</span></span>
<span id="cb112-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb112-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-3" aria-hidden="true" tabindex="-1"></a>multilevel_priors <span class="ot">=</span>  </span>
<span id="cb112-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>speaker), <span class="at">data =</span> w, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>,</span>
<span id="cb112-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">11000</span>, <span class="at">thin =</span> <span class="dv">10</span>,</span>
<span id="cb112-6"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 220.4, 46.4)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb112-7"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-7" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 46.4)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sd&quot;</span>)))</span>
<span id="cb112-8"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-9"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-9" aria-hidden="true" tabindex="-1"></a><span class="do">## download pre-fit model from: </span></span>
<span id="cb112-10"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-10" aria-hidden="true" tabindex="-1"></a><span class="do">## github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb112-11"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-11" aria-hidden="true" tabindex="-1"></a><span class="do">## and load after placing in working directory</span></span>
<span id="cb112-12"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-12" aria-hidden="true" tabindex="-1"></a>multilevel_priors <span class="ot">=</span> <span class="fu">readRDS</span> (<span class="st">&#39;2_multilevel_priors.RDS&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="do">## inspect model</span></span>
<span id="cb113-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb113-2" aria-hidden="true" tabindex="-1"></a>multilevel_priors</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 + (1 | uspeaker) 
##    Data: w (Number of observations: 576) 
## Samples: 4 chains, each with iter = 11000; warmup = 1000; thin = 10;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~uspeaker (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    20.19      2.24    16.29    25.06 1.00     3114     3663
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.42      2.97   214.44   226.38 1.00     1796     2841
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    12.54      0.39    11.81    13.34 1.00     3968     3972
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>In the left panel below (plot code at end of chapter) I compare the t distribution we used (blue) to the equivalent normal distribution (red). It is clear that the t distribution can tolerate more extreme values because of its ‘fatter’ tails. As we will discuss later, using t distributions can make our models more robust to outliers. This is really important in linguistics where subjects/speakers sometimes do weird stuff!</p>
<p>In the middle panel we compare this prior to the data, and see that the prior distribution is much broader (more vague) than the data distribution. The right panel compares the prior for the standard deviation parameters to the absolute value of the centered f0 data. This presentation shows how far each observation is from the mean f0 (at 220 Hz). Again, the prior distribution we have assigned for these parameters is much larger than the variation in the data. As a result, neither of these priors is going to have much of an effect on our parameter estimates.</p>
<p><img src="02_files/figure-html/unnamed-chunk-34-1.png" width="768" /></p>
<p>If we compare the output of this model to <code>multilevel_thinned</code>, we see that specifying a prior has has no noticeable effect on our results. This is because the prior matters less and less when you have a lot of data, and because we have set wide priors that are appropriate (but vague) given our data. Although the priors may not matter much for models as simple as these, they can be very important when working with more complex data, and are a necessary component of Bayesian modeling.</p>
</div>
<div id="answering-our-research-questions" class="section level2" number="2.7">
<h2><span class="header-section-number">2.7</span> Answering our research questions</h2>
<p>Let’s return again to the research questions I posed initially:</p>
<ol style="list-style-type: decimal">
<li><p>What is the average f0 of the whole <em>population</em> likely to be?</p></li>
<li><p>Can we set bounds on likely mean f0 values based on the data we collected?</p></li>
</ol>
<p>And we can compare the answers provided to this question by our initial and final models.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb115-1" aria-hidden="true" tabindex="-1"></a>model</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 
##    Data: w (Number of observations: 576) 
## Samples: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 1000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.40      0.97   218.33   222.30 1.00      851      557
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    23.24      0.69    21.99    24.61 1.00      653      550
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb117-1" aria-hidden="true" tabindex="-1"></a>multilevel_priors</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 + (1 | uspeaker) 
##    Data: w (Number of observations: 576) 
## Samples: 4 chains, each with iter = 11000; warmup = 1000; thin = 10;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~uspeaker (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    20.19      2.24    16.29    25.06 1.00     3114     3663
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.42      2.97   214.44   226.38 1.00     1796     2841
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    12.54      0.39    11.81    13.34 1.00     3968     3972
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Our initial model (<code>model</code>) and our final model (<code>multilevel_priors</code>) agree on what the average f0 is. However, they disagree on a credible interval for that parameter. Our initial model did not specify information about repeated measures. This causes our model to think that it has more independent observations than it does, and so it returns an overly-precise estimate.</p>
<p>Another difference is that the final model has a much smaller <code>sigma</code> parameter (12.5 vs 23.2). This indicates that the error (<span class="math inline">\(\varepsilon\)</span>) is much smaller in the final model than in the initial model. Keep in mind that ‘error’ is just what your model can’t explain. Our final model explains much more and so there is less error. The reduced error is a direct result of the fact that the final model splits random variation up into between-speaker and within-speaker components, estimating the between-speaker variation (<span class="math inline">\(sigma_{speaker}\)</span>) to be about 20 Hz.</p>
<p>Usually, when I report parameters I provide the mean and standard deviations of the posterior distribution, in addition to the bounds of the 95% credible interval of the parameter. Based on the result of our final model, I think a thorough description of the general properties of our data might go something like:</p>
<blockquote>
<p>"Based on our model the average f0 produced by adult females in Michigan is likely to be 220 Hz (s.d. = 2.97, 95% CI = 214.4, 226.4). However, consistent between-speaker variation averages about 20 Hz (s.d. = 2.24, 95% CI = 16.29, 25.06), meaning that we can expect the average f0 produced by individuals to deviate substantially from 220 Hz. Finally, the standard deviation of production error was about 12.5 Hz (s.d. = 0.39, 95% CI = 11.81, 13.34) indicating that the amount of random within-speaker variation in production is about half the magnitude of the systematic between-speaker differences in f0.</p>
</blockquote>
<p>I’m again including the speaker boxplots below because I think this image basically presents the same information as the paragraph above, but in visual form. In general, any data relationship or result can be presented in a figure, and the relationships presented in a figure can also be expressed as a mathematical model.</p>
<p>When you are thinking about the relationships in your data, or that you expect in your data, its a good idea to think: what kind of picture could illustrate this relationship? Conversely, if you see a figure of your results that you feel really expresses something interesting about your data you should think, how can these relationships be represented in a model?</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">1</span>))</span>
<span id="cb119-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb119-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (f0 <span class="sc">~</span> speaker, <span class="at">data =</span> w, <span class="at">main =</span> <span class="st">&quot;Speaker Boxplots&quot;</span>,<span class="at">col=</span><span class="fu">c</span>(yellow,coral,</span>
<span id="cb119-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb119-3" aria-hidden="true" tabindex="-1"></a>         deepgreen,teal)) </span>
<span id="cb119-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb119-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> <span class="fl">220.4</span>, <span class="at">lwd=</span><span class="dv">3</span>,<span class="at">lty=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="02_files/figure-html/unnamed-chunk-36-1.png" width="768" /></p>
</div>
<div id="lmer-corner" class="section level2" number="2.8">
<h2><span class="header-section-number">2.8</span> Lmer corner</h2>
<p>Here I compare the output of <code>brms</code> to the output of the <code>lmer</code> (“linear mixed-effects regression”) function, a very popular function for fitting multilevel models in the lme4 R package. I am not going to talk about the traditional models in any detail. The focus of this section is simply to highlight the potential similarities between different approaches, and to point out where to find this information. This will mostly be useful to people familiar with the traditional approaches!</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (lme4)</span>
<span id="cb120-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb120-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-3" aria-hidden="true" tabindex="-1"></a>lmer_model <span class="ot">=</span>  </span>
<span id="cb120-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lmer</span> (f0 <span class="sc">~</span> (<span class="dv">1</span><span class="sc">|</span>speaker), <span class="at">data =</span> w)</span>
<span id="cb120-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span> (lmer_model)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: f0 ~ (1 | speaker)
##    Data: w
## 
## REML criterion at convergence: 4705.8
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.3792 -0.5962 -0.1005  0.4771  3.9273 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  speaker  (Intercept) 389.9    19.75   
##  Residual             156.8    12.52   
## Number of obs: 576, groups:  speaker, 48
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  220.401      2.897   76.07</code></pre>
<p>The print statement for our <code>lmer</code> model is above. In terms of model structure, this a model is just like our <code>multilevel_priors</code> model. I am going to do a line by line comparison of the <code>lmer</code> output above, and show the same information presented in our <code>brm</code> model print statement. The very top lines:</p>
<pre><code>Linear mixed model fit by REML [&#39;lmerMod&#39;]
Formula: f0 ~ (1 | speaker)
   Data: w</code></pre>
<p>are basic information about data and model structure, equivalent to these lines in <code>brms</code>:</p>
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: f0 ~ 1 + (1 | uspeaker) 
   Data: w (Number of observations: 576) 
Samples: 4 chains, each with iter = 11000; warmup = 1000; thin = 10;
         total post-warmup samples = 4000</code></pre>
<p>the next lines in the <code>lmer</code> output are about the model fit and not usually of much direct interest.</p>
<pre><code>REML criterion at convergence: 4705.8
Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-4.3792 -0.5962 -0.1005  0.4771  3.9273 </code></pre>
<p>the next lines talk about our random effects. <code>lmer</code> groups together the random error (<code>Residual</code>) and the random, between-speaker intercepts (<code>speaker  (Intercept)</code>).</p>
<pre><code>Random effects:
 Groups   Name        Variance Std.Dev.
 speaker  (Intercept) 389.9    19.75   
 Residual             156.8    12.52   
Number of obs: 576, groups:  speaker, 48</code></pre>
<p>We can find the standard deviation for our by-speaker intercepts in these lines in <code>brms</code>. Notice that in addition to a ‘point estimate’ of the most probable posterior estimates, we get a credible interval for this parameter.</p>
<pre><code>Group-Level Effects: 
~uspeaker (Number of levels: 48) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)    20.19      2.24    16.29    25.06 1.00     3114     3663</code></pre>
<p>Information about the ‘residual’ (or error) is presented in these lines in <code>brms</code>. Again, notice that <code>brms</code> returns credible intervals for this parameter rather than just a point estimate.</p>
<pre><code>Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    12.54      0.39    11.81    13.34 1.00     3968     3972</code></pre>
<p>Finally, the fixed effects in <code>lmer</code>:</p>
<pre><code>Fixed effects:
            Estimate Std. Error t value
(Intercept)  220.401      2.897   76.07</code></pre>
<p>Correspond to the ‘Population-Level’ parameters in <code>brms</code>:</p>
<pre><code>Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   220.42      2.97   214.44   226.38 1.00     1796     2841</code></pre>
<p>In each case, you can see a close correspondence between the two sets of estimates.</p>
</div>
<div id="plot-code-1" class="section level2" number="2.9">
<h2><span class="header-section-number">2.9</span> Plot Code</h2>
<p>%<code>{r get-labels, echo = FALSE} %labs = knitr::all_labels() %labs = setdiff(labs, c("setup", "get-labels")) %</code></p>
<p>%```{r ch2-code, ref.label=labs, eval=FALSE}</p>
<p>%```</p>
<p>Plot for comparison of prior distributions with f0 data</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get t density</span></span>
<span id="cb130-2"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">seq</span> (<span class="sc">-</span><span class="dv">4</span>,<span class="dv">4</span>,.<span class="dv">1</span>)</span>
<span id="cb130-3"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-3" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">=</span> <span class="fu">dt</span> (x1, <span class="dv">3</span>); y1 <span class="ot">=</span> y1 <span class="sc">/</span> <span class="fu">max</span> (y1) <span class="sc">/</span> <span class="dv">50</span></span>
<span id="cb130-4"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-4" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="dv">220</span><span class="sc">+</span>(x1<span class="sc">*</span><span class="fl">46.4</span>)</span>
<span id="cb130-5"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-5" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">=</span> <span class="fu">dnorm</span> (x2, <span class="dv">220</span>, <span class="fl">46.4</span>); y2 <span class="ot">=</span> y2 <span class="sc">/</span> <span class="fu">max</span> (y2) <span class="sc">/</span> <span class="dv">50</span></span>
<span id="cb130-6"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-7"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-7" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb130-8"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-8" aria-hidden="true" tabindex="-1"></a><span class="do">## plot t</span></span>
<span id="cb130-9"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (x2, y1, <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">ylab =</span> <span class="st">&#39;Density&#39;</span>, <span class="at">xlab =</span> <span class="st">&#39;f0&#39;</span>, <span class="at">col =</span> <span class="dv">4</span>)</span>
<span id="cb130-10"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-10" aria-hidden="true" tabindex="-1"></a><span class="do">## compare to equivalent normal</span></span>
<span id="cb130-11"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-11" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span> (x2, y2, <span class="at">lwd=</span><span class="dv">2</span>,<span class="at">col=</span><span class="dv">2</span>)</span>
<span id="cb130-12"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-13"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-13" aria-hidden="true" tabindex="-1"></a><span class="do">## plot t</span></span>
<span id="cb130-14"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (x2, y1, <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">ylab =</span> <span class="st">&#39;Density&#39;</span>, <span class="at">xlab =</span> <span class="st">&#39;f0&#39;</span>, <span class="at">col =</span> <span class="dv">4</span>)</span>
<span id="cb130-15"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-15" aria-hidden="true" tabindex="-1"></a><span class="do">## compare to equivalent normal</span></span>
<span id="cb130-16"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-16" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (f0, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">freq =</span> <span class="cn">FALSE</span>)</span>
<span id="cb130-17"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-18"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-18" aria-hidden="true" tabindex="-1"></a><span class="do">## plot prior for standard deviations</span></span>
<span id="cb130-19"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-19" aria-hidden="true" tabindex="-1"></a>x3 <span class="ot">=</span> x2 <span class="sc">-</span> <span class="fu">mean</span> (x2)</span>
<span id="cb130-20"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-20" aria-hidden="true" tabindex="-1"></a>y3 <span class="ot">=</span> <span class="fu">dt</span> (x1, <span class="dv">3</span>); y3 <span class="ot">=</span> y3 <span class="sc">/</span> <span class="fu">max</span> (y3) <span class="sc">/</span> <span class="dv">20</span></span>
<span id="cb130-21"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (x3[x3<span class="sc">&gt;</span><span class="dv">0</span>], y3[x3<span class="sc">&gt;</span><span class="dv">0</span>], <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">ylab =</span> <span class="st">&#39;Density&#39;</span>, </span>
<span id="cb130-22"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-22" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&#39;f0&#39;</span>, <span class="at">col =</span> <span class="dv">4</span>)</span>
<span id="cb130-23"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb130-23" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (<span class="fu">abs</span> (f0 <span class="sc">-</span> <span class="fu">mean</span> (f0)), <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">freq =</span> <span class="cn">FALSE</span>)</span></code></pre></div>

</div>
</div>
<!-- Default Statcounter code for statsbook
https://santiagobarreda.github.io/stats-class/ -->
<script type="text/javascript">
var sc_project=12454226; 
var sc_invisible=1; 
var sc_security="a1959418"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12454226/0/a1959418/1/"
alt="Web Analytics"></a></div></noscript>
<!-- End of Statcounter Code -->
            </section>

          </div>
        </div>
      </div>
<a href="inspecting-a-single-group-of-observations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="comparing-two-groups-of-observations.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
