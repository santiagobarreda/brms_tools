[["comparing-many-groups-anova-and-interactions.html", "Chapter 4 Comparing many groups: ANOVA and interactions 4.1 Data and research questions 4.2 Comparing four (or any number of) groups 4.3 Investigating many factors simultaneously: Analysis of Variance 4.4 Investigating model fit 4.5 Interactions and interaction plots 4.6 Investigating interactions with a model 4.7 Frequentist corner 4.8 Exercises", " Chapter 4 Comparing many groups: ANOVA and interactions Last chapter we talked about comparing two groups. Although the comparison of two groups is very simple, it also comes up often. In addition, more complicated problems are often broken down into several two-group questions. However, most real-world research designs dont usually begin as two-group questions. In this chapter, were going to talk about the comparison of multiple groups of observations/speakers. In terms of model design concepts, last chapter introduced the notion of factors and coding. In this chapter, were going to discuss how to build models with multiple factors, and how to allow these factors to interact in our models. 4.1 Data and research questions First, were going to discuss models that compare observations across any number of groups (levels) for a single factor. These designs have just one predictor factor but it can have any number of levels. Although it is not very common to have a design that only consists of a multi-group comparison, the inclusion of multi-group comparisons is ubiquitous in linguistics. Examples of predictors with multiple levels are vowel phonemes, language, word classes, and ages. In addition, the manipulations linguists carry out in their experiments can vary across more than two groups. For example, consider the example of the experiment investigating coffee in reading speed. We can continue discussing the hypothetical example of the reading experiment presented in Chapter 3. Subjects are asked to drink either a cup of water or a cup of coffee. After a 15-minute wait they are asked to read a passage aloud and the duration of the reading is measured. We might have 3 coffee groups rather than one, and vary the dosage of coffee between groups. Although the dose of coffee can be measured numerically, we could still treat this as a factor called drink with levels water, coffee100ml, coffee200ml, and coffee300ml. Lets imagine that subjects were also divided into groups of male and female speakers. This design results in four different groups (2x2). These groups have an internal structure that our model does not recognize. What I mean by this is that half your groups are caffeine groups, but your model does not know this, and as a result it does not directly estimate any effects related to this. However, we will ignore this issue for now. In the first example we see the within-subjects version of this design where each subject is tested at each level of \\(A\\). Next, we see the between-subjects version of the design. Clearly, this is just a simple extrapolation of the sorts of designs presented in Chapter 2. Figure 4.1: Data from a single group of subjects (S) divided according to a single grouping factor A. To analyze data like this, you should have it in a dataframe with one row for each observation. Then, one column should contain the dependent variable, the variable whose variation youre trying to predict. Another column should contain information about which group each observation belongs to (the factor). Were going to keep working with the Hillenbrand et al.Â data, that we have been discussing in every chapter to this point. This time were going to work with all four groups of speakers: b (boys), g (girls), m (men), and w (women). # load brms library (brms) # load data from course website url1 = &quot;https://raw.githubusercontent.com/santiagobarreda/stats-class/master/data/&quot; h95 = read.csv (url(paste0 (url1, &quot;03_h95_vowel_data.csv&quot;))) Our potential research questions are substantially more complicated than in the two-group case. First, there are four groups now, meaning we could potentially make 6 2-group comparisons. Second, the groups differ along multiple dimensions, making it more difficult to make two-group comparisons that ask one single question. For example, the man and girl groups differ according to adultness and gender. How could we know what part of their f0 difference we should attribute to adultness and what part we should attribute to maleness? Figure 4.2: (left) Comparison of the four groups (middle) Comparison of productions based on whether the speaker is an adult (right) Comparison of all productions based on whether the speaker is male. We can consider our data in several ways: as four independent groups, or as two 2-groups comparisons (adult vs child, female vs male). Were going to focus on the 4-way comparison first, and later talk about models that make multiple comparisons simultaneously. Figure 4.3: (left) Boxplots presenting each speakers production of f0 for boys (red), girls (yellow), men (green), and women (teal). (right) Densities of the overall distributions for each group. 4.1.1 Factors as batches effects R treats nominal, categorical predictors as factors and assumes that each different label is a different group. Each group of a factor is called a level. Actually, weve been using factors all along because our speaker predictor is a factor and the individual participants are levels! As far as our models are concerned, participant/speaker/subject has no special status as a predictor and it is just a factor with many levels. When you have groups in your model that are thematically related, you can batch them together in a factor. For example you may have 4 groups of speakers based on native language. You can treat these four groups as levels of a factor. Implicitly, this tells your model that these four groups are related somehow. You know that they are related by being first language groups. However, keep in mind your model knows next to nothing. Actually, the way you tell your model that these groups are related is precisely by treating them as levels of the same factor rather than as unrelated groups. For example, the same speakers might be divided into women and men. This would introduce two new levels into our design. However, should we just through men and women into the language factor: Italians, Germans, English, Russians, Men and Women? We could definitely do this, no one ill stop us. But this doesnt make much sense. Instead, it makes sense to split these groups into two batches of levels: one factor with four language levels, and one factor with two gender levels. A factor is actually a data type in R. Its basically the same as a vector of words (or numbers!), but it has some additional properties that are useful. For example, consider our group predictor, which tells us which group each speaker falls into. Initially it is a character vector. We see that the first few tokens are produced by men (m), and that there is no numerical value associated with these letter labels. The unique function returns all unique labels in the vector, in the order that they appear in the vector. # see the first 6 observations head (h95$group) ## [1] &quot;b&quot; &quot;b&quot; &quot;b&quot; &quot;b&quot; &quot;b&quot; &quot;b&quot; # class starts as a character vector class (h95$group) ## [1] &quot;character&quot; # no numerical values head (as.numeric (h95$group)) ## Warning in head(as.numeric(h95$group)): NAs introduced by coercion ## [1] NA NA NA NA NA NA # we can see the number of unique groups unique (h95$group) ## [1] &quot;b&quot; &quot;g&quot; &quot;m&quot; &quot;w&quot; We can turn the character vector group into a factor vector group_f. The benefit of this is that these nominal labels now have an inherent ordering, and associated numerical values. R functions such as brm turn your nominal (non-numeric) predictors into factors in the process of fitting the model. Doing this yourself gives you control over how they will be handled. # we can turn it into a factor in R h95$group_f = factor(h95$group) # now it has official levels levels(h95$group_f) ## [1] &quot;b&quot; &quot;g&quot; &quot;m&quot; &quot;w&quot; # now it has nuerical values head (as.numeric (h95$group_f)) ## [1] 1 1 1 1 1 1 By default factor levels are ordered alphabetically. This means that if we are using sum coding we omit the w parameter (the last group) and if we are using treatment coding, the intercept will be equal to m (the first group). You can control this behavior by re-ordering the factor levels as below: h95$group_f2 = factor (h95$group_f, levels = c(&#39;w&#39;,&#39;m&#39;,&#39;g&#39;,&#39;b&#39;)) levels (h95$group_f2) ## [1] &quot;w&quot; &quot;m&quot; &quot;g&quot; &quot;b&quot; # note that &#39;m&#39; is now the second category head (as.numeric (h95$group_f2)) ## [1] 4 4 4 4 4 4 After this reordering, we would omit the (last) b parameter under sum coding, and under treatment coding the first group (w) would be equal to the intercept. In general, representing all groups requires about one variable per group. Our single predictor, group, has four levels: b,g,m, and w. For models where the predictor is a factor with more than two levels, we can represent the predictor in a vector like this, \\(group_{[i]}\\), where \\(i\\) is a counter variable that goes from 1 to the number of groups. So the group effects can be represented in a vector as below, representing the effects (deviations from the intercept) for boys, girls, men and women: c(30, 32, -75, 13) ## [1] 30 32 -75 13 We can then make a short factor vector with the same labels used in this experiment. Below we can see the sequence of letter labels I specified, and their corresponding numeric values (based on alphabetical ordering). group_index = factor (c(&#39;b&#39;,&#39;w&#39;,&#39;m&#39;,&#39;w&#39;,&#39;g&#39;)) data.frame (group_index, group_index_number = as.numeric (group_index)) ## group_index group_index_number ## 1 b 1 ## 2 w 4 ## 3 m 3 ## 4 w 4 ## 5 g 2 We can then take this vector of factor levels and use it to generate a sequence of effects: as.numeric (group_index) ## [1] 1 4 3 4 2 c(30, 32, -75, 13)[group_index] ## [1] 30 13 -75 13 32 Notice that the sequence of effects match the sequence of group levels, based on their numerical value. If every single group were to get an independent parameter represented in our regression equation, these would become very long and difficult to interpret. Instead, by treating the effects for the level of a factor as a vector, our models can represent a very large number of parameters in a concise way. For example, compare the following two possible implementations of our 4 group model (where \\(j\\) is an index for our group effects): \\[\\begin{equation} \\begin{split} \\mu_{[i]} = Intercept + group_{[1]} + group_{[2]} + group_{[3]} + group_{[4]} \\\\ \\mu_{[i]} = Intercept + group_{[j]} \\\\ \\end{split} \\tag{4.1} \\end{equation}\\] It may seem like too much of a difference now, but later we have have many factors, some with dozens or hundreds of levels. In those cases, representing factor effects using vectors becomes essential. 4.2 Comparing four (or any number of) groups Were first going to treat the four groups as if they had no internal structure. In this case it may not be the best approach for this data, since we know there are logical ways to subdivide men, women, boys and girls. However, this is a good starting point since many cases you will have several groups with no logical internal divisions. 4.2.1 The model Our updated model is now: \\[\\begin{equation} \\begin{split} \\textrm{Likelihood:} \\\\ y_{[i]} \\sim \\mathcal{N}(\\mu_{[i]},\\sigma_{error}) \\\\ \\mu_{[i]} = Intercept + group_{[\\mathrm{group}_{[i]}]} + \\alpha_{[speaker_{[i]}]} \\\\\\\\ \\textrm{Priors:} \\\\ \\alpha_{[speaker]} \\sim \\mathcal{N}(0,\\sigma_{[speaker]}) \\\\ \\\\ Intercept \\sim t(3, 220, 100) \\\\ group_{[\\mathrm{group}]} \\sim t(3, 0, 100) \\\\ \\sigma_{error} \\sim t(3, 0, 100) \\\\ \\sigma_{speaker} \\sim t(3, 0, 100) \\\\ \\end{split} \\tag{4.2} \\end{equation}\\] Notice that for each trial number \\(i\\) the group predictor is indexed by a variable called group. This is a bit confusing, but I am just trying to be consistent with how R does things. As noted above, a factor predictor like group is really just a bunch of numbers that represent group effects in a vector. So R really treats your group as a sequence of numbers representing group numbers. But it also calls the predictor in the model by that name! So, though it may look strange \\(group_{[\\mathrm{group}_{[i]}]}\\) just says that you have a predictor in your model called \\(group\\) and it has a few possible values (four in this case). Also, you have a variable in your data with the same name (group) that tells you which value of your \\(group\\) predictor to use for each observation! This may sound convoluted, but it is simply what I demonstrated in the end of the last subsection regarding the behavior of vectors and factors. Our model will estimate three \\(group\\) effects (it must omit one). It estimates these from a the prior distribution specified in the model above (\\(group \\sim t(3, 0, 100)\\)). Our data includes a predictor called group that simply tells us which value of our group effect to use in each trial (group[i] = \\(\\mathrm{group}_{[i]}\\)). For example, above we saw that the first value of the group vector is 3. This means this speaker is a member of the m group. So, in our model above the equation determining \\(\\mu_{[i]}\\) will include the value \\(group_{[3]}\\) in it because, for the third observation this predictor will be \\(group_{[\\mathrm{group}_{[1]}=3]}\\). As in the previous chapters, we fit the models using weakly-informative priors. Were going to use sum coding, which means that the intercept will be the mean of all the groups, and group effects will be represented as differences from this mean. Remember that the missing group effect will be equal to the negative sum of the coefficients that are present. By default, R drops the last level from your factor, which in our case will be the w level. We can set R to use sum coding with the line below: options (contrasts = c(&quot;contr.sum&quot;,&quot;cont.sum&quot;)) And fit the model below: options (contrasts = c(&quot;contr.sum&quot;,&quot;cont.sum&quot;)) # Fit the model yourself, or download pre-fit model from: # github.com/santiagobarreda/stats-class/tree/master/models # and load after placing in working directory # model_four_groups = readRDS (&#39;4_model_four_groups.RDS&#39;)set.seed (1) model_four_groups = brm (f0 ~ group + (1|speaker), data = h95, chains = 4, cores = 4, warmup = 1000, iter = 11000, thin = 10, prior = c(set_prior(&quot;student_t(3, 200, 100)&quot;, class = &quot;Intercept&quot;), set_prior(&quot;student_t(3, 0, 100)&quot;, class = &quot;b&quot;), set_prior(&quot;student_t(3, 0, 100)&quot;, class = &quot;sd&quot;))) # saveRDS (model_four_groups, &#39;model_four_groups.RDS&#39;) # inspect model model_four_groups ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: f0 ~ group + (1 | speaker) ## Data: h95 (Number of observations: 1668) ## Samples: 4 chains, each with iter = 11000; warmup = 1000; thin = 10; ## total post-warmup samples = 4000 ## ## Group-Level Effects: ## ~speaker (Number of levels: 139) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 20.95 1.34 18.51 23.82 1.00 2080 2564 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 206.49 1.93 202.67 210.21 1.00 1474 2270 ## group1 29.53 3.52 22.78 36.65 1.00 1253 2236 ## group2 31.88 3.98 24.35 39.68 1.00 1565 2392 ## group3 -75.18 2.90 -80.89 -69.62 1.00 1246 2383 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 11.86 0.22 11.46 12.31 1.00 3882 3814 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). We can see that the intercept is the average of the group means, and our coefficients are equal to the centered group means. Notice that we use the hypothesis function to recover the final group coefficient using the negative sum of the coefficients that were estimated. # group means means = tapply (h95$f0, h95$group, mean) # overall mean mean (means) ## [1] 206.51 # group means means ## b g m w ## 236.07 238.35 131.22 220.40 # centered means means - mean (means) ## b g m w ## 29.563 31.840 -75.293 13.890 # parameters = centered means brms::hypothesis (model_four_groups, c(&quot;Intercept = 0&quot;, &quot;group1 = 0&quot;, &quot;group2 = 0&quot;, &quot;group3 = 0&quot;, &quot;-(group1+group2+group3) = 0&quot;))[[1]][,1:5] ## Hypothesis Estimate Est.Error CI.Lower CI.Upper ## 1 (Intercept) = 0 206.486 1.9287 202.6697 210.213 ## 2 (group1) = 0 29.532 3.5239 22.7831 36.645 ## 3 (group2) = 0 31.878 3.9764 24.3510 39.684 ## 4 (group3) = 0 -75.176 2.9037 -80.8886 -69.620 ## 5 (-(group1+group2+group3)) = 0 13.766 2.9346 7.9231 19.379 Whn you fit a more traditional model, you cant just compare any groups you want. However, with these Bayesian models we can compare any groups we want by using comparisons of the posterior samples (as shown in chapter 3). For example, the difference between girls and boys can be found by asking if one minus the other equals 0 (which would be true if these were identical): brms::hypothesis (model_four_groups, &quot;group1 - group2 = 0&quot;)[[1]][,1:5] ## Hypothesis Estimate Est.Error CI.Lower CI.Upper ## 1 (group1-group2) = 0 -2.3459 6.4375 -15.038 10.282 The result above suggests that the difference is very small (-2 Hz) and the 95% credible intervals spans a huge range (from -15 to +10)). As a result, the measured difference between these groups is not reliable, and may be very small or close to zero. Notice that in this summary I am focused on minimizing type S and type M errors. This means I am worried about whether the effect is likely to be small or large, and negative or positive, rather than whether it is true or false. 4.3 Investigating many factors simultaneously: Analysis of Variance Above, our model had a single batch of groups. Another way to look at it is that the model predicted variation along a single dimension. However, we can categorize people (or observations) along multiple dimensions simultaneously. So, a speaker may be an adult and a woman, and not just and adult or a women. This is because adultness and gender are independent dimensions and the value of one does not affect the value of the other. We can return to the example of the reading experiment presented above. Recall that we had four groups varying along two dimensions: whether they drank coffee or water, and whether they were male or female. The figure below represents designs of this structure and shows three ways that these can be organized. The characteristics of within-subjects and between-subjects designs should be familiar by now. What is new is the mixed design. In a mixed design, one or more factors are between-subjects, and the others are within-subjects. In the example below, \\(A\\) is between-subjects but \\(B\\) is within-subjects. Actually, the caffeine experiment we have been discussing would have to be a mixed design: subjects can be tested at both levels of drink (water and coffee) but not at both levels of gender. Figure 4.4: Data from a single group of subjects (S) divided according to a single grouping factor A. Our models can include any number of factors, and these can be crossed or nested. When two factors are crossed, this means that all levels of a factor appear at all levels of another factor. This is easiest to conceive of for participants (remember participant is just factor!). Participants are crossed with a factor when these are tested at all levels of a factor. So, a factor that varies within-subject is crossed with subjects. When one or more levels of a factor cannot be observed at all levels of another factor, then these are no longer crossed. When levels of one factor appear exclusively at specific levels of the other factor they are said to be nested. So, when different subsets of participants appear at different levels of a factor, the factor is crossed with subjects. In the images above, all of the examples cross \\(A\\) and \\(B\\). What would it look like for these factors to not be crossed? Well, one of the cells (boxes) would be completely missing observations. If this were to happen, we would lose the ability to make comparisons across groups involving the values in that cell. Designs where all the factors are crossed are sometimes called factorial or orthogonal designs. The name orthogonal is particularly telling. It means at right angles, perpendicular (from the greek stems ortho-, meaning straight, right, and -gon-, meaning side or angle). When you have orthogonal designs, that means that your dimensions (i.e., factors) can be estimated independently. Consider what would have happened if you ran the coffee and reading time experiment and gave coffee only to women and water only to men. How would you know if the coffee is responsible for the difference or if it should be attributed to gender. What if you gave water and coffee to women but only water to men. This would allow you to test the drink effect with accuracy for women but not for men. Is it necessary that the results for women equal those of men? If so, why did we include gender as a predictor? The above example shows that if you want to be able to untangle the independent effects of gender and drink on reading time, you need to test all levels of gender at all levels of drink. In other words, estimating the independent effects of each factor, and the relationships between the factors, requires that factors be crossed so that the design is orthogonal. In addition, orthogonal designs allow us to decompose the variation in our data into individual components. If orthogonality lets us estimate the individual effects of different factors, we can divide the variation in our observations into that which can be attributed to the different factors in our design. This simple but extremely powerful idea is called the analysis of variance, discussed in more detail in the following section. 4.3.1 Description of the model In the previous section, we acted like we just had four different groups with no internal structure. Of course, we know that our groups differ systematically from each other in meaningful ways. For example, we might have chosen to fit two separate models that looked like this: brm (f0 ~ gender + (1|speaker) brm (f0 ~ adult + (1|speaker) For several reasons (some of which well see very soon), its preferable to fit a single model with both predictors at once, rather than fitting two separate models for each one. Our R model formula will now look like this, reflecting the influence of both predictors simultaneously: f0 ~ adult + gender + (1|speaker) This can be read like f0 is distributed according to effects for speaker adultness and gender, with random intercepts for each speaker. You may have noticed that our model no longer includes the group predictor. This is because the group label is perfectly predictable on the basis of adult and gender (i.e., a member of the g group must have values of female and child). Basically, we have decomposed the groups into two components to help us understand the effect of each. This is simply and extension of what we have been doing from the start. For example our model was previously: \\(\\mu_{[i]} = Intercept + (group_{\\mathrm{group}_{[i]}}) + \\alpha_{\\mathrm{speaker}_{[i]}}\\) However, since group can be exactly represented by combinations of gender and adult, our model sort of always contained this more-complicated model inside of it. We can expand the term in parenthesis as below: \\(\\mu_{[i]} = Intercept + (adult_{\\mathrm{adult}_{[i]}} + gender_{\\mathrm{gender}_{[i]}}) + \\alpha_{\\mathrm{speaker}_{[i]}}\\) This is what can be referred to as an ANOVA-like decomposition. ANOVA, the ANalysis Of VAriance, is general approach for understanding data by focusing on the sources of variance contained in it. We have actually been chipping away at the error variance little by little by making more complicated models. Recall that our very first approach to understanding f0 looked like this: \\[ \\sigma_{total} = \\sigma_{error} \\] In other words, all variation was error. After this we added between-speaker variation to the model, and removed that from the error. \\[ \\sigma_{total} = \\sigma_{speaker} + \\sigma_{error} \\] Now, our model can individually estimate the variation in observed f0 due adultness, gender, to between-speaker variation and to production error. \\[ \\sigma_{total} = \\sigma_{adult} + \\sigma_{gender}+\\sigma_{speaker} + \\sigma_{error} \\] Our complete model is now: \\[\\begin{equation} \\begin{split} \\textrm{Likelihood:} \\\\ f0_{[i]} \\sim \\mathcal{N}(\\mu_{[i]},\\sigma_{error}) \\\\ \\mu_{[i]} = Intercept + adult_{\\mathrm{adult}_{[i]}}+gender_{\\mathrm{gender}_{[i]}} + \\alpha_{\\mathrm{speaker}_{[i]}} \\\\\\\\ \\textrm{Priors:} \\\\ \\alpha_{speaker} \\sim \\mathcal{N}(0,\\sigma_{speaker}) \\\\ \\\\ Intercept \\sim t(3, 200, 100) \\\\ adult_{\\mathrm{adult}} \\sim t(3, 0, 100) \\\\ gender_{\\mathrm{gender}} \\sim t(3, 0, 100) \\\\ \\sigma_{error} \\sim t(3, 0, 100) \\\\ \\sigma_{speaker} \\sim t(3, 0, 100) \\\\ \\end{split} \\tag{4.3} \\end{equation}\\] In plain English this says: We expect the mean f0 produced by speakers from Michigan to vary according to a normal distribution with a trial-specific mean parameter. That mean varies based on whether the speaker is an adult/child and female/male, and some random speaker-dependent variation. Speaker-dependent variation in the means were modelled as coming from a normal distribution with a mean of zero and a standard deviation estimated from the data. 4.3.2 Fitting the model and interpreting the results Below we fit the model using the model structure outlined above. # Fit the model yourself, or download pre-fit model from: # github.com/santiagobarreda/stats-class/tree/master/models # and load after placing in working directory # model_both = readRDS (&#39;4_model_both.RDS&#39;) set.seed (1) model_both = brm (f0 ~ adult + gender + (1|speaker), data = h95, chains = 4, cores = 4, warmup = 1000, iter = 11000, thin = 10, prior = c(set_prior(&quot;student_t(3, 200, 100)&quot;, class = &quot;Intercept&quot;), set_prior(&quot;student_t(3, 0, 100)&quot;, class = &quot;b&quot;), set_prior(&quot;student_t(3, 0, 100)&quot;, class = &quot;sd&quot;))) # saveRDS (model_both, &#39;4_model_both.RDS&#39;) And we can inspect the model fixed effects: # inspect the fixed effects brms::fixef (model_both) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 209.134 2.6607 203.948 214.379 ## adult1 -32.948 2.7316 -38.377 -27.657 ## gender1 30.492 2.4980 25.494 35.394 We now have two non-Intercept Population-Level effects: adult1 and gender1, representing the categories adult and female respectively. Remember that since we used sum coding, the effects for the groups that are not represented (child, male) are just the opposite sign of the groups that are represented. Below we calculate the mean f0 of the four groups, and find the average difference between two different arrangements of the group. First, we calculate the difference between the child groups and the adult groups. This tell us what the average differences is according to adultness. Then, we do the same thing for the female and male groups to find the average difference according to gender. Below, we can see that the Intercept (209 Hz) is reasonably close to the mean of the group means (206 Hz), and that the adult effect (-33 Hz) is about the same magnitude as the difference between the mean of the adult and child groups (30 Hz). However, the model seems to overestimate the average differences between male and female groups (30 Hz in model, 23 Hz in the data). # grop means means = tapply (h95$f0, h95$group, mean) # overall mean in data mean (means) ## [1] 206.51 # group means means ## b g m w ## 236.07 238.35 131.22 220.40 # half the average adultness difference in data ((means[&#39;b&#39;]+means[&#39;g&#39;])/2 - (means[&#39;m&#39;]+means[&#39;w&#39;])/2) / 2 ## b ## 30.701 # half the average gender difference in data ((means[&#39;g&#39;]+means[&#39;w&#39;])/2 - (means[&#39;m&#39;]+means[&#39;b&#39;])/2) / 2 ## g ## 22.865 We can recover the group means by adding up the individual coefficients. This can be tedious and requires you to be careful and methodical, but isnt actually difficult. Remember that each of the four groups is uniquely identified by a combination of gender and adultness. To recover the group means we need to add the right combination of coefficients to the intercept. For example, the second hypothesis we are testing below says Intercept + -adult1 + -gender1 = 0. This hypothesis takes the overall mean and adds the effect for child (adult2). Why did we use -adult1 in the formula and not adult2? This is because our model does not contain a parameter called adult2. This parameter is not estimated in our model because -adult1=adult2. So, if we want the value of adult2 we use -adult1, because adult2 does not exist. Similarly, we add the effect for male (gender2) using -gender1. Since we started with the overall mean f0 and add the effects for a male and a child, this hypothesis estimates the group mean for boys. tapply (h95$f0, h95$group, mean) ## b g m w ## 236.07 238.35 131.22 220.40 # this hypothesis calculates the intercept, and # the group means for boys, girls, men, women means_pred = brms::hypothesis (model_both, c(&quot;Intercept = 0&quot;, &quot;Intercept + -adult1 + -gender1 = 0&quot;, &quot;Intercept + -adult1 + gender1 = 0&quot;, &quot;Intercept + adult1 + -gender1 = 0&quot;, &quot;Intercept + adult1 + gender1 = 0&quot;))[[1]][,1:5] means_pred ## Hypothesis Estimate Est.Error CI.Lower CI.Upper ## 1 (Intercept) = 0 209.13 2.6607 203.95 214.38 ## 2 (Intercept+-adult1+-gender1) = 0 211.59 4.8403 202.16 221.42 ## 3 (Intercept+-adult1+gender1) = 0 272.57 5.3907 262.09 283.07 ## 4 (Intercept+adult1+-gender1) = 0 145.69 4.0108 137.79 153.42 ## 5 (Intercept+adult1+gender1) = 0 206.68 3.8145 199.20 214.21 The predictions above are actually not a good match for our group means, suggesting that maybe our model is not capturing something important about our data. 4.4 Investigating model fit So far weve been working with very simple models and not worrying much about how well they fit, meaning how well they represent our data. Our reconstruction of the group means above suggests our current model may have some issues, and that we should be concerned about its fit. We can investigate model fit with a posterior predictive check. The posterior predictions made by your model are the values predicted by your model for each data point, for each set of posterior samples. Effectively, these are the \\(\\mu_{[i]}\\) predicted by your model for each trial. For example, our current model looks like this: \\(\\mu_{[i]} = Intercept + adult_{[\\mathrm{adult}_{[i]}]} + gender_{[\\mathrm{gender}_{[i]}]} + \\alpha_{[\\mathrm{speaker}_{[i]}]}\\) This model equation predicts a different \\(\\mu\\) for each trial by combining the intercept and appropriate coefficients for the trial. These predicted values can then be used with the error estimated by the model (\\(\\sigma_{error})\\)) to generate simulated data using a normal distribution, like this \\(\\mathcal{N}(\\mu_{[i]},\\sigma_{error})\\). This technique is called posterior prediction, and it can be used to assess how well your model fits your data. If your model really gets your data, the fake data it makes will be exactly like your real data. If the fake data your model generates looks substantially different from your real data, that suggests a fundamental misalignment between your model and your data. The brms package has a predict function which can help you make these predictions easily. y_pred = predict (model_both) head (y_pred) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 243.7989 12.55577 219.4143 268.7087 ## [2,] 278.3190 12.55514 253.8997 303.1478 ## [3,] 207.7220 12.36896 183.2782 231.7484 ## [4,] 247.0643 12.28252 223.5102 270.6152 ## [5,] 218.6251 12.50744 193.1472 243.4518 ## [6,] 300.9915 12.43985 276.3581 325.2514 The output of prediction, y_pred, has four columns and as many rows as you had observations. These contain a predicted value for each datapoint, but also information about credible intervals around the predictions. The reason we can get intervals around our predictions is because our model produces a different prediction for each set of posterior samples! This means that if we have 4000 samples we actually have 4000 slightly different models and 4000 slightly different predictions. So, in addition to information about the most probable estimates, we get information about expected variation around these estimates. Below, I make predictions without random effects (re_formula = NA). y_pred_no_re = predict (model_both, re_formula = NA) This corresponds to a model like below, without speaker adjustments: \\(\\mu_{[i]} = Intercept + adult_{adult_{[i]}} + gender_{gender_{[i]}}\\) The posterior predictions made by this model will help us understand how well our model represents average f0 based only on group averages, without the speaker-dependent adjustments. Below we can see that the model with speaker adjustments does a very good job of predicting f0, with most credible intervals for most predictions overlapping with the diagonal (diagonal = perfect prediction). On the other hand, without speaker adjustments the predictions for many high-f0 speakers lie left of the diagonal, meaning our predictions are higher than they should be. Figure 4.5: (left) Posterior predicted f0 for the model with speaker random effects. (right) Posterior predicted f0 for the model without speaker random effects The above plots are good for basic analysis, but its hard to get a good idea of the source of our problems using these plots. We can get a much better idea of how our model is performing by using an interaction plot. 4.5 Interactions and interaction plots Interactions and understanding their graphical representations is extremely important. In many if not most models with multiple predictors, researchers will need to at least consider the effects of interactions in their models. We can think of a single effect representing a difference between groups as a slope. For example, in the left panel below I plotted the mean f0 produced by males and female speakers from the Hillenbrand et al.Â data at x-axis locations 0 and 1. The difference in the group means is -55 Hz (females 225 Hz, males 170 Hz). As a result, the line formed by joining these groups has a slope of -55 (i.e., it drops 55 Hz from 0 to 1). We can use any arbitrary x axis distance to calculate slopes, as long as we are consistent. However, there are obvious practical advantages to choosing to calculate these slopes over the arbitrary distance of 1. In the middle panel we see the effect for adultness, which shows a positive slope for the difference from adult to child: the f0 increases by about 60 Hz. The plots highlighting the effects for adultness and gender are main effects plots. You may have heard things like the analysis showed a significant main effect for so and so. Main effects are the average effects for one predictor averaged across everything else. Saying averaged across everything else basically means we are ignoring everything else. A person looking only at the left plot would not realize our data also investigates the effect of adultness. We have erased the differences in adultness by averaging across all levels of that factor. Another way to think of main effects are that they are marginal effects. They are the overall average difference. Someone might ask you, whats the average difference between the f0 produced by male and female speakers in Michigan? and you can respond 55 Hz. However, sometimes the answer is not so simple, and it starts more like: well it depends. Interactions represent situations like these, where the effect of one variable depends on, or is conditional on, the value of some other variable. Figure 4.6: Plots showing different ways to consider our f0 data. In the right panel above we see a two-way interaction plot. Interaction plots show you what are called the simple effects of your predictors (sometimes also called the simple main effects). The simple effects are the conditional probabilities: the effects of your factor, conditional on the level of another factor. For example, the left plot shows the overall (marginal) effect for gender. The right plot also shows the effect for gender. However, it uses a blue line to show the effect for gender in adults (gender given adultness) and a green line to show the effect for children for children (gender given childness). As a result, we can consider the effects of gender conditioned on adultness, and see how these might differ. So, main effects show you the effect for a factor, and simple effects show you the effects of the factor depending on the value of other things. If adultness in no way affected f0, the right panel should look identical to the left panel. If adultness affected f0 in the same way across genders, we would see parallel lines in the right plot. This is because if you are adding a single value to each end of the adult line, the line indicating the gender effect for adults (broken green line) would just slide up and down the f0 axis but would not change in slope. There is no way to make the green and blue lines above to match by adding a single value to either. This indicates we have an interaction in our data. In general, when we see lines that are not parallel, that means there may be an interaction in our data. In the absence of an interaction, we could just answer the question whats the average difference between males and females in your sample? with a number like 55 Hz. In the presence of an interaction we need to consider the conditional effects of each predictor, at the levels of the other predictor. The idea of conditional effects feels complicated, but it is something we all understand intuitively. How much progress will a person learning a second language make in a year? What if I told you that one group of speakers is 3 and the other is 65. You know that makes a difference, which is to say, that you know there is an interaction between the effect time spent learning a language, and the age at which the learner begins. Furthermore, we all intuitively understand interactions whenever we correctly interpret the information presented in an interaction plot as above. There is a large negative slope for gender for adults. This tells us that gender has a large effect on f0 for adults. However, the slope for gender is basically zero for children. So, we might say there is a large f0 difference for adult males and females in our sample, but basically no gender based difference for children. Alternatively, we might look at the changing effect for gender across adultness levels. If we did this, we might say there is a small effect for adultness in the average f0 produced by females, but a very large effect for adultness for males. Anyone who is able to make such a statement based on the information in the plot above understands interactions, whether or not they know how to relate this concept to the mathematical formalisms used to implement this concepts in regression models. In summary, if the answer to what is the effect of X on Y is well, it depends on the values of Z, you have an interaction in your data. When you have substantial interactions present in your data and you do not include these in your model, this can cause a problem for your model fit. Before moving on from interactions, we need to discuss the relationshpi between interactions and the crossing of factors. The only thing you definitely need to be aware of is that you cannot estimate interactions of factors are not crossed. This is kind of obvious if you think about it. Interactions are conditional effects, and crossing means you observed all combinations. If you did not observe all combinations, you are not in a position to tell me about how effects vary for specific combinations. 4.5.1 Interactions in our f0 data Above we made posterior predictions of our data using our model, with and without the inclusion of the speaker random effects. We can see that when random effects are included, prediction is quite good. This is not surprising since the speaker-specific intercept adjustments allow for each speakers mean f0 to be modeled effectively. However, we see that the predictions made by our model are substantially and systematically wrong in the absence of the speaker random intercepts. Its clear that the problem with our predictions in the right panel is that the lines are parallel. As weve just discussed, in the absence of interactions, interaction plots contain only parallel lines. Well, since our model (model_both) does not include interaction terms it cannot represent interactions, and so is only capable of producing predictions that result in parallel lines. This means it is not capable of representing the pattern in our data! This is an important point worth considering. Your model is a little universe you made up, and it only includes the information you included in it. This universe only contains parallel lines because we only included that capability. So, the fact that your model generates parallel lines does not in any way prove that the lines are parallel, because they were bound to be so. In order to properly model the group differences, and to really understand whether interactions are present in the data, the model must be built in a way that allows it to represent the interactions in our data. par (mfrow = c(1,3), mar = c(4,4,3,2)) plot.interaction (h95$gender, h95$adult, h95$f0, col=3:4, ylim=c(130,280),lwd=3, type=&#39;b&#39;,pch=c(16,17),cex=1.5,main=&quot;Data&quot;,legend = FALSE) plot.interaction (h95$gender, h95$adult, y_pred[,1], col = 3:4,lwd=3, type=&#39;b&#39;, pch = c(16,17), cex = 1.5, ylim = c(130,280), main=&quot;Pred. with RE&quot;,legend=FALSE) plot.interaction (h95$gender, h95$adult, y_pred_no_re[,1],col=3:4, lwd=3, type = &#39;b&#39;, pch = c(16,17), cex = 1.5, ylim = c(130,280), main=&quot;Pred. without RE&quot;, leg.x=1.8,leg.y=270, xlim=c(.95,2.3)) Figure 4.7: Interaction plots showing comparing our f0 data to different posterior predictions, with and without RE (random effects). 4.6 Investigating interactions with a model The model presented above (model_both) requires only a slight tweak to include a term representing the interaction in our data. There are two ways to include interactions in R model formulas, as shown below: f0 ~ adult + gender + adult:gender + (1|speaker) Â  f0 ~ adult * gender + (1|speaker) The first way includes an explicit interaction term, adult:gender. The syntax for these is X:Z for an interaction between effects X and Z, W:X:Z for a three-way interaction, and so on. The second way uses * between our two predictors. This tells R to include those predictors, and the interactions between them. This can be much faster then specifying all interactions, but you lose control over which ones you include. For example the first formula implies the second, but cannot represent the third (since it omits the X:W interaction): y ~ Z * X * W Â  y ~ Z + X + W + Z:X + Z:W + X:W + Z:X:W Â  y ~ Z + X + W + Z:X + X:W + Z:X:W Our full model specification now includes an interaction term that can help explain variation that cannot be explained by the independent effects of adultness and gender. This interaction term helps us model the conditional effect of one predictor given the other. \\[\\begin{equation} \\begin{split} \\textrm{Likelihood:} \\\\ y_{[i]} \\sim \\mathcal{N}(\\mu_{[i]},\\sigma_{error}) \\\\ \\mu_{[i]} = Intercept + adult_{\\textrm{adult}_{[i]}} + gender_{\\textrm{gender}_{[i]}}+ adult:gender + \\alpha_{speaker_{[i]}} \\\\\\\\ \\textrm{Priors:} \\\\ \\alpha_{speaker} \\sim \\mathcal{N}(0,\\sigma_{speaker}) \\\\ \\\\ Intercept \\sim t(3, 200, 100) \\\\ adult_{[i]} \\sim t(3, 0, 100) \\\\ gender_{[i]} \\sim t(3, 0, 100) \\\\ adult:gender \\sim t(3, 0, 100) \\\\ \\sigma_{error} \\sim t(3, 0, 100) \\\\ \\sigma_{speaker} \\sim t(3, 0, 100) \\\\ \\end{split} \\tag{4.4} \\end{equation}\\] In plain English this says: We expect the mean f0 produced by speakers from Michigan to vary according to a normal distribution with a trial-specific mean parameter. That mean varies based on whether the speaker is an adult/child and female/male, including the interaction of these two predictors. Random speaker-dependent variation in means was modelled as coming from a normal distribution with a mean of zero and a standard deviation estimated from the data. 4.6.1 Fitting the model and interpreting the results Below we fit the model which now includes an interaction term representing the changing effect of gender and adultness on average f0. # Fit the model yourself, or download pre-fit model from: # github.com/santiagobarreda/stats-class/tree/master/models # and load after placing in working directory # model_interaction = readRDS (&#39;4_model_interaction.RDS&#39;) set.seed (1) model_interaction = brm (f0 ~ adult + gender + adult:gender + (1|speaker), data = h95, chains = 4, cores = 4, warmup = 1000, iter = 11000, thin = 10, prior = c(set_prior(&quot;student_t(3, 200, 100)&quot;, class = &quot;Intercept&quot;), set_prior(&quot;student_t(3, 0, 100)&quot;, class = &quot;b&quot;), set_prior(&quot;student_t(3, 0, 100)&quot;, class = &quot;sd&quot;))) # saveRDS (model_interaction, &#39;4_model_interaction.RDS&#39;) Remember that this line set_prior(\"student_t(3, 0, 100)\", class = \"b\") sets the prior for all non-intercept Population-Level predictors. This allows you to efficiently set priors for the adult, gender, and adult:gender predictors in your model in a single line, and becomes more and more useful as our models grow more complex. A look at the model output above indicates that we have a large interaction term. In fact, our interaction is as large as the main effect for gender! Our interaction basically says that sometimes being a male and being an adult results in a different f0 than can be predicted by maleness and adultness independently. In cases with large interactions we have to be very careful about interpreting the main effects. In other words, when the answer to a question is it really depends, you should be wary of making blanket statements. For example: how good can a speaker get at a second language in one year? The interaction between age and language learning is so large that it doesnt even really make sense to answer this in a single way for all learners. # inspect fixed effects brms::fixef (model_interaction) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 206.561 1.9131 202.783 210.275 ## adult1 -30.669 1.9366 -34.465 -26.876 ## gender1 22.892 1.9742 18.938 26.761 ## adult1:gender1 21.719 1.9188 17.867 25.461 We need to talk about why there is only a single interaction term. The reason for this is related to the same reason we cant get estimates for all our group effects (i.e., linear dependence). The number of terms you can estimate is generally one fewer than the number of levels. For interaction terms, the number of parameters is equal to (number of levels of factor A - 1)x(number of levels of factor B - 1). Since each of our factors have two levels, we can only estimate one parameter, (2-1)x(2-1)=1. The interaction term is just another element of your prediction equation (i.e., \\(\\mu + x_1+x_2...\\)) intended to help explain variation that cant be predicted by the independent effects of the other predictors in the model. If there is no interaction in your data, then the value of the interaction terms will be zero and your model will look just as if you had not even included the interaction at all. Recovering the predicted group means based on the coefficient values is straightforward, but a bit tedious: we must now either add or subtract the value of the interaction term (adult1:gender1) from each group. We can easily determine which to do for this model because the sign on the interaction term is the product of the signs on the relevant main effects terms. Before doing this however, we need to talk about what adult1:gender1 means. This can be read aloud as the effect of adult1 given (conditional on) gender1. If we wanted to find the simple effect for being an adult (adult1) given femaleness (gender1) we should add the main effect for adult1 to the conditional effect for adult1 given gender1 as in adult1 + adult1:gender1. In other words, the expected pitch for adults that are female considers the effects for adultness, butl also the unique effect that adultness has for female speakers. Importantly, adult1:gender1 has the same value as gender1:adult1 would have if it existed, but remember that is does not. This means that to find the simple effect of gender1 given adult1, we also have to carry out an operation like gender1 + adult1:gender1. This is because, mathematically, this is equivalent to combining gender1 + gender1:adult1 since adult1:gender1 must equal gender1:adult1. Figure 4.8 presents an example of how our interaction plot can be built up from the components in our fixed effects above, and is very useful for understanding the geometry of main effects and interactions. In (a) we see that the intercept lifts up a line from 0 to the level of the overall mean f0 of 206 Hz. Then the effect for adult1 (adult, -30 Hz) and -adult1 (children, -(-30 Hz)) are added to this value, causing the separation between the lines indicating a main effect for adultness. Notice that the lines are parallel, and also parallel to the x-axis. This is because we have not added either an effect for gender (indicated along the x axis), or an interaction between gender an adultness. In (b) we see the addition of the gender effect: gender1 (female, 22 Hz), and -gender1 (male, -22 Hz). Notice that the effect is added to one point on the x axis and subtracted to the other point in the x axis. The result is a slope, and the same slope for both lines (i.e.Â no interaction yet). Panel (c) shows the addition of all of the effects shown in the top row, and the results of a model that includes both main effects both no interaction. In (e) we add the gender interaction adult1:gender1, which was 21 Hz. Notice that the interaction effect has different when added to the same line, and also given a certain x axis position across lines. There is an obvious reason for why this must be the case, and why we only get one interaction term. Focus on the blue line in (e) and its average value, which represents the mean f0 produced by children in our sample. Whatever this average value, it is fixed for this data and cannot change. So, when we add adult1:gender1 to the left end of the blue line, we must therefore subtract the same amount to the right end. Failure to do this would cause the blue line to move up along the y axis. This would mean the average f0 of children went up, which is not possible for this fixed set of data. Instead, the interactions can only make the blue line spin like a propeller around its fixed average value. Although it is a little harder to visualize with the way the interaction plots below are set up, the same sort of constraints mean that the interaction terms in the same x-axis location must also equal but have opposite signs. As a result, we can get only a single independent interaction term when we combine two factors with two levels each! Figure 4.8: An interaction plot built up from its individual components. Below, we use the hypothesis function provided in brms to reconstruct expected group means given the fixed effects above. The fifth hypothesis we are testing below is the simplest to understand, so we will start there. This hypothesis asks whether the sum of the Intercept, adult1 (the effect for adults), gender1 (the effect for femaleness), and adult1:gender1 (the effect for adults given femaleness). Because of the specific combination of parameters values we combined, this results in the comparison of the girl mean f0 to zero. The second hypothesis we are testing below says Intercept + -adult1 + -gender1 + adult1:gender1 = 0. Since we have flipped the sign on adult1 and gender1, these now correspond to the effects of the groups the were not estimated, child and male. These coefficients would be called adult2 and gender2. However, since we cannot estimate these and these do not exist in our model, we flip the sign on the coefficients that arepresent in our model. Since we combined the effects for male children, the second hypothesis below compares the mean f0 for boys to 0. If you look at the hypotheses below, you will see that these generate the predicted group means for our four speaker groups, and that the sign on the interaction terms always depends on the signs of the corresponding main effects terms. Furthermore, we can see that the inclusion of an interaction term allows our model to capture group averages more accurately than the model without intercepts. # actual data means tapply (h95$f0, h95$group, mean) ## b g m w ## 236.07 238.35 131.22 220.40 # intercept, boys, girls, men, women means_pred_interaction = brms::hypothesis (model_interaction, c(&quot;Intercept = 0&quot;, &quot;Intercept + -adult1 + -gender1 + adult1:gender1 = 0&quot;, &quot;Intercept + -adult1 + gender1 + -adult1:gender1 = 0&quot;, &quot;Intercept + adult1 + -gender1 + -adult1:gender1 = 0&quot;, &quot;Intercept + adult1 + gender1 + adult1:gender1 = 0&quot;))[[1]][,1:5] # predictions with no interaction term means_pred ## Hypothesis Estimate Est.Error CI.Lower CI.Upper ## 1 (Intercept) = 0 209.13 2.6607 203.95 214.38 ## 2 (Intercept+-adult1+-gender1) = 0 211.59 4.8403 202.16 221.42 ## 3 (Intercept+-adult1+gender1) = 0 272.57 5.3907 262.09 283.07 ## 4 (Intercept+adult1+-gender1) = 0 145.69 4.0108 137.79 153.42 ## 5 (Intercept+adult1+gender1) = 0 206.68 3.8145 199.20 214.21 # predictions with interaction term means_pred_interaction ## Hypothesis Estimate Est.Error CI.Lower ## 1 (Intercept) = 0 206.56 1.9131 202.78 ## 2 (Intercept+-adult1+-gender1+adult1:gender1) = 0 236.06 4.1908 227.91 ## 3 (Intercept+-adult1+gender1+-adult1:gender1) = 0 238.40 4.8091 229.01 ## 4 (Intercept+adult1+-gender1+-adult1:gender1) = 0 131.28 3.1841 124.90 ## 5 (Intercept+adult1+gender1+adult1:gender1) = 0 220.50 3.0216 214.48 ## CI.Upper ## 1 210.27 ## 2 244.45 ## 3 247.64 ## 4 137.39 ## 5 226.44 Below I print the estimates of the fixed effects in the model so we can focus on those. If you fit a model like this and are having trouble interpreting it, I would really encourage you to write down an interpretation using pen and paper, focusing on the decomposition of values provided by the regression model. brms::fixef (model_interaction) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 206.561 1.9131 202.783 210.275 ## adult1 -30.669 1.9366 -34.465 -26.876 ## gender1 22.892 1.9742 18.938 26.761 ## adult1:gender1 21.719 1.9188 17.867 25.461 For example, the average f0 is 206. The gender difference is 46 Hz (23 * 2) between groups, and there is a gender-based 23 Hz deviation from the mean between groups. This means that, overall, the male and female averages are about 183 and 229 Hz (206 Â± 23). However, the adult1:gender1 interaction is 22 Hz. This means that when the speaker was an adult (adult1), the gender difference was nearly doubled. We know this because the effect for gender1 is 22.8, and the effect for gender1 given adult1 (adult1:gender1, which is the same thing as gender1:adult1) is 21.7 Hz higher than that. So, the total effect for f0 across adults is about 22.8 + 21.7 = 44.5, suggesting a difference in f0 between the groups of 89 Hz (44.5 * 2). I am going to basically restate what I just said because it is very important. The effect for gender is 22.8, and the effect for gender1:adult1 is further 21.7 Hz. As a result, the cumulative effect for gender1 (female) given adult1 (adult) is gender1 + gender1:adult1 = 44.5. In contrast, the fact that adult1:gender1 = 21.7 indicates that adult2:gender1 = -21.7. This is because since adult1:gender1 represents the effect of gender1 given adult1, the effect given adult2 must be opposite in sign (because of sum coding). So, we can say that although the effect for gender is 22.9 overall, given that the speaker is a child (adult2), this effect is 21.7 Hz lower than the main effect estimate. So, for children we expect an f0 effect of 22.9 - 21.7 = 1.2, suggesting a group difference of 2.2 Hz. In other words, the effect of gender is basically zero given that the speakers are children. We can consider the effects the other way. The marginal effect for adult1 is -30, meaning that when speakers are adults, their f0 is 30 Hz lower than the overall average. However, adult1:gender1 = 21.7, meaning that if the speaker is female (gender1), then the expected effect of adultness is reduced (-30 + 21.7 = -8.3) so that the expected group difference is only 17 Hz. On the other hand, when the speaker is a male (gender2) then the interaction term should be flipped in sign (adult1:gender2 = -21.7). This means that the effect of adultness, conditional on the speaker being male is nearly doubled (-30 + -21.7 = -51.7). When considered in this way all these coefficients are just telling us what we already knew from looking at the interaction plot: f0 varies substantially based on gender for adults but not for children. Or: f0 varies substantially as a function of adultness for males but much less for females. 4.6.2 Assessing model fit We can asses model fit for the model including interaction terms by making more posterior predictions with our new model. y_pred_int = predict (model_interaction) y_pred_no_re_int = predict (model_interaction, re_formula = NA) We can make more interaction plots using our data and our posterior predictions. Below I compare our data, the predictions of our original model, and the predictions of our model that includes interactions (both models with no random effects). Whereas the model with no interactions enforced parallelism on the effects, our new model is able to capture the conditional nature of gender given adultness in our data. par (mfrow = c(1,3), mar = c(4,4,3,2)) plot.interaction (h95$gender, h95$adult, h95$f0, col=3:4, ylim=c(130,280),lwd=3, type=&#39;b&#39;,pch=c(16,17),cex=1.5,main=&quot;Data&quot;,legend = FALSE, ylab = &#39;f0 (Hz)&#39;) plot.interaction (h95$gender, h95$adult, y_pred_no_re[,1],col=3:4, lwd=3, type = &#39;b&#39;, pch = c(16,17), cex = 1.5, ylim = c(130,280), main=&quot;No Int. no RE&quot;, legend = FALSE, ylab = &#39;f0 (Hz)&#39;) plot.interaction (h95$gender, h95$adult, y_pred_no_re_int[,1],col=3:4, lwd=3, type = &#39;b&#39;, pch = c(16,17), cex = 1.5, ylim = c(130,280), main=&quot;With Int. no RE&quot;, leg.x=1.8,leg.y=270, xlim=c(.95,2.3), ylab = &#39;f0 (Hz)&#39;) Figure 4.9: Interaction plots showing comparing our f0 data to posterior predictions, with and without interaction terms (neither contains Random Effects). For the first time, we have a model that really does a reasonably-good job of representing the information in our data. The model can capture the gender-dependent nature of age-based f0 differences, and separately estimates between group variation and between group variation. 4.6.3 Making plots There are many ways to make nice graphics using brms models. There are many excellent resources for how to make slick graphics using packages like ggplot2 and bayesplot. In general these packages make figures that are nice but sometimes too fancy for many purposes where simple black and white graphics are needed. As a result, Im going to focus on making simple line plots (like those common in journal articles) using base R graphics. The standard information provided in the output of brm model summaries can be used to make plots. These summaries always contain (among other things) these four columns in the same order: the mean estimate, the standard deviation, and the lower and upper credible intervals. I wrote a small function called brmplot that will help draw effects plots easily using these summaries. The brmplot function takes in a matrix containing these columns and makes plots showing the means and credible intervals of different effects, assuming that each row is an effect. Below I get a summary of the fixed effects. I make plots of these effects in two orientations. In each one I omit the Intercept estimate as the magnitude of this is so different that it cannot easily be included on the plot. There is nothing special about these plots, but they are extremely effective at quickly communicating model information. fixef_interaction = brms::fixef (model_interaction) fixef_interaction ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 206.56112 1.913081 202.78344 210.27475 ## adult1 -30.66934 1.936608 -34.46529 -26.87641 ## gender1 22.89211 1.974245 18.93775 26.76101 ## adult1:gender1 21.71878 1.918765 17.86664 25.46130 par (mfrow =c(1,2), mar = c(8,3,1,1)) brmplot (fixef_interaction[-1,]) ; abline (h = 0,lty=3) par (mar = c(3,8,1,1)) brmplot (fixef_interaction[-1,], horizontal = FALSE) ; abline (v=0,lty=3) Figure 4.10: Horizontal and vertical plots of our fixed effects. Points indicate posterior means and lines indicate span of 95% credible intervals of the posterior distribution of the parameter. Although these plots help to effectively communicate information about your model parameters, representations of the data such as the interaction plots above are also crucial to help the reader understand the patterns in your data. 4.7 Frequentist corner 4.7.1 Bayesian multilevel modesl vs.Â lmer This is going to be a short one! The main shortcoming when it comes to lmer and fitting ANOVA-type models, is that there is no easy way to compare group effects within the model. For example, we can fit the model below which encodes the difference between each group mean and the overall mean. lmer_four_groups = lme4::lmer (f0 ~ group + (1|speaker), data = h95) summary (lmer_four_groups) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: f0 ~ group + (1 | speaker) ## Data: h95 ## ## REML criterion at convergence: 13468 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.644 -0.561 -0.086 0.470 4.808 ## ## Random effects: ## Groups Name Variance Std.Dev. ## speaker (Intercept) 430 20.7 ## Residual 141 11.9 ## Number of obs: 1668, groups: speaker, 139 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 206.51 1.91 107.93 ## group1 29.56 3.44 8.59 ## group2 31.84 3.91 8.15 ## group3 -75.29 2.93 -25.73 ## ## Correlation of Fixed Effects: ## (Intr) group1 group2 ## group1 0.065 ## group2 0.287 -0.464 ## group3 -0.216 -0.286 -0.402 The results provided by lmer are very similar to those provided by brm: brms::fixef (model_four_groups) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 206.486 1.9287 202.670 210.213 ## group1 29.532 3.5239 22.783 36.645 ## group2 31.878 3.9764 24.351 39.684 ## group3 -75.176 2.9037 -80.889 -69.620 Group 1 (boys) and group 2 (girls) have very similar effects to each other. Are they different? Using our brm model this can be answered easily, as shown above (and reproduced below): brms::hypothesis (model_four_groups, &quot;group2 - group1 = 0&quot;)[[1]][,1:5] ## Hypothesis Estimate Est.Error CI.Lower CI.Upper ## 1 (group2-group1) = 0 2.3459 6.4375 -10.282 15.038 Unfortunately, there is no way to answer this question given the information presented in the lmer model above. This is because the effects are only being estimates as differences to the mean, and not to group 1 or group 2. If we did want to investigate this difference specifically, we would need to refit the model using a different coding scheme. For example, if we used treatment coding group 1 (boys) would be the intercept, and the group effects would represent differences to this. We fit a model like this below: options (contrasts = rep(&quot;contr.treatment&quot;,2)) lmer_four_groups_treatment = lme4::lmer (f0 ~ group + (1|speaker), data = h95) summary (lmer_four_groups_treatment) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: f0 ~ group + (1 | speaker) ## Data: h95 ## ## REML criterion at convergence: 13466 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.644 -0.561 -0.086 0.470 4.808 ## ## Random effects: ## Groups Name Variance Std.Dev. ## speaker (Intercept) 430 20.7 ## Residual 141 11.9 ## Number of obs: 1668, groups: speaker, 139 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 236.07 4.04 58.39 ## groupg 2.28 6.29 0.36 ## groupm -104.86 5.11 -20.50 ## groupw -15.67 5.05 -3.10 ## ## Correlation of Fixed Effects: ## (Intr) groupg groupm ## groupg -0.643 ## groupm -0.791 0.508 ## groupw -0.800 0.514 0.632 Notice that our group 2 predictor (group) is now equal to 2.3, the Hz difference between boys and girls. The value of the standard error (Std. Error) is 6.3, representing the uncertainty in the estimate. These values correspond closely to the estimates of 2.3 and 6.4 respectively provided by our Bayesian model using the hypothesis function above. Obviously this situation is not ideal if you plan to compare many groups. In contrast, with our brm model we can easily compare any of the four groups using the method outlined above, without ever having to re-fit the model. 4.8 Exercises "]]
