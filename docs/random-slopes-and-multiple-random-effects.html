<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Random slopes and multiple random effects | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R</title>
  <meta name="description" content="Bayesian Models for Repeated-Measures" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Random slopes and multiple random effects | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://santiagobarreda.com" />
  
  <meta property="og:description" content="Bayesian Models for Repeated-Measures" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Random slopes and multiple random effects | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R" />
  
  <meta name="twitter:description" content="Bayesian Models for Repeated-Measures" />
  

<meta name="author" content="Santiago Bareda" />


<meta name="date" content="2021-08-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="continuous-predictors-and-their-interactions-with-factors.html"/>
<link rel="next" href="plot-code.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Models for Linguists</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><i class="fa fa-check"></i><b>1</b> Inspecting a single group of observations: Introduction to regression models</a>
<ul>
<li class="chapter" data-level="1.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#data-and-research-questions"><i class="fa fa-check"></i><b>1.1</b> Data and research questions</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#inspecting-the-central-location-and-spread-of-values"><i class="fa fa-check"></i><b>1.1.1</b> Inspecting the central location and spread of values</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#probability-distributions"><i class="fa fa-check"></i><b>1.2</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#the-normal-distribution"><i class="fa fa-check"></i><b>1.2.1</b> The normal distribution</a></li>
<li class="chapter" data-level="1.2.2" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#referring-to-the-normal-distribution-to-make-inferences"><i class="fa fa-check"></i><b>1.2.2</b> Referring to the normal distribution to make inferences</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#probabilities-of-events-and-likelihoods-of-parameters"><i class="fa fa-check"></i><b>1.3</b> Probabilities of events and likelihoods of parameters</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#calculating-likelihood-functions"><i class="fa fa-check"></i><b>1.3.1</b> Calculating likelihood functions</a></li>
<li class="chapter" data-level="1.3.2" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#making-inferences-using-likelihoods"><i class="fa fa-check"></i><b>1.3.2</b> Making inferences using likelihoods</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#bayesian-models"><i class="fa fa-check"></i><b>1.4</b> Bayesian models</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#what-are-regression-models"><i class="fa fa-check"></i><b>1.4.1</b> What are regression models?</a></li>
<li class="chapter" data-level="1.4.2" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#whats-bayesian-about-these-models"><i class="fa fa-check"></i><b>1.4.2</b> What’s ‘Bayesian’ about these models?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#posterior-distributions"><i class="fa fa-check"></i><b>1.5</b> Posterior distributions</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#sampling-from-the-posterior"><i class="fa fa-check"></i><b>1.5.1</b> Sampling from the posterior</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#exercises"><i class="fa fa-check"></i><b>1.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><i class="fa fa-check"></i><b>2</b> Inspecting a ‘single group’ of observations using a Bayesian multilevel model</a>
<ul>
<li class="chapter" data-level="2.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#data-and-research-questions-1"><i class="fa fa-check"></i><b>2.1</b> Data and research questions</a></li>
<li class="chapter" data-level="2.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#estimating-a-single-mean-with-the-brms-package"><i class="fa fa-check"></i><b>2.2</b> Estimating a single mean with the <code>brms</code> package</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#description-of-the-model"><i class="fa fa-check"></i><b>2.2.1</b> Description of the model</a></li>
<li class="chapter" data-level="2.2.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#the-model-formula"><i class="fa fa-check"></i><b>2.2.2</b> The model formula</a></li>
<li class="chapter" data-level="2.2.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#fitting-the-model-calling-the-brm-function"><i class="fa fa-check"></i><b>2.2.3</b> Fitting the model: Calling the <code>brm</code> function</a></li>
<li class="chapter" data-level="2.2.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#interpreting-the-model-the-print-statement"><i class="fa fa-check"></i><b>2.2.4</b> Interpreting the model: the print statement</a></li>
<li class="chapter" data-level="2.2.5" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#seeing-the-samples"><i class="fa fa-check"></i><b>2.2.5</b> Seeing the samples</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#repeated-measures-data"><i class="fa fa-check"></i><b>2.3</b> Repeated measures data</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#multilevel-models"><i class="fa fa-check"></i><b>2.3.1</b> Multilevel models</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#estimating-a-multilevel-model-with-brms"><i class="fa fa-check"></i><b>2.4</b> Estimating a multilevel model with <code>brms</code></a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#description-of-the-model-1"><i class="fa fa-check"></i><b>2.4.1</b> Description of the model</a></li>
<li class="chapter" data-level="2.4.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#fitting-the-model"><i class="fa fa-check"></i><b>2.4.2</b> Fitting the model</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#checking-model-convergence"><i class="fa fa-check"></i><b>2.5</b> Checking model convergence</a></li>
<li class="chapter" data-level="2.6" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#specifying-prior-probabilities"><i class="fa fa-check"></i><b>2.6</b> Specifying prior probabilities</a></li>
<li class="chapter" data-level="2.7" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#answering-our-research-questions"><i class="fa fa-check"></i><b>2.7</b> Answering our research questions</a></li>
<li class="chapter" data-level="2.8" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#simulating-data-using-our-model-parameters"><i class="fa fa-check"></i><b>2.8</b> Simulating data using our model parameters</a></li>
<li class="chapter" data-level="2.9" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#frequentist-corner"><i class="fa fa-check"></i><b>2.9</b> Frequentist corner</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#bayesian-multilevel-modesl-vs.-lmer"><i class="fa fa-check"></i><b>2.9.1</b> Bayesian multilevel modesl vs. lmer</a></li>
<li class="chapter" data-level="2.9.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#bayesian-multilevel-modesl-vs.-the-one-sample-t-test"><i class="fa fa-check"></i><b>2.9.2</b> Bayesian multilevel modesl vs. the one-sample t-test</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#exercises-1"><i class="fa fa-check"></i><b>2.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html"><i class="fa fa-check"></i><b>3</b> Comparing two groups of observations: Factors and contrasts</a>
<ul>
<li class="chapter" data-level="3.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#data-and-research-questions-2"><i class="fa fa-check"></i><b>3.1</b> Data and research questions</a></li>
<li class="chapter" data-level="3.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#estimating-the-difference-between-two-means-with-brms"><i class="fa fa-check"></i><b>3.2</b> Estimating the difference between two means with ‘brms’</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-the-model-1"><i class="fa fa-check"></i><b>3.2.1</b> Fitting the model</a></li>
<li class="chapter" data-level="3.2.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#interpreting-the-model"><i class="fa fa-check"></i><b>3.2.2</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#contrasts"><i class="fa fa-check"></i><b>3.3</b> Contrasts</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#treatment-coding"><i class="fa fa-check"></i><b>3.3.1</b> Treatment coding</a></li>
<li class="chapter" data-level="3.3.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#sum-coding"><i class="fa fa-check"></i><b>3.3.2</b> Sum coding</a></li>
<li class="chapter" data-level="3.3.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#comparison-of-sum-and-treatment-coding"><i class="fa fa-check"></i><b>3.3.3</b> Comparison of sum and treatment coding</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#refitting-the-model-with-sum-coding"><i class="fa fa-check"></i><b>3.4</b> Refitting the model with sum coding</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-the-model-2"><i class="fa fa-check"></i><b>3.4.1</b> Fitting the model</a></li>
<li class="chapter" data-level="3.4.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#description-of-the-model-2"><i class="fa fa-check"></i><b>3.4.2</b> Description of the model</a></li>
<li class="chapter" data-level="3.4.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#interpreting-the-model-1"><i class="fa fa-check"></i><b>3.4.3</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#random-effects"><i class="fa fa-check"></i><b>3.5</b> ‘Random’ Effects</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#random-effects-priors-and-pooling"><i class="fa fa-check"></i><b>3.5.1</b> Random effects, priors and pooling</a></li>
<li class="chapter" data-level="3.5.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#inspecting-the-random-effects"><i class="fa fa-check"></i><b>3.5.2</b> Inspecting the random effects</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#but-what-does-it-all-mean"><i class="fa fa-check"></i><b>3.6</b> But what does it all mean?</a></li>
<li class="chapter" data-level="3.7" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#simulating-the-two-group-model"><i class="fa fa-check"></i><b>3.7</b> Simulating the two-group model</a></li>
<li class="chapter" data-level="3.8" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#frequentist-corner-1"><i class="fa fa-check"></i><b>3.8</b> Frequentist corner</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#bayesian-multilevel-modesl-vs.-lmer-1"><i class="fa fa-check"></i><b>3.8.1</b> Bayesian multilevel modesl vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#exercises-2"><i class="fa fa-check"></i><b>3.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html"><i class="fa fa-check"></i><b>4</b> Comparing many groups: ANOVA and interactions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#data-and-research-questions-3"><i class="fa fa-check"></i><b>4.1</b> Data and research questions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#factors-as-batches-effects"><i class="fa fa-check"></i><b>4.1.1</b> Factors as ‘batches’ effects</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#comparing-four-or-any-number-of-groups"><i class="fa fa-check"></i><b>4.2</b> Comparing four (or any number of) groups</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#the-model"><i class="fa fa-check"></i><b>4.2.1</b> The model</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#investigating-many-factors-simultaneously-analysis-of-variance"><i class="fa fa-check"></i><b>4.3</b> Investigating many factors simultaneously: Analysis of Variance</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#description-of-the-model-3"><i class="fa fa-check"></i><b>4.3.1</b> Description of the model</a></li>
<li class="chapter" data-level="4.3.2" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#fitting-the-model-and-interpreting-the-results"><i class="fa fa-check"></i><b>4.3.2</b> Fitting the model and interpreting the results</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#investigating-model-fit"><i class="fa fa-check"></i><b>4.4</b> Investigating model fit</a></li>
<li class="chapter" data-level="4.5" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#interactions-and-interaction-plots"><i class="fa fa-check"></i><b>4.5</b> Interactions and interaction plots</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#interactions-in-our-f0-data"><i class="fa fa-check"></i><b>4.5.1</b> Interactions in our f0 data</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#investigating-interactions-with-a-model"><i class="fa fa-check"></i><b>4.6</b> Investigating interactions with a model</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#fitting-the-model-and-interpreting-the-results-1"><i class="fa fa-check"></i><b>4.6.1</b> Fitting the model and interpreting the results</a></li>
<li class="chapter" data-level="4.6.2" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#assessing-model-fit"><i class="fa fa-check"></i><b>4.6.2</b> Assessing model fit</a></li>
<li class="chapter" data-level="4.6.3" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#making-plots"><i class="fa fa-check"></i><b>4.6.3</b> Making plots</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#frequentist-corner-2"><i class="fa fa-check"></i><b>4.7</b> Frequentist corner</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#bayesian-multilevel-modesl-vs.-lmer-2"><i class="fa fa-check"></i><b>4.7.1</b> Bayesian multilevel modesl vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#exercises-3"><i class="fa fa-check"></i><b>4.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html"><i class="fa fa-check"></i><b>5</b> Continuous predictors and their interactions with factors</a>
<ul>
<li class="chapter" data-level="5.1" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#data-and-research-questions-4"><i class="fa fa-check"></i><b>5.1</b> Data and research questions</a></li>
<li class="chapter" data-level="5.2" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#continuous-predictors-modeling-variation-along-lines"><i class="fa fa-check"></i><b>5.2</b> Continuous predictors: modeling variation along lines</a></li>
<li class="chapter" data-level="5.3" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#models-with-a-single-slope-and-intercept"><i class="fa fa-check"></i><b>5.3</b> Models with a single slope and intercept</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#description-of-the-model-4"><i class="fa fa-check"></i><b>5.3.1</b> Description of the model</a></li>
<li class="chapter" data-level="5.3.2" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#fitting-the-model-3"><i class="fa fa-check"></i><b>5.3.2</b> Fitting the model</a></li>
<li class="chapter" data-level="5.3.3" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#interpreting-the-model-2"><i class="fa fa-check"></i><b>5.3.3</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#centering-predictors"><i class="fa fa-check"></i><b>5.4</b> Centering predictors</a></li>
<li class="chapter" data-level="5.5" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#interactions-in-our-line-parameters"><i class="fa fa-check"></i><b>5.5</b> Interactions in our line parameters</a></li>
<li class="chapter" data-level="5.6" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#models-with-group-dependent-intercepts-but-shared-slopes"><i class="fa fa-check"></i><b>5.6</b> Models with group-dependent intercepts, but shared slopes</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#description-of-the-model-5"><i class="fa fa-check"></i><b>5.6.1</b> Description of the model</a></li>
<li class="chapter" data-level="5.6.2" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#fitting-the-model-4"><i class="fa fa-check"></i><b>5.6.2</b> Fitting the model</a></li>
<li class="chapter" data-level="5.6.3" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#the-effect-of-including-a-slope"><i class="fa fa-check"></i><b>5.6.3</b> The effect of including a slope</a></li>
<li class="chapter" data-level="5.6.4" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#interpreting-group-effects-in-the-presence-of-a-continuous-predictor"><i class="fa fa-check"></i><b>5.6.4</b> Interpreting group effects in the presence of a continuous predictor</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#models-with-group-dependent-slopes-and-intercepts"><i class="fa fa-check"></i><b>5.7</b> Models with group-dependent slopes and intercepts</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#description-of-the-model-6"><i class="fa fa-check"></i><b>5.7.1</b> Description of the model</a></li>
<li class="chapter" data-level="5.7.2" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#fitting-the-model-5"><i class="fa fa-check"></i><b>5.7.2</b> Fitting the model</a></li>
<li class="chapter" data-level="5.7.3" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#interpreting-the-model-3"><i class="fa fa-check"></i><b>5.7.3</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#exercises-4"><i class="fa fa-check"></i><b>5.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html"><i class="fa fa-check"></i><b>6</b> Random slopes and multiple random effects</a>
<ul>
<li class="chapter" data-level="6.1" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#data-and-research-questions-5"><i class="fa fa-check"></i><b>6.1</b> Data and research questions</a></li>
<li class="chapter" data-level="6.2" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#repeated-measures-and-speaker-dependent-parameter-values"><i class="fa fa-check"></i><b>6.2</b> Repeated measures and speaker-dependent parameter values</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#description-of-the-model-7"><i class="fa fa-check"></i><b>6.2.1</b> Description of the model</a></li>
<li class="chapter" data-level="6.2.2" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#fitting-the-model-6"><i class="fa fa-check"></i><b>6.2.2</b> Fitting the model</a></li>
<li class="chapter" data-level="6.2.3" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#interpreting-the-model-4"><i class="fa fa-check"></i><b>6.2.3</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#random-effects-and-the-multivariate-normal-distribution"><i class="fa fa-check"></i><b>6.3</b> Random effects and the multivariate normal distribution</a></li>
<li class="chapter" data-level="6.4" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#random-slopes"><i class="fa fa-check"></i><b>6.4</b> Random slopes</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#description-of-the-model-8"><i class="fa fa-check"></i><b>6.4.1</b> Description of the model</a></li>
<li class="chapter" data-level="6.4.2" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#fitting-the-model-7"><i class="fa fa-check"></i><b>6.4.2</b> Fitting the model</a></li>
<li class="chapter" data-level="6.4.3" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#interpreting-the-model-5"><i class="fa fa-check"></i><b>6.4.3</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#more-predictors-and-more-random-slopes"><i class="fa fa-check"></i><b>6.5</b> More predictors and more random slopes</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#adding-another-random-slope"><i class="fa fa-check"></i><b>6.5.1</b> Adding another random slope</a></li>
<li class="chapter" data-level="6.5.2" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#adding-random-factors"><i class="fa fa-check"></i><b>6.5.2</b> Adding random factors</a></li>
<li class="chapter" data-level="6.5.3" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#the-independence-of-continuous-predictors"><i class="fa fa-check"></i><b>6.5.3</b> The independence of continuous predictors</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#answering-our-research-questions-1"><i class="fa fa-check"></i><b>6.6</b> Answering our research questions</a></li>
<li class="chapter" data-level="6.7" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#frequentist-corner-3"><i class="fa fa-check"></i><b>6.7</b> Frequentist corner</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#bayesian-multilevel-modesl-vs.-lmer-3"><i class="fa fa-check"></i><b>6.7.1</b> Bayesian multilevel modesl vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#exercises-5"><i class="fa fa-check"></i><b>6.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="plot-code.html"><a href="plot-code.html"><i class="fa fa-check"></i><b>7</b> Plot Code</a></li>
<li class="divider"></li>
<li><a href="http://www.santiagobarreda.com" target="blank">Written by Santiago Barreda</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-slopes-and-multiple-random-effects" class="section level1" number="6">
<h1><span class="header-section-number">Chapter 6</span> Random slopes and multiple random effects</h1>
<p>To this point we’ve been fitting realistic, but relatively simple models. Our models so far have only included a single random effect: the <span class="math inline">\(\alpha_{[speaker]}\)</span> parameter that represents between-speaker variation in the intercept. What about between-speaker variation in all of the other effects we’ve discussed?</p>
<p>For example, consider the experiment regarding coffee and reading times that has been mentioned in the previous chapters. What if we did a within-subjects design and tested everyone in the coffee and water conditions. Maybe we expect large differences in the effect for coffee from person to person. Maybe there’s even interesting patterns in these effects?</p>
<p>These random between-speaker differences in effects are sometimes called ‘random slopes’ (for continuous predictors) or ‘random effects’ (for factors) when they are included in your model. This is because since speakers are selected randomly and vary randomly, speaker-dependent effects will also tend to be random variables. For example, if the average speaking rate of different people is a random variable (a random by-subject intercept), then the between-speaker change in this rate induced by the consumption of coffee will also be a random variable (a random by-subject effect for coffee).</p>
<p>In this chapter we’re going to learn to build models that include terms that will model consistent between-speaker variation in the parameters in our models. Fortunately, we’ve already discussed all of the component parts that make up our models. We’ll see that more complicated models are just made up of many smaller components, all working together.</p>
<div id="data-and-research-questions-5" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Data and research questions</h2>
<p>Random by-subject effects for different predictors is not so much a data design as it is an aspect of your model. What I mean by that is that often, the same data could potentially be analyzed with or without the random by-subject effect being included in the model.</p>
<p>However, there is one absolutely essential limitation to this: if you want to test the “random” effect of a predictor according to any other factor (i.e., listener), that predictor <strong>must</strong> be crossed with that factor. For example, if you want to test the random effect for coffee on subjects, you need to test subjects in both water and coffee conditions. This should be obvious: how can you talk about the effect of coffee on specific individuals when you did not observe those specific individuals across both conditions?</p>
<p>We already saw an example of this in our Hillenbrand et al. production data. It is <strong>impossible</strong> to include <code>adult</code> as a by-speaker random effect. What I mean by this is that you cannot test for the individual effect of adultness on each speaker since you only observed them either as adults or as children. Speaker is not <em>crossed</em> with adult and so the random by-subject effect for adultness simply cannot be estimated. If something is mysteriously wrong with your model, you may be trying to estimate effects that cannot be estimated.</p>
<p>The figure below shows the designs presented in Chapter 4, and indicates which random effects may be estimated for each design (i.e., those crossed with subject).</p>
<div class="figure" style="text-align: center"><span id="fig:F5-designfig2"></span>
<img src="images/design_ch5.png" alt="Data from four groups of subjects (S) divided according to a two grouping factors A and B. Estimable random effects indicated by check marks." width="100%" />
<p class="caption">
Figure 6.1: Data from four groups of subjects (S) divided according to a two grouping factors A and B. Estimable random effects indicated by check marks.
</p>
</div>
<p>We’re going to continue analyzing the results of a listening experiment carried out using the Hillenbrand et al. data, presented in Chapter 5. As described in the previous chapter, ten listeners heard productions of ‘hod’ and ‘heed’ produced by all 139 speakers in the dataset, presented at random. For each trial, listeners reported the height of the speaker (in feet and inches) and guessed whether the speaker was a boy, girl, man or woman.</p>
<p>We’re going to analyze the full data, meaning we have 239 observations per listener and 2390 observations overall. In this chapter, we’re going to flip the dependent and independent variables from last chapter and consider variation in perceived height as a function of f0 (and other predictors). This model makes more sense as linguists because it corresponds to a question linguists actually ask: How do you know what <em>kind</em> of person is speaking from their voice? A model predicting perceived height from f0 helps us understand how continuous variation in f0 leads to continuous variation in the size of the speaker, which goes some way towards understanding the perception of what are called the <em>indexical</em> characteristics of the speaker (things like gender, age, size, and so on).</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="random-slopes-and-multiple-random-effects.html#cb127-1" aria-hidden="true" tabindex="-1"></a>url1 <span class="ot">=</span> <span class="st">&quot;https://raw.githubusercontent.com/santiagobarreda/stats-class/master/data/&quot;</span></span>
<span id="cb127-2"><a href="random-slopes-and-multiple-random-effects.html#cb127-2" aria-hidden="true" tabindex="-1"></a>url2 <span class="ot">=</span> <span class="st">&quot;h95_experiment_data.csv&quot;</span></span>
<span id="cb127-3"><a href="random-slopes-and-multiple-random-effects.html#cb127-3" aria-hidden="true" tabindex="-1"></a>h95 <span class="ot">=</span> <span class="fu">read.csv</span> (<span class="fu">url</span>(<span class="fu">paste0</span> (url1, url2)))</span></code></pre></div>
<p>Below we can see the distribution of perceived height plotted according to f0, individually for each listener. Clearly, there is a general tendency for perceived height to decrease as f0 increases resulting in a negative slope in the relationship. This relationship is not really a straight line for most subjects, but is linear enough to try this model as a first step.</p>
<div class="figure"><span id="fig:F6-1"></span>
<img src="06_files/figure-html/F6-1-1.png" alt="Each plot shows responses from a single subject." width="768" />
<p class="caption">
Figure 6.2: Each plot shows responses from a single subject.
</p>
</div>
<p>In Figure <a href="random-slopes-and-multiple-random-effects.html#fig:F6-2">6.3</a>, we compare the data from all subjects using the same colors as above. There is clearly quite a bit of general agreement between listeners. However, we can also clearly see that there is between-subject variation in responses.</p>
<div class="figure"><span id="fig:F6-2"></span>
<img src="06_files/figure-html/F6-2-1.png" alt="Distribution of perceived height responses as a function of f0 for all listeners." width="768" />
<p class="caption">
Figure 6.3: Distribution of perceived height responses as a function of f0 for all listeners.
</p>
</div>
</div>
<div id="repeated-measures-and-speaker-dependent-parameter-values" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Repeated measures and speaker-dependent parameter values</h2>
<p>In Chapter 5 we saw that in order to encode group-specific regression lines in our model, we need to include the group predictor and an interaction between the group predictor and our continuous predictor. We also know that a predictor like listener/subject/participant is just a factor like any other. This suggests that to encode listener-specific lines in our model, we many need to include a predictor for listener and the interaction between listener and our continuous predictors.</p>
<p>In fact, this is precisely what random effects are: the interactions between your predictors and the random variables in your design. Random by-listener effects represent our listener effects, and random by-subject slopes represent the interaction between listener and our continuous predictor. In the context of our Bayesian multilevel models, we call them ‘random’ effects because they are estimated with partial-pooling. This means that these interaction terms are treated as coming from a distribution whose characteristics are estimated from the data itself (discussed in Chapter 2).</p>
<p>To highlight the nature of random effects and their similarity to interactions, we’re going to consider two approaches to including subject-specific slopes and intercepts in our model: one with random slopes by subject, and one with a fixed <span class="math inline">\(predictor \colon subject\)</span> interaction.</p>
<div id="description-of-the-model-7" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Description of the model</h3>
<p>We’re going to predict perceived height (in inches) as a function of centered log-f0 (the logarithm of the fundamental frequency), which will be referred to as <span class="math inline">\(g0\_c\)</span>. Our model formula is:</p>
<p><code>pheight ~ g0_c * subj + (1|speaker)</code></p>
<p>As we saw in the last chapter, including an interaction between our continuous predictor and a factor allows for arbitrarily different lines according to the factor. So, the inclusion of <code>g0_c * subj</code> allows the relationship between f0 and perceived height to vary arbitrarily according to listener (<code>subj</code>). In addition, the model also includes a random effect for speaker, meaning we allow the average height response to potentially vary across <em>speakers</em>.</p>
<p>The model formula above says “model perceived height as a function of centered log-f0 (<code>g0_c</code>) and include subject effects (i.e. subject-specific intercepts). Also, allow subject-specific use of centered log-f0 in the perception of height (using the g0_c:subj interaction)”.</p>
<p>We can build this model up from the equation for a single line using the information outlined in the previous chapter. Recall that the formula for a line is:</p>
<p><span class="math display" id="eq:61">\[
\mu = a + b \times x
\tag{6.1}
\]</span></p>
<p>Where our predicted value (<span class="math inline">\(\mu\)</span>) varies along a line with an intercept of <span class="math inline">\(a\)</span> and a slope of <span class="math inline">\(b\)</span>. We can decompose the intercept and slope terms in an ‘ANOVA-like decomposition’ as below, given predictors <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>:</p>
<p><span class="math display" id="eq:62">\[
\mu = (Intercept + A + B + ...) + (Slope + Slope \colon A + Slope \colon B + ...) \times x
\tag{6.2}
\]</span></p>
<p>Above, the line intercept is broken up into a model intercept, and effects for A and B. The slope is broken up into a ‘main effect’ for slope (basically a slope intercept) and the factor by slope interactions (e.g., <span class="math inline">\(Slope \colon A\)</span>).</p>
<p>Below, the equation is expanded further by removing the parenthesis and multiplying each slope term by our continuous predictor (<span class="math inline">\(\mathrm{x}\)</span>).</p>
<p><span class="math display" id="eq:63">\[
\mu = Intercept + A + B + ... + Slope \times x + slope \colon A \times x + Slope \colon B \times x + ...
\tag{6.3}
\]</span></p>
<p>As our models get bigger and bigger, expressions like the one above can be difficult to interpret. A presentation like the one below can be clearer and easier to interpret (once you get used to it). The top line reminds you that you are modeling a line. The second and third lines provide information about expected variation in the intercept and the slope.</p>
<p><span class="math display" id="eq:64">\[\begin{equation}
\begin{split}
\mu = a + b * \mathrm{x} \\
a = Intercept + A + B + ... \\
b = Slope + slope \colon A + Slope \colon B + ... \\
\end{split}
\tag{6.4}
\end{equation}\]</span></p>
<p>If you prefer the ‘expanded’ version of the model equation it’s easy enough to get this. You simply place all of the components of the <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> equations on the same line, and multiply each term in the <span class="math inline">\(b\)</span> equation by the appropriate continuous predictor.</p>
<p>Below is the structure for our model that treats subject as a fixed effect (just like <span class="math inline">\(group\)</span> in the previous chapter). This model includes subject-specific intercepts for our lines (based on the <span class="math inline">\(subj\)</span> term) and subject-specific slopes for our lines (based on the <span class="math inline">\(g0\_c \colon subj\)</span> term). This model includes random intercepts for speakers (<span class="math inline">\(\alpha_{speaker}\)</span>), seen in the intercept equation. Note that our model does <em>not</em> include any random effects in the slopes equation.</p>
<p><span class="math display" id="eq:65">\[\begin{equation}
\begin{split}
\textrm{Likelihood:} \\
pheight_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = a_{[i]} + b_{[i]} * \mathrm{x}_{[i]}  \\ 
a_{[i]} = Intercept + subj_{[\mathrm{subj}_{[i]}]} + \alpha_{[\mathrm{speaker}_{[i]}]}  \\
b_{[i]} =  g0\_c + g0\_c \colon subj_{[\mathrm{subj}_{[i]}]} \\ \\
\textrm{Priors:} \\
\alpha_{speaker} \sim \mathcal{N}(0,\sigma_{speaker}) \\ \\ 
Intercept \sim t(3, 60, 12) \\
g0\_c \sim t(3, 0, 50) \\ 
g0\_c \colon subj \sim t(3, 0, 50) \\ 
subj \sim t(3, 0, 12) \\ 
\sigma_{error} \sim t(3, 0, 12) \\
\sigma_{speaker} \sim t(3, 0, 12) \\ 
\end{split}
\tag{6.5}
\end{equation}\]</span></p>
<p>Here’s a description of the model in plain English:</p>
<blockquote>
<p>Perceived height is normally distributed with a mean that varies trial to trial but a fixed standard deviation. The mean (expected value) varies along lines. The lines are specified by intercepts and slopes that vary trom trial to trial, and there is a single continuous predictor (g0_c). The intercept of these lines vary based on an overall intercept (the main effect), subject-specific deviations from the mean, and speaker-specific deviations from the mean. The slope of these lines vary based on an overall slope (the main effect) and subject-specific deviations from the average slope.</p>
</blockquote>
<blockquote>
<p>The speaker intercepts were drawn from a normal distribution with a mean of zero and a standard deviation estimated from the data. All other effects (e.g., the Intercept, g0_c, etc.) were treated as ‘fixed’ and drawn from prior distributions appropriate for their expected range of values (e.g., subj ~ t(3,0,12)).</p>
</blockquote>
</div>
<div id="fitting-the-model-6" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Fitting the model</h3>
<p>We fit the model that treats subject as a fixed effect:</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="random-slopes-and-multiple-random-effects.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself, or</span></span>
<span id="cb128-2"><a href="random-slopes-and-multiple-random-effects.html#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="co"># download pre-fit model from: </span></span>
<span id="cb128-3"><a href="random-slopes-and-multiple-random-effects.html#cb128-3" aria-hidden="true" tabindex="-1"></a><span class="co"># github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb128-4"><a href="random-slopes-and-multiple-random-effects.html#cb128-4" aria-hidden="true" tabindex="-1"></a><span class="co"># and load after placing in working directory</span></span>
<span id="cb128-5"><a href="random-slopes-and-multiple-random-effects.html#cb128-5" aria-hidden="true" tabindex="-1"></a><span class="co"># fixed_slopes_model = readRDS (&#39;6_fixed_slopes_model.RDS&#39;)</span></span>
<span id="cb128-6"><a href="random-slopes-and-multiple-random-effects.html#cb128-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-7"><a href="random-slopes-and-multiple-random-effects.html#cb128-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb128-8"><a href="random-slopes-and-multiple-random-effects.html#cb128-8" aria-hidden="true" tabindex="-1"></a>fixed_slopes_model <span class="ot">=</span></span>
<span id="cb128-9"><a href="random-slopes-and-multiple-random-effects.html#cb128-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (pheight <span class="sc">~</span> g0_c <span class="sc">*</span> subj <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>speaker), <span class="at">data =</span> h95, <span class="at">chains=</span><span class="dv">4</span>, <span class="at">cores=</span><span class="dv">4</span>,  </span>
<span id="cb128-10"><a href="random-slopes-and-multiple-random-effects.html#cb128-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">warmup=</span><span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">7500</span>, <span class="at">thin =</span> <span class="dv">4</span>, <span class="at">control =</span> <span class="fu">list</span>(<span class="at">adapt_delta =</span> <span class="fl">0.95</span>), </span>
<span id="cb128-11"><a href="random-slopes-and-multiple-random-effects.html#cb128-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 60, 24)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb128-12"><a href="random-slopes-and-multiple-random-effects.html#cb128-12" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 0.24)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb128-13"><a href="random-slopes-and-multiple-random-effects.html#cb128-13" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 24)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sd&quot;</span>)))</span>
<span id="cb128-14"><a href="random-slopes-and-multiple-random-effects.html#cb128-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-15"><a href="random-slopes-and-multiple-random-effects.html#cb128-15" aria-hidden="true" tabindex="-1"></a><span class="co"># save model</span></span>
<span id="cb128-16"><a href="random-slopes-and-multiple-random-effects.html#cb128-16" aria-hidden="true" tabindex="-1"></a><span class="co"># saveRDS (fixed_slopes_model, &#39;6_fixed_slopes_model.RDS&#39;)</span></span></code></pre></div>
</div>
<div id="interpreting-the-model-4" class="section level3" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> Interpreting the model</h3>
<p>We’re going to focus on the model fixed effects. Since we’re calculating subject-specific intercepts and slopes, we need 20 coefficients to represents all the lines for our ten subjects. Because we are using sum coding, the <code>Intercept</code> and <code>g0_c</code> parameters represent our mean overall intercept and slope across all subjects. The <code>subj</code> parameters represent subject-specific deviations from the mean intercept for a given subject, while the <code>g0_c:subject</code> interactions represent subject specific deviations from the overall slope. As a result, the line representing subject 8’s responses can be found by calculating <code>Intercept + subj8</code> for the intercept and <code>g0_c + g0_c:subj8</code> for the slope.</p>
<p>Recall (from Chapter 4) that the average value of a predictor is called the <em>main effect</em>. In contrast, the effect of a predictor at one specific level of another other factor is called a <em>simple effect</em>. So, the value of the intercept for a particular subject can be thought of at the simple effect of that predictor for that level of factor.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="random-slopes-and-multiple-random-effects.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="co"># inspect main effects</span></span>
<span id="cb129-2"><a href="random-slopes-and-multiple-random-effects.html#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="fu">fixef</span> (fixed_slopes_model)</span>
<span id="cb129-3"><a href="random-slopes-and-multiple-random-effects.html#cb129-3" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Est.Error       Q2.5      Q97.5</span></span>
<span id="cb129-4"><a href="random-slopes-and-multiple-random-effects.html#cb129-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept  60.98678449 0.4784301 60.0484335 61.9134125</span></span>
<span id="cb129-5"><a href="random-slopes-and-multiple-random-effects.html#cb129-5" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c       -6.28597349 1.4033403 -8.9682111 -3.5214787</span></span>
<span id="cb129-6"><a href="random-slopes-and-multiple-random-effects.html#cb129-6" aria-hidden="true" tabindex="-1"></a><span class="do">## subj1       1.16432587 0.2191837  0.7370882  1.5905736</span></span>
<span id="cb129-7"><a href="random-slopes-and-multiple-random-effects.html#cb129-7" aria-hidden="true" tabindex="-1"></a><span class="do">## subj2       1.15897715 0.2178242  0.7268558  1.5884516</span></span>
<span id="cb129-8"><a href="random-slopes-and-multiple-random-effects.html#cb129-8" aria-hidden="true" tabindex="-1"></a><span class="do">## subj3       0.08484842 0.2191453 -0.3439572  0.5161977</span></span>
<span id="cb129-9"><a href="random-slopes-and-multiple-random-effects.html#cb129-9" aria-hidden="true" tabindex="-1"></a><span class="do">## subj4       3.19209439 0.2196449  2.7737538  3.6216057</span></span>
<span id="cb129-10"><a href="random-slopes-and-multiple-random-effects.html#cb129-10" aria-hidden="true" tabindex="-1"></a><span class="do">## subj5      -1.99350871 0.2183408 -2.4207174 -1.5651102</span></span>
<span id="cb129-11"><a href="random-slopes-and-multiple-random-effects.html#cb129-11" aria-hidden="true" tabindex="-1"></a><span class="do">## subj6       0.03808015 0.2185083 -0.3916037  0.4690840</span></span>
<span id="cb129-12"><a href="random-slopes-and-multiple-random-effects.html#cb129-12" aria-hidden="true" tabindex="-1"></a><span class="do">## subj7      -1.35476612 0.2171118 -1.7884342 -0.9376645</span></span>
<span id="cb129-13"><a href="random-slopes-and-multiple-random-effects.html#cb129-13" aria-hidden="true" tabindex="-1"></a><span class="do">## subj8      -0.18965272 0.2172589 -0.6200814  0.2400315</span></span>
<span id="cb129-14"><a href="random-slopes-and-multiple-random-effects.html#cb129-14" aria-hidden="true" tabindex="-1"></a><span class="do">## subj9      -1.53045427 0.2166533 -1.9543467 -1.1057361</span></span>
<span id="cb129-15"><a href="random-slopes-and-multiple-random-effects.html#cb129-15" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c:subj1  0.97782028 0.7314227 -0.4547865  2.3773882</span></span>
<span id="cb129-16"><a href="random-slopes-and-multiple-random-effects.html#cb129-16" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c:subj2 -1.04728394 0.7340484 -2.4842509  0.3662594</span></span>
<span id="cb129-17"><a href="random-slopes-and-multiple-random-effects.html#cb129-17" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c:subj3  1.33942054 0.7252348 -0.1290505  2.7669004</span></span>
<span id="cb129-18"><a href="random-slopes-and-multiple-random-effects.html#cb129-18" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c:subj4  7.67663353 0.7400229  6.2212793  9.1142621</span></span>
<span id="cb129-19"><a href="random-slopes-and-multiple-random-effects.html#cb129-19" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c:subj5  2.00732223 0.7318437  0.5799876  3.4735872</span></span>
<span id="cb129-20"><a href="random-slopes-and-multiple-random-effects.html#cb129-20" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c:subj6 -4.77805879 0.7323175 -6.1988376 -3.3397408</span></span>
<span id="cb129-21"><a href="random-slopes-and-multiple-random-effects.html#cb129-21" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c:subj7  2.18304348 0.7355534  0.7304213  3.6183430</span></span>
<span id="cb129-22"><a href="random-slopes-and-multiple-random-effects.html#cb129-22" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c:subj8 -2.05792955 0.7389462 -3.4984697 -0.6021956</span></span>
<span id="cb129-23"><a href="random-slopes-and-multiple-random-effects.html#cb129-23" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c:subj9 -4.34455418 0.7365353 -5.7989383 -2.8925264</span></span></code></pre></div>
<p>Since we’re treating subject as a factor and using sum coding, notice that we don’t get the final level for the subject intercepts or slopes (i.e. there is no <code>subj10</code>). Unlike with a frequentist analysis, the value of the missing coefficients does not need to remain a mystery. We can recover this using the hypothesis function, though this can be a bit tedious when there are many levels for a factor.</p>
<p>I wrote a couple of functions that can help with recovering missing factor levels. First, there is a function called <code>divide_factors</code>. This function takes in a <code>brm</code> model and returns a list of matrices. Each matrix represents the samples for a single main effect or interaction term in your model.</p>
<p>We can apply this function to the model we fit above to inspect the output of the <code>divide_factors</code> function. Using the <code>names</code> function shows us that our output has four matrices corresponding to the effects for <code>(Intercept)</code>,<code>g0_c</code>, <code>subj</code>, and <code>g_c:subj</code>.</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="random-slopes-and-multiple-random-effects.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get individual factor matrices from brm model</span></span>
<span id="cb130-2"><a href="random-slopes-and-multiple-random-effects.html#cb130-2" aria-hidden="true" tabindex="-1"></a>factors <span class="ot">=</span> <span class="fu">divide_factors</span> (fixed_slopes_model)</span>
<span id="cb130-3"><a href="random-slopes-and-multiple-random-effects.html#cb130-3" aria-hidden="true" tabindex="-1"></a><span class="co"># check out names of factors</span></span>
<span id="cb130-4"><a href="random-slopes-and-multiple-random-effects.html#cb130-4" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span> (factors)</span>
<span id="cb130-5"><a href="random-slopes-and-multiple-random-effects.html#cb130-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;(Intercept)&quot; &quot;g0_c&quot;        &quot;subj&quot;        &quot;g0_c:subj&quot;</span></span></code></pre></div>
<p>We can use the <code>str</code> function to inspect the output. We can see that <code>(Intercept)</code> and <code>g0_c</code> are vectors (i.e. single columns) of length 6500 (our number of samples), while <code>subj</code> and <code>g_c:subj</code> are matrices with 6500 rows, but 9 columns (number of subjects - 1).</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="random-slopes-and-multiple-random-effects.html#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span> (factors)</span>
<span id="cb131-2"><a href="random-slopes-and-multiple-random-effects.html#cb131-2" aria-hidden="true" tabindex="-1"></a><span class="do">## List of 4</span></span>
<span id="cb131-3"><a href="random-slopes-and-multiple-random-effects.html#cb131-3" aria-hidden="true" tabindex="-1"></a><span class="do">##  $ (Intercept): num [1:6500] 61.3 61 61.4 60.9 61 ...</span></span>
<span id="cb131-4"><a href="random-slopes-and-multiple-random-effects.html#cb131-4" aria-hidden="true" tabindex="-1"></a><span class="do">##  $ g0_c       : num [1:6500] -6.31 -7.25 -7.65 -6.45 -7.75 ...</span></span>
<span id="cb131-5"><a href="random-slopes-and-multiple-random-effects.html#cb131-5" aria-hidden="true" tabindex="-1"></a><span class="do">##  $ subj       : num [1:6500, 1:9] 1.017 1.185 1.395 1.298 0.962 ...</span></span>
<span id="cb131-6"><a href="random-slopes-and-multiple-random-effects.html#cb131-6" aria-hidden="true" tabindex="-1"></a><span class="do">##   ..- attr(*, &quot;dimnames&quot;)=List of 2</span></span>
<span id="cb131-7"><a href="random-slopes-and-multiple-random-effects.html#cb131-7" aria-hidden="true" tabindex="-1"></a><span class="do">##   .. ..$ iterations: NULL</span></span>
<span id="cb131-8"><a href="random-slopes-and-multiple-random-effects.html#cb131-8" aria-hidden="true" tabindex="-1"></a><span class="do">##   .. ..$ parameters: chr [1:9] &quot;subj1&quot; &quot;subj2&quot; &quot;subj3&quot; &quot;subj4&quot; ...</span></span>
<span id="cb131-9"><a href="random-slopes-and-multiple-random-effects.html#cb131-9" aria-hidden="true" tabindex="-1"></a><span class="do">##  $ g0_c:subj  : num [1:6500, 1:9] 0.2202 -0.0829 0.1943 1.3944 1.5306 ...</span></span>
<span id="cb131-10"><a href="random-slopes-and-multiple-random-effects.html#cb131-10" aria-hidden="true" tabindex="-1"></a><span class="do">##   ..- attr(*, &quot;dimnames&quot;)=List of 2</span></span>
<span id="cb131-11"><a href="random-slopes-and-multiple-random-effects.html#cb131-11" aria-hidden="true" tabindex="-1"></a><span class="do">##   .. ..$ iterations: NULL</span></span>
<span id="cb131-12"><a href="random-slopes-and-multiple-random-effects.html#cb131-12" aria-hidden="true" tabindex="-1"></a><span class="do">##   .. ..$ parameters: chr [1:9] &quot;g0_c:subj1&quot; &quot;g0_c:subj2&quot; &quot;g0_c:subj3&quot; &quot;g0_c:subj4&quot; ...</span></span></code></pre></div>
<p>We can use a function I wrote called <code>add_missing</code> which will add missing levels to single factors (it doesn’t work for interactions for now). The process is very simple. Recall from Chapter 3 that the missing factor level will equal the negative sum of the other factors. From this we know that each sample of the missing factor level must equal the negative sum of the estimates for the 9 levels that <em>are</em> present. We have a matrix with 9 columns, and we would like a tenth column representing the coefficients we don’t have.</p>
<p>Recall from Chapter 2 that we are allowed to combine our parameter samples to answer questions about their values or combinations of these. This suggests we can add up the 9 columns we have in a row-wise manner (i.e. across rows), resulting in a single column representing the sum of the other columns. We flip the sign on this column and we now have a column that represents <em>the negative sum</em> of the other parameters. We stick this column onto the end of our existing matrix and we now have a ten-column matrix representing estimates for <em>all</em> of our factor levels.</p>
<p>The above summarizes the function of the <code>add_missing</code> function, and below it is used to recover the missing intercept and slope terms (those of <code>subj10</code>).</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="random-slopes-and-multiple-random-effects.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># add missing subject intercept effect</span></span>
<span id="cb132-2"><a href="random-slopes-and-multiple-random-effects.html#cb132-2" aria-hidden="true" tabindex="-1"></a>factors[[<span class="st">&quot;subj&quot;</span>]] <span class="ot">=</span> <span class="fu">add_missing</span> (factors[[<span class="st">&quot;subj&quot;</span>]])</span>
<span id="cb132-3"><a href="random-slopes-and-multiple-random-effects.html#cb132-3" aria-hidden="true" tabindex="-1"></a><span class="co"># add missing subject slope effect</span></span>
<span id="cb132-4"><a href="random-slopes-and-multiple-random-effects.html#cb132-4" aria-hidden="true" tabindex="-1"></a>factors[[<span class="st">&quot;g0_c:subj&quot;</span>]] <span class="ot">=</span> <span class="fu">add_missing</span> (factors[[<span class="st">&quot;g0_c:subj&quot;</span>]])</span></code></pre></div>
<p>I then use <code>brmplot</code> to plot the speaker intercept and slope effects, including the final recovered set of parameters:</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="random-slopes-and-multiple-random-effects.html#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb133-2"><a href="random-slopes-and-multiple-random-effects.html#cb133-2" aria-hidden="true" tabindex="-1"></a><span class="fu">brmplot</span> (factors[[<span class="st">&quot;subj&quot;</span>]], <span class="at">col =</span> cols) ; <span class="fu">abline</span> (<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb133-3"><a href="random-slopes-and-multiple-random-effects.html#cb133-3" aria-hidden="true" tabindex="-1"></a><span class="fu">brmplot</span> (factors[[<span class="st">&quot;g0_c:subj&quot;</span>]], <span class="at">col =</span> cols) ; <span class="fu">abline</span> (<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span></code></pre></div>
<div class="figure"><span id="fig:f6-3"></span>
<img src="06_files/figure-html/f6-3-1.png" alt="(left) Fixed-effects estimates of subject intercept effects. (right) Fixed-effects estimates of subject slope effects." width="768" />
<p class="caption">
Figure 6.4: (left) Fixed-effects estimates of subject intercept effects. (right) Fixed-effects estimates of subject slope effects.
</p>
</div>
<p>If we want to recover the <em>actual</em> speaker-specific intercepts and slopes (the simple effects), we need to add the speaker effects to their corresponding main effects terms. We can do this by adding the column representing each main effect to the matrix representing each set of subject interactions, as below. We could also do this with the hypothesis function but this way we can add all ten subjects’ slopes in a single operation, instead of having to write (or even copy) ten lines of code.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="random-slopes-and-multiple-random-effects.html#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="co"># add overall intercept to subject effects</span></span>
<span id="cb134-2"><a href="random-slopes-and-multiple-random-effects.html#cb134-2" aria-hidden="true" tabindex="-1"></a>subj_intercepts <span class="ot">=</span> factors[[<span class="st">&quot;(Intercept)&quot;</span>]] <span class="sc">+</span> factors[[<span class="st">&quot;subj&quot;</span>]]</span>
<span id="cb134-3"><a href="random-slopes-and-multiple-random-effects.html#cb134-3" aria-hidden="true" tabindex="-1"></a><span class="co"># add overall slope to subject slope effects</span></span>
<span id="cb134-4"><a href="random-slopes-and-multiple-random-effects.html#cb134-4" aria-hidden="true" tabindex="-1"></a>subj_slopes <span class="ot">=</span> factors[[<span class="st">&quot;g0_c&quot;</span>]] <span class="sc">+</span> factors[[<span class="st">&quot;g0_c:subj&quot;</span>]]</span></code></pre></div>
<p>I want to pause for a moment to highlight that everything to this point has involved the original <strong>samples</strong> from the posterior, not <em>summaries</em> of the samples. Any manipulations done to parameters (including any comparisons) need to be carried out on the samples, and then summarized (never summarized, and then compared).</p>
<p>For example, <code>subj_intercepts</code>, the sum of the overall intercept and the subject-specific intercept effects is still a matrix with ten columns and 6500 rows, representing the individual samples from the posterior distribution of each parameter.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="random-slopes-and-multiple-random-effects.html#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>( <span class="fu">round</span> ( subj_intercepts , <span class="dv">3</span> ) )</span>
<span id="cb135-2"><a href="random-slopes-and-multiple-random-effects.html#cb135-2" aria-hidden="true" tabindex="-1"></a><span class="do">##       subj1  subj2  subj3  subj4  subj5  subj6  subj7  subj8  subj9 subj10</span></span>
<span id="cb135-3"><a href="random-slopes-and-multiple-random-effects.html#cb135-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,] 62.339 62.790 61.641 64.905 59.008 61.347 59.750 60.958 59.741 60.750</span></span>
<span id="cb135-4"><a href="random-slopes-and-multiple-random-effects.html#cb135-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [2,] 62.161 62.134 61.071 64.067 59.011 60.838 59.832 60.910 59.144 60.587</span></span>
<span id="cb135-5"><a href="random-slopes-and-multiple-random-effects.html#cb135-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [3,] 62.785 62.419 61.316 64.498 59.232 61.654 60.327 61.181 59.824 60.667</span></span>
<span id="cb135-6"><a href="random-slopes-and-multiple-random-effects.html#cb135-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [4,] 62.180 62.219 60.886 64.023 59.134 60.946 59.616 60.716 58.898 60.195</span></span>
<span id="cb135-7"><a href="random-slopes-and-multiple-random-effects.html#cb135-7" aria-hidden="true" tabindex="-1"></a><span class="do">## [5,] 61.964 62.323 61.121 64.120 59.261 61.075 59.532 60.542 59.761 60.321</span></span>
<span id="cb135-8"><a href="random-slopes-and-multiple-random-effects.html#cb135-8" aria-hidden="true" tabindex="-1"></a><span class="do">## [6,] 61.905 61.601 60.894 63.631 58.602 61.029 59.257 60.500 59.197 60.035</span></span></code></pre></div>
<p>Only after we are done working with it, we can summarize these matrices:</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="random-slopes-and-multiple-random-effects.html#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="co"># find summary statistics for the posterior distributions of our parameters</span></span>
<span id="cb136-2"><a href="random-slopes-and-multiple-random-effects.html#cb136-2" aria-hidden="true" tabindex="-1"></a>subj_intercepts_summary <span class="ot">=</span> <span class="fu">posterior_summary</span> (factors[[<span class="st">&quot;(Intercept)&quot;</span>]] <span class="sc">+</span> factors[[<span class="st">&quot;subj&quot;</span>]])</span>
<span id="cb136-3"><a href="random-slopes-and-multiple-random-effects.html#cb136-3" aria-hidden="true" tabindex="-1"></a>subj_slopes_summary <span class="ot">=</span> <span class="fu">posterior_summary</span> (factors[[<span class="st">&quot;g0_c&quot;</span>]] <span class="sc">+</span> factors[[<span class="st">&quot;g0_c:subj&quot;</span>]])</span></code></pre></div>
<p>Resulting in a summary of the matrix where each row corresponds to a column from the <code>subj_intercepts</code> matrix above.</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="random-slopes-and-multiple-random-effects.html#cb137-1" aria-hidden="true" tabindex="-1"></a>subj_intercepts_summary</span>
<span id="cb137-2"><a href="random-slopes-and-multiple-random-effects.html#cb137-2" aria-hidden="true" tabindex="-1"></a><span class="do">##        Estimate Est.Error     Q2.5    Q97.5</span></span>
<span id="cb137-3"><a href="random-slopes-and-multiple-random-effects.html#cb137-3" aria-hidden="true" tabindex="-1"></a><span class="do">## subj1  62.15111 0.5290596 61.10673 63.16930</span></span>
<span id="cb137-4"><a href="random-slopes-and-multiple-random-effects.html#cb137-4" aria-hidden="true" tabindex="-1"></a><span class="do">## subj2  62.14576 0.5255985 61.09036 63.15278</span></span>
<span id="cb137-5"><a href="random-slopes-and-multiple-random-effects.html#cb137-5" aria-hidden="true" tabindex="-1"></a><span class="do">## subj3  61.07163 0.5283570 60.02235 62.10693</span></span>
<span id="cb137-6"><a href="random-slopes-and-multiple-random-effects.html#cb137-6" aria-hidden="true" tabindex="-1"></a><span class="do">## subj4  64.17888 0.5274135 63.14280 65.19576</span></span>
<span id="cb137-7"><a href="random-slopes-and-multiple-random-effects.html#cb137-7" aria-hidden="true" tabindex="-1"></a><span class="do">## subj5  58.99328 0.5243383 57.96506 60.01118</span></span>
<span id="cb137-8"><a href="random-slopes-and-multiple-random-effects.html#cb137-8" aria-hidden="true" tabindex="-1"></a><span class="do">## subj6  61.02486 0.5266767 59.98223 62.03750</span></span>
<span id="cb137-9"><a href="random-slopes-and-multiple-random-effects.html#cb137-9" aria-hidden="true" tabindex="-1"></a><span class="do">## subj7  59.63202 0.5237791 58.60875 60.64282</span></span>
<span id="cb137-10"><a href="random-slopes-and-multiple-random-effects.html#cb137-10" aria-hidden="true" tabindex="-1"></a><span class="do">## subj8  60.79713 0.5233061 59.76867 61.81433</span></span>
<span id="cb137-11"><a href="random-slopes-and-multiple-random-effects.html#cb137-11" aria-hidden="true" tabindex="-1"></a><span class="do">## subj9  59.45633 0.5243279 58.39773 60.45063</span></span>
<span id="cb137-12"><a href="random-slopes-and-multiple-random-effects.html#cb137-12" aria-hidden="true" tabindex="-1"></a><span class="do">## subj10 60.41684 0.5247678 59.37266 61.42216</span></span></code></pre></div>
<p>We can plot the subject effects and the actual subject-specific parameter estimates side by side as in Figure <a href="random-slopes-and-multiple-random-effects.html#fig:f6-4">6.5</a>. Clearly, the pattern is the same except for two key differences. First, there are shifts along the y axis due to the addition of the main effects. Second, the error around the estimates is larger when the main effects are added in. This is because the estimates on the right represent the sum of the uncertainty in each individual effect, and the uncertainty in the corresponding main effect.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="random-slopes-and-multiple-random-effects.html#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb138-2"><a href="random-slopes-and-multiple-random-effects.html#cb138-2" aria-hidden="true" tabindex="-1"></a><span class="fu">brmplot</span> (factors[[<span class="st">&quot;subj&quot;</span>]], <span class="at">col =</span> cols) ; <span class="fu">abline</span> (<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb138-3"><a href="random-slopes-and-multiple-random-effects.html#cb138-3" aria-hidden="true" tabindex="-1"></a><span class="fu">brmplot</span> (subj_intercepts_summary, <span class="at">col =</span> cols)</span>
<span id="cb138-4"><a href="random-slopes-and-multiple-random-effects.html#cb138-4" aria-hidden="true" tabindex="-1"></a><span class="fu">brmplot</span> (factors[[<span class="st">&quot;g0_c:subj&quot;</span>]], <span class="at">col =</span> cols) ; <span class="fu">abline</span> (<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb138-5"><a href="random-slopes-and-multiple-random-effects.html#cb138-5" aria-hidden="true" tabindex="-1"></a><span class="fu">brmplot</span> (subj_slopes_summary, <span class="at">col =</span> cols) ; <span class="fu">abline</span> (<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span></code></pre></div>
<div class="figure"><span id="fig:f6-4"></span>
<img src="06_files/figure-html/f6-4-1.png" alt="(top left) Fixed-effects estimates of subject intercept terms. (top left) Fixed-effects estimates of subject intercept (main effect + subject effect). (bottom left) Fixed-effects estimates of subject slope terms. (bottom right) Fixed-effects estimates of subject slopes (main effect + subject effect)." width="672" />
<p class="caption">
Figure 6.5: (top left) Fixed-effects estimates of subject intercept terms. (top left) Fixed-effects estimates of subject intercept (main effect + subject effect). (bottom left) Fixed-effects estimates of subject slope terms. (bottom right) Fixed-effects estimates of subject slopes (main effect + subject effect).
</p>
</div>
<p>In in Figure <a href="random-slopes-and-multiple-random-effects.html#fig:F6-5">6.6</a> we again see the distribution of perceived height plotted according to f0 (centered log-f0), individually for each subject. We can now add lines indicating predicted perceived height based on our model parameters.</p>
<div class="figure"><span id="fig:F6-5"></span>
<img src="06_files/figure-html/F6-5-1.png" alt="Each plot shows responses from a single subject. Lines indicate best fit line relating variables, as indicated by our fixed slopes model." width="768" />
<p class="caption">
Figure 6.6: Each plot shows responses from a single subject. Lines indicate best fit line relating variables, as indicated by our fixed slopes model.
</p>
</div>
<p>In Figure in Figure <a href="random-slopes-and-multiple-random-effects.html#fig:F6-6">6.7</a>, we again compare the data from all subjects using the same colors as above. This time, we add the regression lines for each subject so that we can compare the similarities/differences between them.</p>
<p>The fit provided by this model is not great: they make predictions (the lines) that don’t match the data well for <em>anyone</em>, suggesting that our model is really missing important information with respect to size perception. We will return to these issues later but will not worry about that for now.</p>
<div class="figure"><span id="fig:F6-6"></span>
<img src="06_files/figure-html/F6-6-1.png" alt="Distribution of perceived height responses as a function of f0 for all listeners. Lines indicate best-fit lines for each subject." width="768" />
<p class="caption">
Figure 6.7: Distribution of perceived height responses as a function of f0 for all listeners. Lines indicate best-fit lines for each subject.
</p>
</div>
</div>
</div>
<div id="random-effects-and-the-multivariate-normal-distribution" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Random effects and the multivariate normal distribution</h2>
<p>Recall from Chapter 2 that when you place a predictor in the formula in parenthesis and on the right-hand-side of a pipe, like this <code>(effect|predictor)</code>, you tell brm that you expect data to be clustered according to each category represented in the grouping vector. Further, whatever you put in the left-hand-side of the parentheses <code>( in here | predictor )</code> is the model for each subcluster. However, to this point we have not considered putting anything other than a <code>1</code> on the left of the pipe in the section where we define random effects.</p>
<p>If subject is our clustering factor, this means that each individual subject (i.e. each level) gets their own model. So, a <code>(1|speaker)</code> term says “we’re going to have an intercept for every level of speaker in our model”. In the same way, a <code>(g0_c|subj)</code> term says “we’re going to have an intercept and a g0_c slope for every level of subject in our data” (remember the intercept is assumed even if you don’t include a <code>1</code>).</p>
<p>So we may write a model formula such as:</p>
<p><code>pheight ~ g0_c + (g0_c |subj) + (1|speaker)</code></p>
<p>Our model formula could <em>conceivably</em> be written like this (though this <strong>won’t work</strong> because the syntax is wrong):</p>
<p><code>pheight ~ 1 + g0_c + (pheight ~ 1 + g0_c |subj) + (pheight ~ 1|speaker)</code></p>
<p>Again, this won’t actually work, but it might be helpful to think of your formulas this way. Notice that the formula inside the subject parenthesis is the same as the formula outside the parenthesis. In each case we are just estimating perceived height according to a slope and an intercept. The equation outside the parentheses (<code>pheight ~ 1 + g0_c</code>) tells our model to estimate an overall slope and intercept, and the part inside the parentheses (<code>(pheight ~ 1 + g0_c |subj)</code>) tells our model to do the same thing individually for each subject. Normally, we omit the <code>1</code> for the intercept, and we only include the dependent variable (and the <code>~</code>) in the outside formula. However, the formula above is an accurate representation of what our model formula is really doing.</p>
<p>So, a model formula like this <code>y ~ g0_c (g0_c | subject)</code> tells <code>brm</code> to estimate a random intercept for each subject, and also a random effect for <code>g0_c</code> for each speaker. Thus, each level of the clustering factor (<code>subject</code>) is represented by two random parameters, the intercept and the slope for <code>g0_c</code>. Random effects in multilevel models are usually treated as draws from multivariate normal distributions. What I mean by this is that the random intercept and slope for each speaker are treated as a single multidimensional variable, rather than as two independent variables.</p>
<p>The main difference between treating our random coefficients as a single variable rather than two variables is that when we do this, we also estimate the correlation between them. The easiest way to imagine this is by drawing a bivariate (2-dimensional) normal variable and plotting it. This is what I’ve done below, with simulated intercept and slope parameters drawn at random from a multivariate normal distribution.</p>
<p>In the left column below I compare three bivariate normal variables along the two dimensions. In the absence of any correlation between variables, a plot of this distribution will be <em>spherical</em> (or circular in 2 dimensions). When there is a correlation between the two dimensions, the distribution starts looking more and more like a straight line. When there is a negative correlation, the line just points down rather than up.</p>
<p>Note the the marginal (independent) distributions of the variables (the left and right histograms) don’t change as the correlation changes. The correlation is a reflection of the <em>joint</em> variation in the two variables and will not necessarily be evident in the marginal distributions of each variable.</p>
<div class="figure"><span id="fig:unnamed-chunk-13"></span>
<img src="06_files/figure-html/unnamed-chunk-13-1.png" alt="10,000 bivatiate normal draws of simulated intercept and slope coefficients from distributions with a mean of 0 and a standard deviation of 1. The correlation of the variables is 0 (top), 0.5 (middle) and 0.9 (bottom). The left column presents both variables together, the middle column presents intercepts and the right column presents slopes. " width="672" />
<p class="caption">
Figure 6.8: 10,000 bivatiate normal draws of simulated intercept and slope coefficients from distributions with a mean of 0 and a standard deviation of 1. The correlation of the variables is 0 (top), 0.5 (middle) and 0.9 (bottom). The left column presents both variables together, the middle column presents intercepts and the right column presents slopes.
</p>
</div>
<p>When our dimensions are uncorrelated they are independent. The value of one does not help you understand the other. However, when the dimensions <em>are</em> correlated we can use this to make better predictions using our data. For example, an intercept of 2 in the bottom row in the figure above is very likely to be paired with a slope of 2, but <em>extremely</em> unlikely to be seen with a slope of -2. In contrast, in the top row a slope of 2 and -2 seem about equally likely given an intercept of 2. So, when we use multiple random predictors per grouping factor, we are really drawing from a multivariate normal distributions that acknowledges the relationships between random predictors in our data, within-cluster (e.g. subject/participant/speaker).</p>
<p>For example, consider the experiment regarding coffee and speaking rate. Perhaps people who speak fast normally get an even larger boost to their speaking rate from coffee. On the other hand, maybe since they already speak fast, the effect for coffee is diminished in these speakers. In other case, the relationship between the intercept for these speakers (baseline rate) and their coffee effect would not be independent.</p>
<p>The shape of the multivariate normal distribution (i.e. how much it looks liek a circle vs an ellipse) is determined by a covariance matrix called sigma (<span class="math inline">\(\Sigma\)</span>). This matrix is a square <span class="math inline">\(n\)</span> x <span class="math inline">\(n\)</span> matrix for a variable with <span class="math inline">\(n\)</span> dimensions. When we dealt with unidimensional normal distributions for our previous random effects, we specified priors for the (unidimensional) standard deviations using t distributions. The specification of priors for our covariance matrix is only slightly more complicated.</p>
<p>In our models, we won’t actually include priors for <span class="math inline">\(\Sigma\)</span> directly. This is because <code>brms</code> (and STAN) build up <span class="math inline">\(\Sigma\)</span> for us from the components we <em>do</em> specify. This is more information that you <em>really</em> need, but it helps to understand why the priors are specified the way they are for our random effects.</p>
<p>Consider two random effects, a random by subject intercept <span class="math inline">\(\alpha_{[subj]}\)</span>, and a random by-subject slope called _{[subj]}. The covariance matrix for our random effects is created by multiplying the standard deviations of our individual dimensions by a correlation matrix (<span class="math inline">\(R\)</span>) specifying the correlations between each dimension. The operation is like this:</p>
<p><span class="math display" id="eq:66">\[\begin{equation}
\begin{split}
\Sigma = \begin{bmatrix} \sigma_{\alpha_{[subj]}} &amp; 0 \\ 0 &amp; \sigma_{\beta_{[subj]}} \\ \end{bmatrix} 
\times R \times
\begin{bmatrix} \sigma_{\alpha_{[subj]}} &amp; 0 \\ 0 &amp; \sigma_{\beta_{[subj]}} \\ \end{bmatrix} \\
\end{split}
\tag{6.6}
\end{equation}\]</span></p>
<p>The values in the outside matrices are the the standard deviations of the random intercepts (<span class="math inline">\(\sigma_{\alpha_{[subj]}}\)</span>) and slopes (<span class="math inline">\(\sigma_{\beta_{[subj]}}\)</span>) individually. The correlation matrix <span class="math inline">\(R\)</span> contains information about the correlation between the dimensions of the variable (e.g., <span class="math inline">\(\rho_{\alpha_{[subj]} \beta _{[subj]}}\)</span>).</p>
<p>So, when we have multiple random effects we have a multidimensional variable, and we need to specify priors for each dimension and for the correlation between all dimensions (but not for <span class="math inline">\(\Sigma\)</span> directly).</p>
<p>We provide priors for the standard deviations of the individual dimensions in the same way as we do for ‘unidimensional’ random effects (like <span class="math inline">\(\alpha_{[speaker]}\)</span>).</p>
<p>The correlation matrix <span class="math inline">\(R\)</span> will look something like below (for two dimensions). It will contain only values of 1 on the main diagonal and have mirrored values between -1 and 1 off of the diagonal (since the correlation of a and b equals the correlation of b and a).</p>
<p><span class="math display" id="eq:67">\[\begin{equation}
\begin{split}
R = \begin{bmatrix} x &amp; y \\ y &amp; z \\ \end{bmatrix} \\ \\
\end{split}
\tag{6.7}
\end{equation}\]</span></p>
<p>We specify priors for variables of this type using the <span class="math inline">\(LKJCorr\)</span> distribution in <code>brms</code>. This distribution has a single parameter that determines how peaked the distribution is around 0. Basically, higher numbers make it harder to find larger correlations (and therefore yield more conservative estimates). <a href="https://eager-roentgen-523c83.netlify.app/2014/12/27/d-lkj-priors/">See here for an example</a>.</p>
<p><span class="math display" id="eq:672">\[\begin{equation}
\begin{split}
R \sim \mathrm{LKJCorr} (2)
\end{split}
\tag{6.8}
\end{equation}\]</span></p>
<p>The above was a full explanation of what information the model needs and why it needs it. You don’t need to <em>understand</em> any of the above to use random effects correctly. The important take away is that whenever you are estimating any random effects above and beyond a random intercept, you need to:</p>
<ol style="list-style-type: decimal">
<li><p>Specify priors for the standard deviation of each dimension.</p></li>
<li><p>Specify a prior for the correlation matrix for the multivariate normal used for the random parameters.</p></li>
</ol>
<p>and <code>brm</code> (and STAN) will do the rest.</p>
</div>
<div id="random-slopes" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Random slopes</h2>
<p>The initial model we considered was a demonstration that served primarily as a comparison for the model we are going to fit now. No one would actually include subjects as a ‘fixed’ effect, nor would they include the <span class="math inline">\(g0_c\)</span> by <span class="math inline">\(subject\)</span> interaction as a fixed effect. In both cases, researchers would tend to include these predictors as ‘random effects’. Here, we’re going to refit the model as a ‘random slopes’ model, and talk about how this is similar/different to our previous approach of treating subjects as fixed effects.</p>
<div id="description-of-the-model-8" class="section level3" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Description of the model</h3>
<p>Our previous model formula was:</p>
<p><code>pheight ~ g0_c * subj +  (1|speaker)</code></p>
<p>Our new model formula moves <code>g0_c</code> into the parenthesis with subject like this:</p>
<p><code>pheight ~ g0_c + ( g0_c |subj) + (1|speaker)</code></p>
<p>As noted above, this means our model has subject-specific slopes and intercepts now. You may be thinking “subject specific intercepts and slopes, isn’t that what we did in our last model?”. The answer is yes, it is what we did in our last model! As we’ll see below, our ‘random’ and ‘fixed’ effects models are largely the same thing, and provide very similar information. However, there are a few very (very) important differences.</p>
<p>The model description for our random slopes model is given below. The differences relative to our previous model lie in the replacement of our <span class="math inline">\(subj\)</span> predictor with an <span class="math inline">\(\alpha_{[\mathrm{subj}]}\)</span> random effect, and the <span class="math inline">\(g0 \_ c \colon subj\)</span> predictor with a <span class="math inline">\(\beta_{[\mathrm{subj}]}\)</span> random effect. In addition, the inclusion of these random effects requires that we provide a prior for our correlation term (i.e. <span class="math inline">\(\mathrm{LKJCorr} (2)\)</span>). However, note that the priors for the standard deviations of the random effects are still being specified in the same way.</p>
<p><span class="math display" id="eq:68">\[\begin{equation}
\begin{split}
\textrm{Likelihood:} \\
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = a_{[i]} + b_{[i]} * \mathrm{x}_{[i]}  \\ 
a_{[i]} = Intercept + \alpha_{[\mathrm{subj}_{[i]}]} + \alpha_{[\mathrm{speaker}_{[i]}]}  \\
b_{[i]} =  g0\_c + \beta_{[\mathrm{subj}_{[i]}]} \\ \\
\textrm{Priors:} \\
\alpha_{speaker} \sim \mathrm{Normal}(0,\sigma_{speaker}) \\ \\  
\begin{bmatrix} \alpha_{subj} \\ \beta_{subj} \end{bmatrix} \sim \mathrm{MVNormal} ( \begin{bmatrix} 0 \\ 0 \\ \end{bmatrix}, \Sigma) \\ \\
Intercept \sim t(3, 60, 12) \\
g0\_c \sim t(3, 0, 50) \\ \\
\sigma_{error} \sim t(3, 0, 100) \\
\sigma_{\alpha_{speaker}} \sim t(3, 0, 100) \\ 
\sigma_{\alpha_{subj}} \sim t(3, 0, 12) \\ 
\sigma_{\beta_{subj}} \sim t(3, 0, 12) \\ 
R \sim \mathrm{LKJCorr} (2)
\end{split}
\tag{6.9}
\end{equation}\]</span></p>
<p>Here’s a description of the model in plain English:</p>
<blockquote>
<p>Perceived height is normally distributed with a mean that varies trial to trial but a fixed standard deviation. The mean (expected value) varies along lines. The lines are specified by intercepts and slopes that vary from trial to trial, and there is a single continuous predictor (g0_c). The intercept of these lines vary based on an overall intercept (the main effect), subject-specific deviations from the mean, and speaker-specific deviations from the mean. The slope of these lines vary based on an overall slope (the main effect) and subject-specific deviations from the average slope.</p>
</blockquote>
<blockquote>
<p>The speaker intercepts were drawn from a normal distribution with a mean of zero and a standard deviation estimated from the data. The subject intercepts and slopes were drawn from a bivariate normal distribution with means of 0 of zero and a covariance matrix estimated from the data. All other effects (e.g., the Intercept, g0_c, etc.) were treated as ‘fixed’ and drawn from prior distributions appropriate for their expected range of values (e.g., subj ~ t(3,0,12)).</p>
</blockquote>
<p>Note that the prediction equation in our last model:</p>
<p><span class="math display" id="eq:69">\[\begin{equation}
\begin{split}
\mu_{[i]} = a_{[i]} + b_{[i]} * \mathrm{x}_{[i]}  \\ 
a_{[i]} = Intercept + subj_{[\mathrm{subj}_{[i]}]} + \alpha_{[\mathrm{speaker}_{[i]}]}  \\
b_{[i]} =  g0\_c + g0\_c \colon subj_{[\mathrm{subj}_{[i]}]} \\ \\
\end{split}
\tag{6.10}
\end{equation}\]</span></p>
<p>Is just like the one for this model, save for a one-to-one replacement of the terms <span class="math inline">\(\alpha_{[\mathrm{subj}]}\)</span> and <span class="math inline">\(\beta_{[\mathrm{subj}]}\)</span> for <span class="math inline">\(subj_{[\mathrm{subj}]}\)</span> and <span class="math inline">\(g0\_c \colon subj_{[\mathrm{subj}]}\)</span>:</p>
<p><span class="math display" id="eq:610">\[\begin{equation}
\begin{split}
\mu_{[i]} = a_{[i]} + b_{[i]} * \mathrm{x}_{[i]}  \\ 
a_{[i]} = Intercept + \alpha_{[\mathrm{subj}_{[i]}]} + \alpha_{[\mathrm{speaker}_{[i]}]}  \\
b_{[i]} =  g0\_c + \beta_{[\mathrm{subj}_{[i]}]} \\ \\
\end{split}
\tag{6.11}
\end{equation}\]</span></p>
<p>Although the prediction equations are largely the same, in the previous model we treated subject as a ‘fixed’ effect. Remember that in our multilevel Bayesian models, this means that the prior distribution for these was determined entirely a priori and was not estimated from the data. For example our subject effects were drawn from a population of <span class="math inline">\(subj \sim t(3, 0, 12)\)</span> and the subject by g0_c interaction was drawn from a population of <span class="math inline">\(g0\_c \colon subj \sim t(3, 0, 50)\)</span>.</p>
<p>In contrast, random effects are drawn from populations whose standard deviation is estimated from the data. This is the way our current (and previous) models treat the speaker effects. Notice that we estimate, rather than stipulate, the standard deviation for the population of speaker effects (<span class="math inline">\(\sigma_{speaker}\)</span>):</p>
<p><span class="math display" id="eq:611">\[\begin{equation}
\begin{split}
\alpha_{speaker} \sim \mathrm{Normal}(0,\sigma_{speaker}) \\ \\  
\sigma_{speaker} \sim t(3, 0, 100) \\ 
\end{split}
\tag{6.12}
\end{equation}\]</span></p>
<p>We might have treated our subject intercepts in the same way, except for the fact that we are also estimating random slopes for subjects. Since we are drawing two random variables for each person, we need to also model the correlation between the variables.</p>
<p>So, when we have multiple random effects (e.g., intercepts and/or slopes) for a predictor, we draw this from a multivariate normal distribution where each predictor is a different ‘dimension’ of the variable. This requires that we estimate a standard deviation for each predictor, and a correlation between each pair of predictors.</p>
<p>As seen below, we draw our predictors from a two-dimensional normal distribution. This distribution has a mean of zero for each dimension, and a covariance matrix equal to <span class="math inline">\(\Sigma\)</span>.</p>
<p><span class="math display" id="eq:612">\[
\begin{bmatrix} \alpha_{subj} \\ \beta_{subj} \\ \end{bmatrix}  
\sim \mathrm{MVNormal} ( \begin{bmatrix} 0 \\ 0 \\ \end{bmatrix}, \Sigma) \\ \\
\tag{6.13}
\]</span></p>
</div>
<div id="fitting-the-model-7" class="section level3" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Fitting the model</h3>
<p>We now fit the model that includes random intercepts and by-subject slopes for f0. Notice that my <code>set_prior</code> section now includes a new category of parameter <code>cor</code> for which I provide a prior using the <code>lkj_corr_cholesky</code> distribution.</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="random-slopes-and-multiple-random-effects.html#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself, or</span></span>
<span id="cb139-2"><a href="random-slopes-and-multiple-random-effects.html#cb139-2" aria-hidden="true" tabindex="-1"></a><span class="co"># download pre-fit model from: </span></span>
<span id="cb139-3"><a href="random-slopes-and-multiple-random-effects.html#cb139-3" aria-hidden="true" tabindex="-1"></a><span class="co"># github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb139-4"><a href="random-slopes-and-multiple-random-effects.html#cb139-4" aria-hidden="true" tabindex="-1"></a><span class="co"># and load after placing in working directory</span></span>
<span id="cb139-5"><a href="random-slopes-and-multiple-random-effects.html#cb139-5" aria-hidden="true" tabindex="-1"></a><span class="co"># random_slopes_model = readRDS (&#39;6_random_slopes_model.RDS&#39;)</span></span>
<span id="cb139-6"><a href="random-slopes-and-multiple-random-effects.html#cb139-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-7"><a href="random-slopes-and-multiple-random-effects.html#cb139-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb139-8"><a href="random-slopes-and-multiple-random-effects.html#cb139-8" aria-hidden="true" tabindex="-1"></a>random_slopes_model <span class="ot">=</span></span>
<span id="cb139-9"><a href="random-slopes-and-multiple-random-effects.html#cb139-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (pheight <span class="sc">~</span> g0_c <span class="sc">+</span> (g0_c<span class="sc">|</span>subj) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>speaker), <span class="at">data=</span>h95, <span class="at">chains=</span><span class="dv">4</span>, <span class="at">cores=</span><span class="dv">4</span>,  </span>
<span id="cb139-10"><a href="random-slopes-and-multiple-random-effects.html#cb139-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">warmup=</span><span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">7500</span>, <span class="at">thin =</span> <span class="dv">4</span>, <span class="at">control =</span> <span class="fu">list</span>(<span class="at">adapt_delta =</span> <span class="fl">0.95</span>), </span>
<span id="cb139-11"><a href="random-slopes-and-multiple-random-effects.html#cb139-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 60, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb139-12"><a href="random-slopes-and-multiple-random-effects.html#cb139-12" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 50)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb139-13"><a href="random-slopes-and-multiple-random-effects.html#cb139-13" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sd&quot;</span>),</span>
<span id="cb139-14"><a href="random-slopes-and-multiple-random-effects.html#cb139-14" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;lkj_corr_cholesky (2)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;cor&quot;</span>)))</span>
<span id="cb139-15"><a href="random-slopes-and-multiple-random-effects.html#cb139-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-16"><a href="random-slopes-and-multiple-random-effects.html#cb139-16" aria-hidden="true" tabindex="-1"></a><span class="co"># save model</span></span>
<span id="cb139-17"><a href="random-slopes-and-multiple-random-effects.html#cb139-17" aria-hidden="true" tabindex="-1"></a><span class="co"># saveRDS (random_slopes_model, &#39;6_random_slopes_model.RDS&#39;)</span></span></code></pre></div>
</div>
<div id="interpreting-the-model-5" class="section level3" number="6.4.3">
<h3><span class="header-section-number">6.4.3</span> Interpreting the model</h3>
<p>When we look at the print statement for our model, we now see multiple entries in the <code>Group-Level Effects</code> section. Under <code>~speaker</code> we see <code>sd(Intercept)</code> representing the standard deviation of the talker intercepts. This tells us that we are only estimating random intercepts for our 139 speakers. These intercepts represent systematic variability in perceived height that is independent of the linear effect for f0.</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="random-slopes-and-multiple-random-effects.html#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Group-Level Effects: </span></span>
<span id="cb140-2"><a href="random-slopes-and-multiple-random-effects.html#cb140-2" aria-hidden="true" tabindex="-1"></a><span class="do">## ~speaker (Number of levels: 139) </span></span>
<span id="cb140-3"><a href="random-slopes-and-multiple-random-effects.html#cb140-3" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb140-4"><a href="random-slopes-and-multiple-random-effects.html#cb140-4" aria-hidden="true" tabindex="-1"></a><span class="do">## sd(Intercept)     5.52      0.47     4.65     6.51 1.00     1643     2982</span></span>
<span id="cb140-5"><a href="random-slopes-and-multiple-random-effects.html#cb140-5" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb140-6"><a href="random-slopes-and-multiple-random-effects.html#cb140-6" aria-hidden="true" tabindex="-1"></a><span class="do">## ~subj (Number of levels: 10) </span></span>
<span id="cb140-7"><a href="random-slopes-and-multiple-random-effects.html#cb140-7" aria-hidden="true" tabindex="-1"></a><span class="do">##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb140-8"><a href="random-slopes-and-multiple-random-effects.html#cb140-8" aria-hidden="true" tabindex="-1"></a><span class="do">## sd(Intercept)           1.81      0.54     1.09     3.18 1.00     4776     5714</span></span>
<span id="cb140-9"><a href="random-slopes-and-multiple-random-effects.html#cb140-9" aria-hidden="true" tabindex="-1"></a><span class="do">## sd(g0_c)                4.21      1.22     2.54     7.25 1.00     5435     5917</span></span>
<span id="cb140-10"><a href="random-slopes-and-multiple-random-effects.html#cb140-10" aria-hidden="true" tabindex="-1"></a><span class="do">## cor(Intercept,g0_c)     0.34      0.27    -0.27     0.77 1.00     5602     5807</span></span></code></pre></div>
<p>We see that there is also a section for <code>~subj</code>, containing our by-subject random effects. This section has three elements. the first is <code>sd(Intercept)</code>, representing the standard deviation of our subject intercepts. These intercepts represent differences in the average height responses of different subjects that are independent of f0. The second is <code>sd(g0_c)</code> representing the standard deviation of subject-dependent <em>slopes</em>. This represents variation in by-subject slopes, analogous to the <span class="math inline">\(g0_c \colon subj\)</span> interaction in our fixed effects model. The third item is<code>cor(Intercept,g0_c)</code>, representing the correlation of subject intercepts and subject slopes. Notice that we get means but also credible intervals areound all these parameters.</p>
<p>Below, we can compare the fixed effect estimates of our random slopes model:</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="random-slopes-and-multiple-random-effects.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Population-Level Effects: </span></span>
<span id="cb141-2"><a href="random-slopes-and-multiple-random-effects.html#cb141-2" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb141-3"><a href="random-slopes-and-multiple-random-effects.html#cb141-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept    60.93      0.76    59.44    62.43 1.00     1539     3029</span></span>
<span id="cb141-4"><a href="random-slopes-and-multiple-random-effects.html#cb141-4" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c         -6.34      1.94   -10.17    -2.63 1.00     2883     4064</span></span></code></pre></div>
<p>To those of the fixed slopes model.</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="random-slopes-and-multiple-random-effects.html#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Population-Level Effects: </span></span>
<span id="cb142-2"><a href="random-slopes-and-multiple-random-effects.html#cb142-2" aria-hidden="true" tabindex="-1"></a><span class="do">##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb142-3"><a href="random-slopes-and-multiple-random-effects.html#cb142-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept     60.99      0.48    60.05    61.91 1.00      713     1735</span></span>
<span id="cb142-4"><a href="random-slopes-and-multiple-random-effects.html#cb142-4" aria-hidden="true" tabindex="-1"></a><span class="do">## g0_c          -6.29      1.40    -8.97    -3.52 1.00     1963     3303</span></span></code></pre></div>
<p>The estimates are quite close in value, though their credible intervals vary. The difference in the credible intervals comes across more clearly when we plot them to compare:</p>
<div class="figure"><span id="fig:F6-8"></span>
<img src="06_files/figure-html/F6-8-1.png" alt="(left) Comparison of random effect (RE) and fixed effect (FE) estimates of the intercept main effect. (right) Comparison of random effect (RE) and fixed effect (FE) estimates of the slope main effect." width="768" />
<p class="caption">
Figure 6.9: (left) Comparison of random effect (RE) and fixed effect (FE) estimates of the intercept main effect. (right) Comparison of random effect (RE) and fixed effect (FE) estimates of the slope main effect.
</p>
</div>
<p>We can get the random effects (slopes and intercepts) from our model using the <code>ranef</code> function, and asking for the <code>subj</code> random effects.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="random-slopes-and-multiple-random-effects.html#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get random effects</span></span>
<span id="cb143-2"><a href="random-slopes-and-multiple-random-effects.html#cb143-2" aria-hidden="true" tabindex="-1"></a>random_effects <span class="ot">=</span> <span class="fu">ranef</span> (random_slopes_model)<span class="sc">$</span>subj</span>
<span id="cb143-3"><a href="random-slopes-and-multiple-random-effects.html#cb143-3" aria-hidden="true" tabindex="-1"></a><span class="co"># inspect their structure</span></span>
<span id="cb143-4"><a href="random-slopes-and-multiple-random-effects.html#cb143-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span> (random_effects)</span>
<span id="cb143-5"><a href="random-slopes-and-multiple-random-effects.html#cb143-5" aria-hidden="true" tabindex="-1"></a><span class="do">##  num [1:10, 1:4, 1:2] 1.164 1.155 0.116 3.174 -1.914 ...</span></span>
<span id="cb143-6"><a href="random-slopes-and-multiple-random-effects.html#cb143-6" aria-hidden="true" tabindex="-1"></a><span class="do">##  - attr(*, &quot;dimnames&quot;)=List of 3</span></span>
<span id="cb143-7"><a href="random-slopes-and-multiple-random-effects.html#cb143-7" aria-hidden="true" tabindex="-1"></a><span class="do">##   ..$ : chr [1:10] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...</span></span>
<span id="cb143-8"><a href="random-slopes-and-multiple-random-effects.html#cb143-8" aria-hidden="true" tabindex="-1"></a><span class="do">##   ..$ : chr [1:4] &quot;Estimate&quot; &quot;Est.Error&quot; &quot;Q2.5&quot; &quot;Q97.5&quot;</span></span>
<span id="cb143-9"><a href="random-slopes-and-multiple-random-effects.html#cb143-9" aria-hidden="true" tabindex="-1"></a><span class="do">##   ..$ : chr [1:2] &quot;Intercept&quot; &quot;g0_c&quot;</span></span></code></pre></div>
<p>When we have a look at the output of the <code>str</code> function, we can see that this is a 3-dimensional matrix. When we look at this matrix along the third dimension (e.g., <code>random_effects[,,in here]</code>), we get a series of 2-d matrices that are a summary of a single random effect. Below we see that the first matrix (<code>random_effects[,,1]</code>) corresponds to the random intercepts, and the second matrix (<code>random_effects[,,2]</code>) corresponding to the random slopes.</p>
<p>You’ll note that we actually get all ten subject effects and there is no omitted value. This is because when you use partial pooling to estimate parameters, you actually <em>can</em> estimate all levels of a factor (for technical reasons related to shrinkage).</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="random-slopes-and-multiple-random-effects.html#cb144-1" aria-hidden="true" tabindex="-1"></a>random_effects</span>
<span id="cb144-2"><a href="random-slopes-and-multiple-random-effects.html#cb144-2" aria-hidden="true" tabindex="-1"></a><span class="do">## , , Intercept</span></span>
<span id="cb144-3"><a href="random-slopes-and-multiple-random-effects.html#cb144-3" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb144-4"><a href="random-slopes-and-multiple-random-effects.html#cb144-4" aria-hidden="true" tabindex="-1"></a><span class="do">##       Estimate Est.Error        Q2.5       Q97.5</span></span>
<span id="cb144-5"><a href="random-slopes-and-multiple-random-effects.html#cb144-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 1   1.16377527 0.6268821 -0.04942324  2.46153571</span></span>
<span id="cb144-6"><a href="random-slopes-and-multiple-random-effects.html#cb144-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 2   1.15505273 0.6275566 -0.03510937  2.42001233</span></span>
<span id="cb144-7"><a href="random-slopes-and-multiple-random-effects.html#cb144-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 3   0.11623493 0.6231278 -1.10121480  1.38309357</span></span>
<span id="cb144-8"><a href="random-slopes-and-multiple-random-effects.html#cb144-8" aria-hidden="true" tabindex="-1"></a><span class="do">## 4   3.17445575 0.6258360  1.99622247  4.49472090</span></span>
<span id="cb144-9"><a href="random-slopes-and-multiple-random-effects.html#cb144-9" aria-hidden="true" tabindex="-1"></a><span class="do">## 5  -1.91413822 0.6259466 -3.12790488 -0.63922912</span></span>
<span id="cb144-10"><a href="random-slopes-and-multiple-random-effects.html#cb144-10" aria-hidden="true" tabindex="-1"></a><span class="do">## 6   0.04515396 0.6257749 -1.18640204  1.32431108</span></span>
<span id="cb144-11"><a href="random-slopes-and-multiple-random-effects.html#cb144-11" aria-hidden="true" tabindex="-1"></a><span class="do">## 7  -1.28080815 0.6267446 -2.50106938 -0.03644058</span></span>
<span id="cb144-12"><a href="random-slopes-and-multiple-random-effects.html#cb144-12" aria-hidden="true" tabindex="-1"></a><span class="do">## 8  -0.16633822 0.6317497 -1.39801195  1.11656287</span></span>
<span id="cb144-13"><a href="random-slopes-and-multiple-random-effects.html#cb144-13" aria-hidden="true" tabindex="-1"></a><span class="do">## 9  -1.47968132 0.6320220 -2.71728703 -0.21591965</span></span>
<span id="cb144-14"><a href="random-slopes-and-multiple-random-effects.html#cb144-14" aria-hidden="true" tabindex="-1"></a><span class="do">## 10 -0.53282781 0.6300846 -1.74720063  0.75334092</span></span>
<span id="cb144-15"><a href="random-slopes-and-multiple-random-effects.html#cb144-15" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb144-16"><a href="random-slopes-and-multiple-random-effects.html#cb144-16" aria-hidden="true" tabindex="-1"></a><span class="do">## , , g0_c</span></span>
<span id="cb144-17"><a href="random-slopes-and-multiple-random-effects.html#cb144-17" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb144-18"><a href="random-slopes-and-multiple-random-effects.html#cb144-18" aria-hidden="true" tabindex="-1"></a><span class="do">##      Estimate Est.Error      Q2.5     Q97.5</span></span>
<span id="cb144-19"><a href="random-slopes-and-multiple-random-effects.html#cb144-19" aria-hidden="true" tabindex="-1"></a><span class="do">## 1   1.0157799  1.577586 -2.117585  4.117939</span></span>
<span id="cb144-20"><a href="random-slopes-and-multiple-random-effects.html#cb144-20" aria-hidden="true" tabindex="-1"></a><span class="do">## 2  -0.9027227  1.566411 -4.070686  2.179692</span></span>
<span id="cb144-21"><a href="random-slopes-and-multiple-random-effects.html#cb144-21" aria-hidden="true" tabindex="-1"></a><span class="do">## 3   1.3279988  1.577451 -1.798952  4.516177</span></span>
<span id="cb144-22"><a href="random-slopes-and-multiple-random-effects.html#cb144-22" aria-hidden="true" tabindex="-1"></a><span class="do">## 4   7.4737121  1.591885  4.444100 10.670002</span></span>
<span id="cb144-23"><a href="random-slopes-and-multiple-random-effects.html#cb144-23" aria-hidden="true" tabindex="-1"></a><span class="do">## 5   1.8695128  1.569712 -1.300681  5.008267</span></span>
<span id="cb144-24"><a href="random-slopes-and-multiple-random-effects.html#cb144-24" aria-hidden="true" tabindex="-1"></a><span class="do">## 6  -4.4944108  1.569323 -7.674207 -1.418619</span></span>
<span id="cb144-25"><a href="random-slopes-and-multiple-random-effects.html#cb144-25" aria-hidden="true" tabindex="-1"></a><span class="do">## 7   2.0829323  1.582772 -1.030887  5.365565</span></span>
<span id="cb144-26"><a href="random-slopes-and-multiple-random-effects.html#cb144-26" aria-hidden="true" tabindex="-1"></a><span class="do">## 8  -1.9113901  1.578336 -5.155632  1.199296</span></span>
<span id="cb144-27"><a href="random-slopes-and-multiple-random-effects.html#cb144-27" aria-hidden="true" tabindex="-1"></a><span class="do">## 9  -4.1408383  1.578127 -7.315184 -1.035547</span></span>
<span id="cb144-28"><a href="random-slopes-and-multiple-random-effects.html#cb144-28" aria-hidden="true" tabindex="-1"></a><span class="do">## 10 -1.8307910  1.561144 -4.991040  1.268622</span></span></code></pre></div>
<p>In Figure <a href="random-slopes-and-multiple-random-effects.html#fig:p6-10">6.10</a>, we see a comparison of the subject intercept and slope terms provided by the random and fixed slopes models. We can see that the effects are extremely similar, however, again the credible intervals are substantially wider for the estimates provided by the random effects model.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="random-slopes-and-multiple-random-effects.html#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb145-2"><a href="random-slopes-and-multiple-random-effects.html#cb145-2" aria-hidden="true" tabindex="-1"></a><span class="co"># plot random intercepts</span></span>
<span id="cb145-3"><a href="random-slopes-and-multiple-random-effects.html#cb145-3" aria-hidden="true" tabindex="-1"></a><span class="fu">brmplot</span> (<span class="at">xs =</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)<span class="sc">-</span>.<span class="dv">2</span>,  random_effects[,,<span class="dv">1</span>], <span class="at">col=</span>cols, <span class="at">labels =</span> <span class="st">&quot;&quot;</span>, <span class="at">pch=</span><span class="dv">15</span>)</span>
<span id="cb145-4"><a href="random-slopes-and-multiple-random-effects.html#cb145-4" aria-hidden="true" tabindex="-1"></a><span class="co"># plot fixed intercepts</span></span>
<span id="cb145-5"><a href="random-slopes-and-multiple-random-effects.html#cb145-5" aria-hidden="true" tabindex="-1"></a><span class="fu">brmplot</span> (<span class="at">xs =</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)<span class="sc">+</span>.<span class="dv">2</span>, factors[[<span class="st">&quot;subj&quot;</span>]], <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">col=</span>cols)</span>
<span id="cb145-6"><a href="random-slopes-and-multiple-random-effects.html#cb145-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h=</span><span class="dv">0</span>, <span class="at">lty=</span><span class="dv">3</span>)</span>
<span id="cb145-7"><a href="random-slopes-and-multiple-random-effects.html#cb145-7" aria-hidden="true" tabindex="-1"></a><span class="co"># plot random slopes</span></span>
<span id="cb145-8"><a href="random-slopes-and-multiple-random-effects.html#cb145-8" aria-hidden="true" tabindex="-1"></a><span class="fu">brmplot</span> (<span class="at">xs =</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)<span class="sc">-</span>.<span class="dv">2</span>, random_effects[,,<span class="dv">2</span>], <span class="at">col =</span> cols, <span class="at">labels =</span> <span class="st">&quot;&quot;</span>, <span class="at">pch=</span><span class="dv">15</span>)</span>
<span id="cb145-9"><a href="random-slopes-and-multiple-random-effects.html#cb145-9" aria-hidden="true" tabindex="-1"></a><span class="co"># plot fixed slopes</span></span>
<span id="cb145-10"><a href="random-slopes-and-multiple-random-effects.html#cb145-10" aria-hidden="true" tabindex="-1"></a><span class="fu">brmplot</span> (<span class="at">xs =</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)<span class="sc">+</span>.<span class="dv">2</span>, factors[[<span class="st">&quot;g0_c:subj&quot;</span>]], <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">col=</span>cols)</span>
<span id="cb145-11"><a href="random-slopes-and-multiple-random-effects.html#cb145-11" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h=</span><span class="dv">0</span>, <span class="at">lty=</span><span class="dv">3</span>)</span></code></pre></div>
<div class="figure"><span id="fig:p6-10"></span>
<img src="06_files/figure-html/p6-10-1.png" alt="(top) Comparison of random effects (squares) and fixed effect (circles) estimates for speaker intercept effects. (bottom) Same as above but for the slope terms." width="768" />
<p class="caption">
Figure 6.10: (top) Comparison of random effects (squares) and fixed effect (circles) estimates for speaker intercept effects. (bottom) Same as above but for the slope terms.
</p>
</div>
<p>In Figure <a href="random-slopes-and-multiple-random-effects.html#fig:F6-10">6.11</a>, we compare the random and fixed effects estimates for the subject intercepts. Note that the difference between the random and fixed effect estimates is largest for the effects with the largest magnitude. For example, on the left edge of the right figure below we see that the green effect with a fixed effect estimates near -2 has a random effect that is nearly 0.1 larger than that (near to -1.9).</p>
<div class="figure"><span id="fig:F6-10"></span>
<img src="06_files/figure-html/F6-10-1.png" alt="(left) Comparison of fixed and random estimates for subject effects (intercept terms). (right) Plot of the difference between the estimates for each parameter, plotted against the value of the fixed-effect estimate of the same parameter." width="768" />
<p class="caption">
Figure 6.11: (left) Comparison of fixed and random estimates for subject effects (intercept terms). (right) Plot of the difference between the estimates for each parameter, plotted against the value of the fixed-effect estimate of the same parameter.
</p>
</div>
<p>The same pattern is evident in Figure <a href="random-slopes-and-multiple-random-effects.html#fig:F6-11">6.12</a>, : more extreme values are ‘shrunk’ towards the mean. This is partial-pooling and shrinkage in action! Because parameters in a ‘random effect’ are jointly estimated (to some extent), extreme values can be pulled towards the mean when they are weakly supported. Here we see a tiny bit of shrinkage indicating that: 1) the values were not so extreme, and 2) the ‘extreme’ values had a reasonable amount of support.</p>
<div class="figure"><span id="fig:F6-11"></span>
<img src="06_files/figure-html/F6-11-1.png" alt="(left) Comparison of fixed and random estimates for g0_c:subject effects (slope terms). (right) Plot of the difference between the estimates for each parameter, plotted against the value of the fixed-effect estimate of the same parameter." width="768" />
<p class="caption">
Figure 6.12: (left) Comparison of fixed and random estimates for g0_c:subject effects (slope terms). (right) Plot of the difference between the estimates for each parameter, plotted against the value of the fixed-effect estimate of the same parameter.
</p>
</div>
</div>
</div>
<div id="more-predictors-and-more-random-slopes" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> More predictors and more random slopes</h2>
<div id="adding-another-random-slope" class="section level3" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> Adding another random slope</h3>
<p>Imagine we were to add another continuous predictor to our model. We can use the centered logarithm of F1 (<code>g1_c</code>) as an example. Inclusion of random slopes for this predictor would mean our equation now looks like:</p>
<p><code>pheight ~ g0_c + g1_c (g0_c + g1_c|subj) + (1|speaker)</code></p>
<p>In turn, this means that the likelihood section of our model now looks like below. Basically, we have just added a new continuous predictor (<span class="math inline">\(\mathrm{x}_{2[i]}\)</span>) and slope term (<span class="math inline">\(b_{2}\)</span>), with its own corresponding decomposition into a main effect and a random subject effect.</p>
<p><span class="math display" id="eq:613a">\[\begin{equation}
\begin{split}
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = a_{[i]} + b_{1[i]} * \mathrm{x}_{1[i]} + b_{2[i]} * \mathrm{x}_{2[i]}  \\ 
a_{[i]} = Intercept + \alpha_{[\mathrm{subj}_{[i]}]} + \alpha_{[\mathrm{speaker}_{[i]}]}  \\
b_{1[i]} =  g0\_c + \beta_{1{[\mathrm{subj}_{[i]}]}} \\ 
b_{2[i]} =  g1\_c + \beta_{2{[\mathrm{subj}_{[i]}]}} \\ 
\end{split}
\tag{6.14}
\end{equation}\]</span></p>
<p>The two random slopes (<span class="math inline">\(\beta_{1{[\mathrm{subj}]}},\beta_{2{[\mathrm{subj}]}}\)</span>) and the random intercept (<span class="math inline">\(\alpha_{[\mathrm{subj}]}\)</span>) are all drawn from a multivariate normal distribution:</p>
<p><span class="math display" id="eq:613b">\[\begin{equation}
\begin{split}
\begin{bmatrix} \alpha_{[subj]} \\ \beta_{1[subj]} \\ \beta_{2[subj]} \\ \end{bmatrix}  
\sim \mathrm{MVNormal} ( \begin{bmatrix} 0 \\ 0 \\ 0 \\ \end{bmatrix}, \Sigma) \\ 
\end{split}
\tag{6.15}
\end{equation}\]</span></p>
<p>Just as for our first random slopes model, we just need to worry about specifying the priors for the effects standard deviations (<span class="math inline">\(\sigma_{\alpha_{[\mathrm{speaker}]}}, \sigma_{\beta_{[\mathrm{speaker}]}}\)</span>) and the correlation matrix (<span class="math inline">\(R\)</span>) (like below) and <code>brm</code> does the rest of the work for us.</p>
<p><span class="math display" id="eq:614">\[\begin{equation}
\begin{split}
\sigma_{\alpha_{[speaker]}} \sim t(3, 0, 100) \\ 
\sigma_{\beta_{1[subj]}} \sim t(3, 0, 100) \\ 
\sigma_{\beta_{2[subj]}} \sim t(3, 0, 100) \\ 
R \sim \mathrm{LKJCorr} (2)
\end{split}
\tag{6.16}
\end{equation}\]</span></p>
</div>
<div id="adding-random-factors" class="section level3" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> Adding random factors</h3>
<p>We can also add random effects for factors. For example, we could include <code>adult</code> inside our <code>subj</code> parentheses in the model formula. This would tell our model to calculate a subject-specific effect for <code>adult</code>:</p>
<p><code>pheight ~ g0_c + g1_c + adult (g0_c + g1_c + adult |subj) + (1|speaker)</code></p>
<p>We discussed before that the random effect of <code>adult</code> cannot be estimated for speaker. However, since subjects were tested for both adult and child voices, we <em>can</em> estimate the random effect for adultness according to subject.</p>
<p>The likelihood section of our model will now look like below. Note that the random effect associated with adultness is added to the intercept equation. This is because this effect does not interact with our continuous predictors. Since there are no interactions between our continuous predictors and the adult effect, the slopes cannot vary based on adultness. As a result, the adultness parameter can only affect the intercepts of the shapes being drawn and not their slopes.</p>
<p><span class="math display" id="eq:614b">\[\begin{equation}
\begin{split}
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = a_{[i]} + b_{1[i]} * \mathrm{x}_{1[i]} + b_{2[i]} * \mathrm{x}_{2[i]}  \\ 
a_{[i]} = Intercept + \alpha_{[\mathrm{subj}_{[i]}]} + \alpha_{adult[\mathrm{subj}_{[i]}]} + \alpha_{[\mathrm{speaker}_{[i]}]}  \\
b_{1[i]} =  g0\_c + \beta_{1{[\mathrm{subj}_{[i]}]}} \\ 
b_{2[i]} =  g1\_c + \beta_{2{[\mathrm{subj}_{[i]}]}} \\ \\
\end{split}
\tag{6.17}
\end{equation}\]</span></p>
<p>Since we now have 4 random effects for subject, we draw our subject random effects from a four-dimensional normal distribution like this:</p>
<p><span class="math display" id="eq:615">\[\begin{equation}
\begin{split}
\begin{bmatrix} \alpha_{[subj]} \\ \alpha_{adult[subj]} \\ \beta_{1[subj]} \\ \beta_{2[subj]} \\ \end{bmatrix}  
\sim \mathrm{MVNormal} ( \begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \\ \end{bmatrix}, \Sigma) \\ \\
\end{split}
\tag{6.18}
\end{equation}\]</span></p>
</div>
<div id="the-independence-of-continuous-predictors" class="section level3" number="6.5.3">
<h3><span class="header-section-number">6.5.3</span> The independence of continuous predictors</h3>
<p>It’s important to note that each continuous predictor is treated independently in our model. We could, for example, include an interaction between adultness and F1 in our model. This would make the formula look like this:</p>
<p><code>pheight ~ g0_c + g1_c + adult + g1_c:adult + (g0_c + g1_c + adult + g1_c:adult|subj) + (1|speaker)</code></p>
<p>This model says “model variation as a function of f0, F1, adultness, and the interaction of F1 and adultness”. Note that this only causes a change for one of our slopes (<span class="math inline">\(b_2\)</span>). It causes no change at all for our intercept or the other slope:</p>
<p><span class="math display" id="eq:616">\[\begin{equation}
\begin{split}
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = a_{[i]} + b_{1[i]} * \mathrm{x}_{1[i]} + b_{2[i]} * \mathrm{x}_{2[i]}  \\ 
a_{[i]} = Intercept + \alpha_{[\mathrm{subj}_{[i]}]} + \alpha_{adult[\mathrm{subj}_{[i]}]} + \alpha_{[\mathrm{speaker}_{[i]}]}  \\
b_{1[i]} =  g0\_c + \beta_{1{[\mathrm{subj}_{[i]}]}} \\ 
b_{2[i]} =  g1\_c + \beta_{2{[\mathrm{subj}_{[i]}]}} + \beta_{2,adult[\mathrm{subj}_{[i]}]} \\ 
\end{split}
\tag{6.19}
\end{equation}\]</span></p>
<p>Since we now have five random effects, we now draw our subject random effects from a five-dimensional normal distribution like:</p>
<p><span class="math display" id="eq:616b">\[\begin{equation}
\begin{split}
\begin{bmatrix} \alpha_{[subj]} \\ \alpha_{adult[subj]} \\ \beta_{1[subj]} \\ \beta_{2[subj]} \\ \beta_{2,adult[\mathrm{subj}_{[i]}]} \\ \end{bmatrix}  
\sim \mathrm{MVNormal} ( \begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ \end{bmatrix}, \Sigma) \\ \\
\end{split}
\tag{6.20}
\end{equation}\]</span></p>
<p>Keep in mind that the correlation matrix for this distribution is a 5x5 matrix with 25 elements, meaning we have to estimate 10 correlation parameters and 5 variance parameters in order to estimate these random effects. Many of the convergence problems that <code>lmer</code> has seem to relate to the estimation of the correlation parameters for random slopes. Since our Bayesian models have prior distributions on these correlation parameters, they can do a much better job of investigating the random effects correlations and can therefore easily (but perhaps slowly) find solutions for models with even large numbers of random effects.</p>
</div>
</div>
<div id="answering-our-research-questions-1" class="section level2" number="6.6">
<h2><span class="header-section-number">6.6</span> Answering our research questions</h2>
<p>Let’s return to the output of our random slopes model to see where we stand with respect to our research question: How does f0 relate to the perception of speaker size?</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="random-slopes-and-multiple-random-effects.html#cb146-1" aria-hidden="true" tabindex="-1"></a>random_slopes_model</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: pheight ~ g0_c + (g0_c | subj) + (1 | speaker) 
##    Data: h95 (Number of observations: 2780) 
## Samples: 4 chains, each with iter = 7500; warmup = 1000; thin = 4;
##          total post-warmup samples = 6500
## 
## Group-Level Effects: 
## ~speaker (Number of levels: 139) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     5.52      0.47     4.65     6.51 1.00     1643     2982
## 
## ~subj (Number of levels: 10) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           1.81      0.54     1.09     3.18 1.00     4776     5714
## sd(g0_c)                4.21      1.22     2.54     7.25 1.00     5435     5917
## cor(Intercept,g0_c)     0.34      0.27    -0.27     0.77 1.00     5602     5807
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    60.93      0.76    59.44    62.43 1.00     1539     3029
## g0_c         -6.34      1.94   -10.17    -2.63 1.00     2883     4064
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     3.83      0.05     3.73     3.94 1.00     5831     6083
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>There is clearly an effect for f0 on perceived height, and our credible intervals suggest that this effect is unlikely to be zero or even a very small value. If we were so inclined we could leave it at that and conclude “f0 predicts perceived height”. However, we can do a very simple form of posterior prediction by considering the lines generated by our models. In the figure below (recreated from above) we can see that the lines are actually doing a pretty terrible job of predicting where the data is. In most cases, there is no data where the line actually is! Are you happy with a model whose predictions are almost entirely different from your data?</p>
<div class="figure"><span id="fig:F6-12"></span>
<img src="06_files/figure-html/F6-12-1.png" alt="Each plot shows responses from a single subject. Lines indicate best fit line relating variables, as indicated by our fixed slopes model." width="768" />
<p class="caption">
Figure 6.13: Each plot shows responses from a single subject. Lines indicate best fit line relating variables, as indicated by our fixed slopes model.
</p>
</div>
<p>When we look at the model statement above, we can see that the residual error (<code>sigma</code>, <span class="math inline">\(\sigma_{error}\)</span>) is only 3.8 inches, meaning our model can predict perceived height with an expected error of 3.8 inches. That doesn’t seem that bad. However, if we look at the standard deviation for the speaker intercepts (<code>sd(Intercept)</code> under <code>~speaker</code>, <span class="math inline">\(\sigma_{\alpha_{[speaker]}}\)</span>) we can see that this is 5.5 inches. In other words, our model contains large amounts of speaker specific variation in perceived height. This variation is ‘explained’ by the random effects in our model, but is not being explained by f0. We can inspect these below:</p>
<div class="figure"><span id="fig:F6-13"></span>
<img src="06_files/figure-html/F6-13-1.png" alt="Speaker random intercepts and credible intervals colored by group (red = boys, yellow = girls, green = men, blue = women)." width="768" />
<p class="caption">
Figure 6.14: Speaker random intercepts and credible intervals colored by group (red = boys, yellow = girls, green = men, blue = women).
</p>
</div>
<p>Remember, these ‘random’ effects are being modeled as being normally distributed with a mean of 0. The distribution of random effects clearly shows a systematic pattern according to speaker group. In general, boys and girls have negative coefficients meaning they are perceived as <em>smaller than expected given their f0</em>. In contrast, the positive coefficients for adult males and females indicate that the speakers in these groups were perceived as <em>taller than expected given their f0</em>.</p>
<p>The speaker intercepts above show a remarkable amount of consistency within group. However, keep in mind that listeners were not told the group the speaker belonged to, so either 1) listener guessed speaker group and used this to guess size, or 2) there are other acoustic cues that vary systematically between groups, and listeners used this to estimate size. In either case, this suggests that our model needs to change in order to really capture how listeners are arriving at size judgments for these speakers.</p>
<p>As a result, we could say that this model definitely suggests a relationship between f0 and perceived size. However, there number of discrepancies between our data and our model as currently implemented suggests that we should be looking to make adjustments to the structure of this model.</p>
</div>
<div id="frequentist-corner-3" class="section level2" number="6.7">
<h2><span class="header-section-number">6.7</span> Frequentist corner</h2>
<div id="bayesian-multilevel-modesl-vs.-lmer-3" class="section level3" number="6.7.1">
<h3><span class="header-section-number">6.7.1</span> Bayesian multilevel modesl vs. lmer</h3>
<p>We can fit a ‘random slopes’ model with <code>lmer</code> using the code below:</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="random-slopes-and-multiple-random-effects.html#cb148-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> lme4<span class="sc">::</span><span class="fu">lmer</span> (pheight <span class="sc">~</span> g0_c <span class="sc">+</span>  (g0_c<span class="sc">|</span>subj) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>speaker), <span class="at">data =</span> h95)</span></code></pre></div>
<p>Below I recreate the middle part of the <code>lmer</code> model print statement, except I added numbers to some rows. This is because <code>lmer</code> and <code>brm</code> present much of the same information but with different labels and in a different order.</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="random-slopes-and-multiple-random-effects.html#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Random effects:</span></span>
<span id="cb149-2"><a href="random-slopes-and-multiple-random-effects.html#cb149-2" aria-hidden="true" tabindex="-1"></a><span class="do">##     Groups   Name        Variance Std.Dev.  Corr</span></span>
<span id="cb149-3"><a href="random-slopes-and-multiple-random-effects.html#cb149-3" aria-hidden="true" tabindex="-1"></a><span class="do">## (1) speaker  (Intercept) 29.903   5.468        </span></span>
<span id="cb149-4"><a href="random-slopes-and-multiple-random-effects.html#cb149-4" aria-hidden="true" tabindex="-1"></a><span class="do">## (2) subj     (Intercept)  2.326   1.525        </span></span>
<span id="cb149-5"><a href="random-slopes-and-multiple-random-effects.html#cb149-5" aria-hidden="true" tabindex="-1"></a><span class="do">## (3)          g0_c        12.908   3.593  (7) 0.52</span></span>
<span id="cb149-6"><a href="random-slopes-and-multiple-random-effects.html#cb149-6" aria-hidden="true" tabindex="-1"></a><span class="do">## (4) Residual             14.649   3.827        </span></span>
<span id="cb149-7"><a href="random-slopes-and-multiple-random-effects.html#cb149-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of obs: 2780, groups:  speaker, 139; subj, 10</span></span>
<span id="cb149-8"><a href="random-slopes-and-multiple-random-effects.html#cb149-8" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb149-9"><a href="random-slopes-and-multiple-random-effects.html#cb149-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Fixed effects:</span></span>
<span id="cb149-10"><a href="random-slopes-and-multiple-random-effects.html#cb149-10" aria-hidden="true" tabindex="-1"></a><span class="do">##                Estimate Std. Error t value</span></span>
<span id="cb149-11"><a href="random-slopes-and-multiple-random-effects.html#cb149-11" aria-hidden="true" tabindex="-1"></a><span class="do">## (5) (Intercept)  60.9939     0.6731  90.621</span></span>
<span id="cb149-12"><a href="random-slopes-and-multiple-random-effects.html#cb149-12" aria-hidden="true" tabindex="-1"></a><span class="do">## (6) g0_c         -6.3488     1.5340  -4.139</span></span></code></pre></div>
<p>Below I show the <code>random_slopes_model</code> print statement with numbers that match the labels in the print statement above. We see that both models provide reasonably similar estimates for our parameters, with the <code>brm</code> model providing more information about parameter intervals.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="random-slopes-and-multiple-random-effects.html#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Group-Level Effects: </span></span>
<span id="cb150-2"><a href="random-slopes-and-multiple-random-effects.html#cb150-2" aria-hidden="true" tabindex="-1"></a><span class="do">## ~speaker (Number of levels: 139) </span></span>
<span id="cb150-3"><a href="random-slopes-and-multiple-random-effects.html#cb150-3" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb150-4"><a href="random-slopes-and-multiple-random-effects.html#cb150-4" aria-hidden="true" tabindex="-1"></a><span class="do">## (1) sd(Intercept)     5.52      0.47     4.65     6.51 1.00     1643     2982</span></span>
<span id="cb150-5"><a href="random-slopes-and-multiple-random-effects.html#cb150-5" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb150-6"><a href="random-slopes-and-multiple-random-effects.html#cb150-6" aria-hidden="true" tabindex="-1"></a><span class="do">## ~subj (Number of levels: 10) </span></span>
<span id="cb150-7"><a href="random-slopes-and-multiple-random-effects.html#cb150-7" aria-hidden="true" tabindex="-1"></a><span class="do">##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb150-8"><a href="random-slopes-and-multiple-random-effects.html#cb150-8" aria-hidden="true" tabindex="-1"></a><span class="do">## (2) sd(Intercept)           1.81      0.54     1.09     3.18 1.00     4776     5714</span></span>
<span id="cb150-9"><a href="random-slopes-and-multiple-random-effects.html#cb150-9" aria-hidden="true" tabindex="-1"></a><span class="do">## (3) sd(g0_c)                4.21      1.22     2.54     7.25 1.00     5435     5917</span></span>
<span id="cb150-10"><a href="random-slopes-and-multiple-random-effects.html#cb150-10" aria-hidden="true" tabindex="-1"></a><span class="do">## (7) cor(Intercept,g0_c)     0.34      0.27    -0.27     0.77 1.00     5602     5807</span></span>
<span id="cb150-11"><a href="random-slopes-and-multiple-random-effects.html#cb150-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-12"><a href="random-slopes-and-multiple-random-effects.html#cb150-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Population-Level Effects: </span></span>
<span id="cb150-13"><a href="random-slopes-and-multiple-random-effects.html#cb150-13" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb150-14"><a href="random-slopes-and-multiple-random-effects.html#cb150-14" aria-hidden="true" tabindex="-1"></a><span class="do">## (5) Intercept    60.93      0.76    59.44    62.43 1.00     1539     3029</span></span>
<span id="cb150-15"><a href="random-slopes-and-multiple-random-effects.html#cb150-15" aria-hidden="true" tabindex="-1"></a><span class="do">## (6) g0_c         -6.34      1.94   -10.17    -2.63 1.00     2883     4064</span></span>
<span id="cb150-16"><a href="random-slopes-and-multiple-random-effects.html#cb150-16" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb150-17"><a href="random-slopes-and-multiple-random-effects.html#cb150-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Family Specific Parameters: </span></span>
<span id="cb150-18"><a href="random-slopes-and-multiple-random-effects.html#cb150-18" aria-hidden="true" tabindex="-1"></a><span class="do">##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb150-19"><a href="random-slopes-and-multiple-random-effects.html#cb150-19" aria-hidden="true" tabindex="-1"></a><span class="do">## (4) sigma     3.83      0.05     3.73     3.94 1.00     5831     6083</span></span></code></pre></div>
<p>Below is a comparison of the subject intercepts and slopes fit by both approches:</p>
<div class="figure"><span id="fig:F6-14"></span>
<img src="06_files/figure-html/F6-14-1.png" alt="(left) Subject random intercepts and credible intervals estimated using brms models. Crosses indicate random effects estimated by lmer. (right) Same as right but for random slopes." width="768" />
<p class="caption">
Figure 6.15: (left) Subject random intercepts and credible intervals estimated using brms models. Crosses indicate random effects estimated by lmer. (right) Same as right but for random slopes.
</p>
</div>
<p>And the speaker random intercepts estimates by both approaches. In both cases we see that we arrive at basically the same results using either analysis method.</p>
<div class="figure"><span id="fig:F6-15"></span>
<img src="06_files/figure-html/F6-15-1.png" alt="Speaker random intercepts and credible intervals estimated using brms models. Crosses indicate random effects estimated by lmer." width="768" />
<p class="caption">
Figure 6.16: Speaker random intercepts and credible intervals estimated using brms models. Crosses indicate random effects estimated by lmer.
</p>
</div>
<p>I’m also going to fit a model that was described but not fit above. Below we see a model predicting perceived height as a function of centered log F1 and f0. It also included an effect for adultness and an adultness by F1 interaction. The model includes random intercepts for subject and by subject slopes for all predictors. A random by-speaker intercept was also included.</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="random-slopes-and-multiple-random-effects.html#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make variable that indicates if the talker is an adult</span></span>
<span id="cb151-2"><a href="random-slopes-and-multiple-random-effects.html#cb151-2" aria-hidden="true" tabindex="-1"></a>h95<span class="sc">$</span>adult <span class="ot">=</span> <span class="st">&quot;&quot;</span></span>
<span id="cb151-3"><a href="random-slopes-and-multiple-random-effects.html#cb151-3" aria-hidden="true" tabindex="-1"></a>h95<span class="sc">$</span>adult[h95<span class="sc">$</span>group <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&#39;w&#39;</span>,<span class="st">&#39;m&#39;</span>)] <span class="ot">=</span> <span class="st">&quot;adult&quot;</span></span>
<span id="cb151-4"><a href="random-slopes-and-multiple-random-effects.html#cb151-4" aria-hidden="true" tabindex="-1"></a>h95<span class="sc">$</span>adult[h95<span class="sc">$</span>group <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&#39;g&#39;</span>,<span class="st">&#39;b&#39;</span>)] <span class="ot">=</span> <span class="st">&quot;child&quot;</span></span>
<span id="cb151-5"><a href="random-slopes-and-multiple-random-effects.html#cb151-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb151-6"><a href="random-slopes-and-multiple-random-effects.html#cb151-6" aria-hidden="true" tabindex="-1"></a><span class="co"># make centered log F1</span></span>
<span id="cb151-7"><a href="random-slopes-and-multiple-random-effects.html#cb151-7" aria-hidden="true" tabindex="-1"></a>h95<span class="sc">$</span>g1_c <span class="ot">=</span> <span class="fu">log</span>(h95<span class="sc">$</span>f1) <span class="sc">-</span> <span class="fu">mean</span> (<span class="fu">log</span>(h95<span class="sc">$</span>f1))</span>
<span id="cb151-8"><a href="random-slopes-and-multiple-random-effects.html#cb151-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb151-9"><a href="random-slopes-and-multiple-random-effects.html#cb151-9" aria-hidden="true" tabindex="-1"></a>formula <span class="ot">=</span> pheight <span class="sc">~</span> g0_c <span class="sc">+</span> g1_c <span class="sc">+</span> adult <span class="sc">+</span> g1_c<span class="sc">:</span>adult <span class="sc">+</span> </span>
<span id="cb151-10"><a href="random-slopes-and-multiple-random-effects.html#cb151-10" aria-hidden="true" tabindex="-1"></a>                   (g0_c <span class="sc">+</span> g1_c <span class="sc">+</span> adult <span class="sc">+</span> g1_c<span class="sc">:</span>adult<span class="sc">|</span>subj) <span class="sc">+</span> </span>
<span id="cb151-11"><a href="random-slopes-and-multiple-random-effects.html#cb151-11" aria-hidden="true" tabindex="-1"></a>                   (<span class="dv">1</span><span class="sc">|</span>speaker)</span>
<span id="cb151-12"><a href="random-slopes-and-multiple-random-effects.html#cb151-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb151-13"><a href="random-slopes-and-multiple-random-effects.html#cb151-13" aria-hidden="true" tabindex="-1"></a>model_2 <span class="ot">=</span> lme4<span class="sc">::</span><span class="fu">lmer</span> (formula, <span class="at">data =</span> h95)</span></code></pre></div>
<p>Notice that <code>lmer</code> also treats our subject random effects as draws from a 5-dimensional normal distribution. It provides estimates of the standard deviations of the five dimensions (under <code>Random effects:</code> and <code>subj</code>), and also estimates of the correlations between the dimensions.</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="random-slopes-and-multiple-random-effects.html#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span> (model_2)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: pheight ~ g0_c + g1_c + adult + g1_c:adult + (g0_c + g1_c + adult +  
##     g1_c:adult | subj) + (1 | speaker)
##    Data: h95
## 
## REML criterion at convergence: 15283.3
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.0394 -0.5447  0.0323  0.6016  4.7085 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr                   
##  speaker  (Intercept)  3.1496  1.7747                          
##  subj     (Intercept)  2.8338  1.6834                          
##           g0_c        12.9514  3.5988    0.25                  
##           g1_c         0.6226  0.7891    0.75 -0.33            
##           adult1       2.0034  1.4154   -0.41  0.31 -0.21      
##           g1_c:adult1  0.8725  0.9341    0.35 -0.04  0.55  0.12
##  Residual             12.5969  3.5492                          
## Number of obs: 2780, groups:  speaker, 139; subj, 10
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  59.4982     0.5618 105.897
## g0_c        -11.1546     1.2865  -8.670
## g1_c         -2.4530     0.3384  -7.249
## adult1        4.1865     0.4920   8.509
## g1_c:adult1  -1.2790     0.3709  -3.448
## 
## Correlation of Fixed Effects:
##             (Intr) g0_c   g1_c   adult1
## g0_c         0.179                     
## g1_c         0.501 -0.154              
## adult1      -0.402  0.345 -0.091       
## g1_c:adult1  0.286 -0.034  0.176  0.071
## optimizer (nloptwrap) convergence code: 0 (OK)
## boundary (singular) fit: see ?isSingular</code></pre>
</div>
</div>
<div id="exercises-5" class="section level2" number="6.8">
<h2><span class="header-section-number">6.8</span> Exercises</h2>

</div>
</div>
<!-- Default Statcounter code for statsbook
https://santiagobarreda.github.io/stats-class/ -->
<script type="text/javascript">
var sc_project=12454226; 
var sc_invisible=1; 
var sc_security="a1959418"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12454226/0/a1959418/1/"
alt="Web Analytics"></a></div></noscript>
<!-- End of Statcounter Code -->
            </section>

          </div>
        </div>
      </div>
<a href="continuous-predictors-and-their-interactions-with-factors.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="plot-code.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
