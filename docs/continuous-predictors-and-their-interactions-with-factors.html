<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Continuous predictors and their interactions with factors | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R</title>
  <meta name="description" content="Bayesian Models for Repeated-Measures" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Continuous predictors and their interactions with factors | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://santiagobarreda.com" />
  
  <meta property="og:description" content="Bayesian Models for Repeated-Measures" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Continuous predictors and their interactions with factors | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R" />
  
  <meta name="twitter:description" content="Bayesian Models for Repeated-Measures" />
  

<meta name="author" content="Santiago Bareda" />


<meta name="date" content="2021-08-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="comparing-many-groups-anova-and-interactions.html"/>
<link rel="next" href="random-slopes-and-multiple-random-effects.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Models for Linguists</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><i class="fa fa-check"></i><b>1</b> Inspecting a single group of observations: Introduction to regression models</a>
<ul>
<li class="chapter" data-level="1.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#data-and-research-questions"><i class="fa fa-check"></i><b>1.1</b> Data and research questions</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#inspecting-the-central-location-and-spread-of-values"><i class="fa fa-check"></i><b>1.1.1</b> Inspecting the central location and spread of values</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#probability-distributions"><i class="fa fa-check"></i><b>1.2</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#the-normal-distribution"><i class="fa fa-check"></i><b>1.2.1</b> The normal distribution</a></li>
<li class="chapter" data-level="1.2.2" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#referring-to-the-normal-distribution-to-make-inferences"><i class="fa fa-check"></i><b>1.2.2</b> Referring to the normal distribution to make inferences</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#probabilities-of-events-and-likelihoods-of-parameters"><i class="fa fa-check"></i><b>1.3</b> Probabilities of events and likelihoods of parameters</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#calculating-likelihood-functions"><i class="fa fa-check"></i><b>1.3.1</b> Calculating likelihood functions</a></li>
<li class="chapter" data-level="1.3.2" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#making-inferences-using-likelihoods"><i class="fa fa-check"></i><b>1.3.2</b> Making inferences using likelihoods</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#bayesian-models"><i class="fa fa-check"></i><b>1.4</b> Bayesian models</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#what-are-regression-models"><i class="fa fa-check"></i><b>1.4.1</b> What are regression models?</a></li>
<li class="chapter" data-level="1.4.2" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#whats-bayesian-about-these-models"><i class="fa fa-check"></i><b>1.4.2</b> What’s ‘Bayesian’ about these models?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#posterior-distributions"><i class="fa fa-check"></i><b>1.5</b> Posterior distributions</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#sampling-from-the-posterior"><i class="fa fa-check"></i><b>1.5.1</b> Sampling from the posterior</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="inspecting-a-single-group-of-observations-introduction-to-regression-models.html"><a href="inspecting-a-single-group-of-observations-introduction-to-regression-models.html#exercises"><i class="fa fa-check"></i><b>1.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><i class="fa fa-check"></i><b>2</b> Inspecting a ‘single group’ of observations using a Bayesian multilevel model</a>
<ul>
<li class="chapter" data-level="2.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#data-and-research-questions-1"><i class="fa fa-check"></i><b>2.1</b> Data and research questions</a></li>
<li class="chapter" data-level="2.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#estimating-a-single-mean-with-the-brms-package"><i class="fa fa-check"></i><b>2.2</b> Estimating a single mean with the <code>brms</code> package</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#description-of-the-model"><i class="fa fa-check"></i><b>2.2.1</b> Description of the model</a></li>
<li class="chapter" data-level="2.2.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#the-model-formula"><i class="fa fa-check"></i><b>2.2.2</b> The model formula</a></li>
<li class="chapter" data-level="2.2.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#fitting-the-model-calling-the-brm-function"><i class="fa fa-check"></i><b>2.2.3</b> Fitting the model: Calling the <code>brm</code> function</a></li>
<li class="chapter" data-level="2.2.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#interpreting-the-model-the-print-statement"><i class="fa fa-check"></i><b>2.2.4</b> Interpreting the model: the print statement</a></li>
<li class="chapter" data-level="2.2.5" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#seeing-the-samples"><i class="fa fa-check"></i><b>2.2.5</b> Seeing the samples</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#repeated-measures-data"><i class="fa fa-check"></i><b>2.3</b> Repeated measures data</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#multilevel-models"><i class="fa fa-check"></i><b>2.3.1</b> Multilevel models</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#estimating-a-multilevel-model-with-brms"><i class="fa fa-check"></i><b>2.4</b> Estimating a multilevel model with <code>brms</code></a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#description-of-the-model-1"><i class="fa fa-check"></i><b>2.4.1</b> Description of the model</a></li>
<li class="chapter" data-level="2.4.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#fitting-the-model"><i class="fa fa-check"></i><b>2.4.2</b> Fitting the model</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#checking-model-convergence"><i class="fa fa-check"></i><b>2.5</b> Checking model convergence</a></li>
<li class="chapter" data-level="2.6" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#specifying-prior-probabilities"><i class="fa fa-check"></i><b>2.6</b> Specifying prior probabilities</a></li>
<li class="chapter" data-level="2.7" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#answering-our-research-questions"><i class="fa fa-check"></i><b>2.7</b> Answering our research questions</a></li>
<li class="chapter" data-level="2.8" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#simulating-data-using-our-model-parameters"><i class="fa fa-check"></i><b>2.8</b> Simulating data using our model parameters</a></li>
<li class="chapter" data-level="2.9" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#frequentist-corner"><i class="fa fa-check"></i><b>2.9</b> Frequentist corner</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#bayesian-multilevel-modesl-vs.-lmer"><i class="fa fa-check"></i><b>2.9.1</b> Bayesian multilevel modesl vs. lmer</a></li>
<li class="chapter" data-level="2.9.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#bayesian-multilevel-modesl-vs.-the-one-sample-t-test"><i class="fa fa-check"></i><b>2.9.2</b> Bayesian multilevel modesl vs. the one-sample t-test</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#exercises-1"><i class="fa fa-check"></i><b>2.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html"><i class="fa fa-check"></i><b>3</b> Comparing two groups of observations: Factors and contrasts</a>
<ul>
<li class="chapter" data-level="3.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#data-and-research-questions-2"><i class="fa fa-check"></i><b>3.1</b> Data and research questions</a></li>
<li class="chapter" data-level="3.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#estimating-the-difference-between-two-means-with-brms"><i class="fa fa-check"></i><b>3.2</b> Estimating the difference between two means with ‘brms’</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-the-model-1"><i class="fa fa-check"></i><b>3.2.1</b> Fitting the model</a></li>
<li class="chapter" data-level="3.2.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#interpreting-the-model"><i class="fa fa-check"></i><b>3.2.2</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#contrasts"><i class="fa fa-check"></i><b>3.3</b> Contrasts</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#treatment-coding"><i class="fa fa-check"></i><b>3.3.1</b> Treatment coding</a></li>
<li class="chapter" data-level="3.3.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#sum-coding"><i class="fa fa-check"></i><b>3.3.2</b> Sum coding</a></li>
<li class="chapter" data-level="3.3.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#comparison-of-sum-and-treatment-coding"><i class="fa fa-check"></i><b>3.3.3</b> Comparison of sum and treatment coding</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#refitting-the-model-with-sum-coding"><i class="fa fa-check"></i><b>3.4</b> Refitting the model with sum coding</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-the-model-2"><i class="fa fa-check"></i><b>3.4.1</b> Fitting the model</a></li>
<li class="chapter" data-level="3.4.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#description-of-the-model-2"><i class="fa fa-check"></i><b>3.4.2</b> Description of the model</a></li>
<li class="chapter" data-level="3.4.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#interpreting-the-model-1"><i class="fa fa-check"></i><b>3.4.3</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#random-effects"><i class="fa fa-check"></i><b>3.5</b> ‘Random’ Effects</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#random-effects-priors-and-pooling"><i class="fa fa-check"></i><b>3.5.1</b> Random effects, priors and pooling</a></li>
<li class="chapter" data-level="3.5.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#inspecting-the-random-effects"><i class="fa fa-check"></i><b>3.5.2</b> Inspecting the random effects</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#but-what-does-it-all-mean"><i class="fa fa-check"></i><b>3.6</b> But what does it all mean?</a></li>
<li class="chapter" data-level="3.7" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#simulating-the-two-group-model"><i class="fa fa-check"></i><b>3.7</b> Simulating the two-group model</a></li>
<li class="chapter" data-level="3.8" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#frequentist-corner-1"><i class="fa fa-check"></i><b>3.8</b> Frequentist corner</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#bayesian-multilevel-modesl-vs.-lmer-1"><i class="fa fa-check"></i><b>3.8.1</b> Bayesian multilevel modesl vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#exercises-2"><i class="fa fa-check"></i><b>3.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html"><i class="fa fa-check"></i><b>4</b> Comparing many groups: ANOVA and interactions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#data-and-research-questions-3"><i class="fa fa-check"></i><b>4.1</b> Data and research questions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#factors-as-batches-effects"><i class="fa fa-check"></i><b>4.1.1</b> Factors as ‘batches’ effects</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#comparing-four-or-any-number-of-groups"><i class="fa fa-check"></i><b>4.2</b> Comparing four (or any number of) groups</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#the-model"><i class="fa fa-check"></i><b>4.2.1</b> The model</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#investigating-many-factors-simultaneously-analysis-of-variance"><i class="fa fa-check"></i><b>4.3</b> Investigating many factors simultaneously: Analysis of Variance</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#description-of-the-model-3"><i class="fa fa-check"></i><b>4.3.1</b> Description of the model</a></li>
<li class="chapter" data-level="4.3.2" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#fitting-the-model-and-interpreting-the-results"><i class="fa fa-check"></i><b>4.3.2</b> Fitting the model and interpreting the results</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#investigating-model-fit"><i class="fa fa-check"></i><b>4.4</b> Investigating model fit</a></li>
<li class="chapter" data-level="4.5" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#interactions-and-interaction-plots"><i class="fa fa-check"></i><b>4.5</b> Interactions and interaction plots</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#interactions-in-our-f0-data"><i class="fa fa-check"></i><b>4.5.1</b> Interactions in our f0 data</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#investigating-interactions-with-a-model"><i class="fa fa-check"></i><b>4.6</b> Investigating interactions with a model</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#fitting-the-model-and-interpreting-the-results-1"><i class="fa fa-check"></i><b>4.6.1</b> Fitting the model and interpreting the results</a></li>
<li class="chapter" data-level="4.6.2" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#assessing-model-fit"><i class="fa fa-check"></i><b>4.6.2</b> Assessing model fit</a></li>
<li class="chapter" data-level="4.6.3" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#making-plots"><i class="fa fa-check"></i><b>4.6.3</b> Making plots</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#frequentist-corner-2"><i class="fa fa-check"></i><b>4.7</b> Frequentist corner</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#bayesian-multilevel-modesl-vs.-lmer-2"><i class="fa fa-check"></i><b>4.7.1</b> Bayesian multilevel modesl vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="comparing-many-groups-anova-and-interactions.html"><a href="comparing-many-groups-anova-and-interactions.html#exercises-3"><i class="fa fa-check"></i><b>4.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html"><i class="fa fa-check"></i><b>5</b> Continuous predictors and their interactions with factors</a>
<ul>
<li class="chapter" data-level="5.1" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#data-and-research-questions-4"><i class="fa fa-check"></i><b>5.1</b> Data and research questions</a></li>
<li class="chapter" data-level="5.2" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#continuous-predictors-modeling-variation-along-lines"><i class="fa fa-check"></i><b>5.2</b> Continuous predictors: modeling variation along lines</a></li>
<li class="chapter" data-level="5.3" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#models-with-a-single-slope-and-intercept"><i class="fa fa-check"></i><b>5.3</b> Models with a single slope and intercept</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#description-of-the-model-4"><i class="fa fa-check"></i><b>5.3.1</b> Description of the model</a></li>
<li class="chapter" data-level="5.3.2" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#fitting-the-model-3"><i class="fa fa-check"></i><b>5.3.2</b> Fitting the model</a></li>
<li class="chapter" data-level="5.3.3" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#interpreting-the-model-2"><i class="fa fa-check"></i><b>5.3.3</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#centering-predictors"><i class="fa fa-check"></i><b>5.4</b> Centering predictors</a></li>
<li class="chapter" data-level="5.5" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#interactions-in-our-line-parameters"><i class="fa fa-check"></i><b>5.5</b> Interactions in our line parameters</a></li>
<li class="chapter" data-level="5.6" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#models-with-group-dependent-intercepts-but-shared-slopes"><i class="fa fa-check"></i><b>5.6</b> Models with group-dependent intercepts, but shared slopes</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#description-of-the-model-5"><i class="fa fa-check"></i><b>5.6.1</b> Description of the model</a></li>
<li class="chapter" data-level="5.6.2" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#fitting-the-model-4"><i class="fa fa-check"></i><b>5.6.2</b> Fitting the model</a></li>
<li class="chapter" data-level="5.6.3" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#the-effect-of-including-a-slope"><i class="fa fa-check"></i><b>5.6.3</b> The effect of including a slope</a></li>
<li class="chapter" data-level="5.6.4" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#interpreting-group-effects-in-the-presence-of-a-continuous-predictor"><i class="fa fa-check"></i><b>5.6.4</b> Interpreting group effects in the presence of a continuous predictor</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#models-with-group-dependent-slopes-and-intercepts"><i class="fa fa-check"></i><b>5.7</b> Models with group-dependent slopes and intercepts</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#description-of-the-model-6"><i class="fa fa-check"></i><b>5.7.1</b> Description of the model</a></li>
<li class="chapter" data-level="5.7.2" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#fitting-the-model-5"><i class="fa fa-check"></i><b>5.7.2</b> Fitting the model</a></li>
<li class="chapter" data-level="5.7.3" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#interpreting-the-model-3"><i class="fa fa-check"></i><b>5.7.3</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="continuous-predictors-and-their-interactions-with-factors.html"><a href="continuous-predictors-and-their-interactions-with-factors.html#exercises-4"><i class="fa fa-check"></i><b>5.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html"><i class="fa fa-check"></i><b>6</b> Random slopes and multiple random effects</a>
<ul>
<li class="chapter" data-level="6.1" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#data-and-research-questions-5"><i class="fa fa-check"></i><b>6.1</b> Data and research questions</a></li>
<li class="chapter" data-level="6.2" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#repeated-measures-and-speaker-dependent-parameter-values"><i class="fa fa-check"></i><b>6.2</b> Repeated measures and speaker-dependent parameter values</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#description-of-the-model-7"><i class="fa fa-check"></i><b>6.2.1</b> Description of the model</a></li>
<li class="chapter" data-level="6.2.2" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#fitting-the-model-6"><i class="fa fa-check"></i><b>6.2.2</b> Fitting the model</a></li>
<li class="chapter" data-level="6.2.3" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#interpreting-the-model-4"><i class="fa fa-check"></i><b>6.2.3</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#random-effects-and-the-multivariate-normal-distribution"><i class="fa fa-check"></i><b>6.3</b> Random effects and the multivariate normal distribution</a></li>
<li class="chapter" data-level="6.4" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#random-slopes"><i class="fa fa-check"></i><b>6.4</b> Random slopes</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#description-of-the-model-8"><i class="fa fa-check"></i><b>6.4.1</b> Description of the model</a></li>
<li class="chapter" data-level="6.4.2" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#fitting-the-model-7"><i class="fa fa-check"></i><b>6.4.2</b> Fitting the model</a></li>
<li class="chapter" data-level="6.4.3" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#interpreting-the-model-5"><i class="fa fa-check"></i><b>6.4.3</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#more-predictors-and-more-random-slopes"><i class="fa fa-check"></i><b>6.5</b> More predictors and more random slopes</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#adding-another-random-slope"><i class="fa fa-check"></i><b>6.5.1</b> Adding another random slope</a></li>
<li class="chapter" data-level="6.5.2" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#adding-random-factors"><i class="fa fa-check"></i><b>6.5.2</b> Adding random factors</a></li>
<li class="chapter" data-level="6.5.3" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#the-independence-of-continuous-predictors"><i class="fa fa-check"></i><b>6.5.3</b> The independence of continuous predictors</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#answering-our-research-questions-1"><i class="fa fa-check"></i><b>6.6</b> Answering our research questions</a></li>
<li class="chapter" data-level="6.7" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#frequentist-corner-3"><i class="fa fa-check"></i><b>6.7</b> Frequentist corner</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#bayesian-multilevel-modesl-vs.-lmer-3"><i class="fa fa-check"></i><b>6.7.1</b> Bayesian multilevel modesl vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="random-slopes-and-multiple-random-effects.html"><a href="random-slopes-and-multiple-random-effects.html#exercises-5"><i class="fa fa-check"></i><b>6.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="plot-code.html"><a href="plot-code.html"><i class="fa fa-check"></i><b>7</b> Plot Code</a></li>
<li class="divider"></li>
<li><a href="http://www.santiagobarreda.com" target="blank">Written by Santiago Barreda</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="continuous-predictors-and-their-interactions-with-factors" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Continuous predictors and their interactions with factors</h1>
<p>Last chapter we talked about comparing many groups, and including interactions in our models. So far we have only discussed models that include nominal predictors (factors), meaning predictors that split up our observations into discrete groups/categories. In this chapter we’re going to talk about including continuous, numerical predictors in our models.</p>
<p>Just as in chapter 1, we’re going to begin by talking about ‘single’ level (<em>not</em> multi-level) models. These models have no random effects, and so are not really appropriate for our data. We’re going to focus on the interpretation of model coefficients and what these mean for the geometry of the lines we make, so we are not going to worry about the fact that the credible intervals in these models are not appropriate for inference. The geometric interpretations of different model structures are not specifically “Bayesian”. In fact, the concepts presented below are shared by any approach to linear regression.</p>
<p>Next chapter, armed with an understanding of the geometry of continuous predictors, we’ll extend these concepts to understand ‘random slopes and intercepts’ for variables such as speaker and listener.</p>
<p>Before continuing, we should note that designs with many continuous predictors, factors, and interactions between these can result in very complicated models, which then have to be interpreted. However, the researcher has a big role to play in the complexity of the eventual analysis that they are faced with. Once when I was buying a backpack for traveling, I was looking for the biggest backpack possible. One of the reviews said “1/5 stars, it was way too heavy when I filled it all the way up with my stuff”. However, if we fill a backpack up with heavy things, it doesn’t seem fair to blame the poor backpack when it becomes difficult to manage.</p>
<p>In the same way, if you are faced with an overly complex model that you then need to interpret, you shouldn’t blame the model for your predicament. If you design an experiment with a complicated structure (i.e., lot of predictors or interactions). In order to avoid a situation where you end up with data you can’t analyze or a model you don’t know how to interpret, it’s worth considering the following questions before advancing to data collection:</p>
<ul>
<li>How will I analyze the data? Will I be able to?</li>
<li>What will the model structure be?</li>
<li>What would different results ‘mean’? How will this manifest in my regression model?</li>
<li>What kind of results am I expecting?</li>
</ul>
<div id="data-and-research-questions-4" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Data and research questions</h2>
<p>As noted above we are going to start by just focusing on the geometry of different model structures, so we are not going to worry about what kind of data works for these models yet. For now all we need to worry about is that the data contains at least two columns, each of which contains a continuous variable, that is, variables that can take on an unlimited (or at least large) number of different numerical values.</p>
<p>We’re still going to work with the Hillenbrand et al. data, again focusing on variation in f0. However, we’re now going to focus on the results of a listening experiment based on this data. Here are the details of the experiment:</p>
<ol style="list-style-type: decimal">
<li><p>Listeners were 10 native speakers of American English.</p></li>
<li><p>Listeners were presented with the words “heed” and “hod” produced by all 139 of the speakers in the Hillenbrand et al. data. Stimuli were presented at random and one at a time.</p></li>
<li><p>For each trial, listeners were asked to:
a) estimate the height of the speaker in feet and inches.
b) indicate whether they though the speaker was a “boy”, a “girl”, a “man”, or a “woman”.</p></li>
<li><p>Each participant listened to all 238 stimuli once, for a total of 2380 observtions across all subjects.</p></li>
</ol>
<p>This dataset has two response variables that we are interested in: the perceived height (<code>pheight</code>) reported for each trial, and the perceived group (<code>pgroup</code>) reported for each trial. We’re going to start by talking about a summary of the data, available below:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb112-1" aria-hidden="true" tabindex="-1"></a>url1 <span class="ot">=</span> <span class="st">&quot;https://raw.githubusercontent.com/santiagobarreda/stats-class/master/data/&quot;</span></span>
<span id="cb112-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb112-2" aria-hidden="true" tabindex="-1"></a>url2 <span class="ot">=</span> <span class="st">&quot;h95_experiment_summary.csv&quot;</span></span>
<span id="cb112-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb112-3" aria-hidden="true" tabindex="-1"></a>h95 <span class="ot">=</span> <span class="fu">read.csv</span> (<span class="fu">url</span>(<span class="fu">paste0</span> (url1, url2)))</span></code></pre></div>
<p>Rather than every individual response, this dataset contains only the average perceived height (and modal perceived group) for each unique stimulus in the experiment. We’re going to begin by using perceived height as a predictor to see if we can use it to guess the f0 of tokens. This asks: given knowledge of the speaker size a person reported, can we predict the f0 they heard? Of course, this is causally backwards as the f0 ‘causes’ the size perception and not vice versa. However, that doesn’t actually matter for a regression model as these simply investigate the relationships between variables: if x is linearly related to y then y is linearly related to x. Since we have built up some intuitions about the distribution of f0 between speakers, we will begin by considering f0 as the dependent variable.</p>
</div>
<div id="continuous-predictors-modeling-variation-along-lines" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Continuous predictors: modeling variation along lines</h2>
<p>Below I plot the average f0 for each token against its average perceived height in inches. I use a scatter plot with the dependent variable (<code>f0</code>, the thing we are interested in) varying along the y axis (this is done by convention).</p>
<p>The scatter plot clearly shows what is called a <em>linear relationship</em> between the two variables. When you make a scatter plot of two variables that are linearly related you will see points you think are suggestive of a line, or a couple of lines.</p>
<p>Our models have so far featured only nominal predictors, things like group membership. Although it might be strange to think of it this way, our regression models have <em>already</em> been making lines, however, they are lines with slopes of 0 along all possible x axis variables. What this means is, that for any x-axis variable, variation along the x axis variable <strong>has no effect</strong> on variation along the y axis variable (according to our model).</p>
<p>Below I show an example of what I mean by this. Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-fig1">5.1</a> shows an ‘intercept only model’ that features a fixed f0 for all tokens. In the right panel we see four lines, one for each group. These lines have different intercepts but have the same slope (0). This means that these lines try to predict f0 based on group, but do not allow this to vary as a function of perceived height.</p>
<p>When we look at lines such as those below, they tell us that our model thinks mean f0 is <em>independent</em> of perceived height. This is because perceived height can vary from positive to negative infinity and we don’t expect f0 to change (since the line is flat). The same statement could be made for any other x variable we choose because our model does not include slopes for those variables. So, in models like these you can make a bunch of lines, but you only ever change their intercepts.</p>
<div class="figure"><span id="fig:F5-fig1"></span>
<img src="05_files/figure-html/F5-fig1-1.png" alt="(left) f0 plotted against perceived height for each token. Horizontal line is the mean of the group means. (right) Same as right panel except each group gets its own horizontal line. Groups are boys (yellow), girls (green), women (blue), and men (red)." width="768" />
<p class="caption">
Figure 5.1: (left) f0 plotted against perceived height for each token. Horizontal line is the mean of the group means. (right) Same as right panel except each group gets its own horizontal line. Groups are boys (yellow), girls (green), women (blue), and men (red).
</p>
</div>
<p>Recall (from high school) that the equation for a line is the following:</p>
<p><span class="math display" id="eq:51">\[
y = m \times x + b \\ 
\tag{5.1}
\]</span></p>
<p>Where <span class="math inline">\(y\)</span> is the ‘dependent’ variable you are ‘predicting’ using a line with a slope of <span class="math inline">\(m\)</span> and and intercept of <span class="math inline">\(b\)</span>. The slope <span class="math inline">\(m\)</span> represents how much of a change you expect in your <span class="math inline">\(y\)</span> variable for a <em>1 unit change</em> in your x variable. Obviously, this means that the slope depends on the units of measurement of your <span class="math inline">\(x\)</span> variable. In general, dividing your <span class="math inline">\(x\)</span> predictor by <span class="math inline">\(z\)</span> will increase your slopes by a factor of <span class="math inline">\(z\)</span>. For example, imagine measuring the slope of a long hill with a constant rise. The amount of rise measured in meters will necessarily be 1/1000 as large as the rise measured in kilometers.</p>
<p>We can use the following line equation, which just uses symbols that are more similar to the ones we have been using (and presents them in a different order):</p>
<p><span class="math display" id="eq:52">\[
\mu = a + b \times x \\
\tag{5.2}
\]</span></p>
<p>We can predict f0 in the left panel of Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-fig1">5.1</a> using a horizontal line by setting the intercept to the overall grand mean, and setting the slope coefficient to 0. In this case the slope coefficient erases the influence of the continuous predictor <span class="math inline">\(x\)</span> and we would have an ‘intercept only’ regression model just like the one we saw in chapters 1 and 2.</p>
<p><span class="math display" id="eq:53">\[
a = Intercept, b = 0 \\ \\
f0 = Intercept = Intercept + 0 \times pheight \\
\tag{5.3}
\]</span></p>
<p>In the right panel of Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-fig1">5.1</a> we see four horizontal lines, one for each group of speakers. These lines all differ in terms of intercepts but have the same slope (0). This means that these lines try to predict f0 based on group, but don’t allow this to vary as a function of perceived height. So, our four-group model with only nominal predictors in chapter 4 could really be thought of as predicting f0 along a set of lines that are horizontal along the perceived height dimension.</p>
<p><span class="math display" id="eq:56">\[
a = Intercept + group_{[\mathrm{group}]}, b = 0 \\ \\
f0 = Intercept + group_{[\mathrm{group}]} + (0 \times pheight) \\
\tag{5.4}
\]</span></p>
<p>Ok, so what if we <em>do</em> want to think about variation in f0 as a function of variation in perceived height. In Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-52">5.2</a> we can see what this might look like. On the left we have a normal distribution sliding along a horizontal line, generating numbers as it slides. The mean of this data does not vary based on the values of perceived height, and so is <em>independent</em> of them. The standard deviation of this distribution (<span class="math inline">\(\sigma_{error}\)</span>) does not not change as a function of perceived height so its ‘width’ is stable.</p>
<p>On the right in Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-52">5.2</a> we can imagine that the mean of the normal distribution generating f0 values <em>does</em> change as a function of the value of perceived height. We can say that the model on the right predicts f0 <em>conditional on</em> values of perceived height.</p>
<p>The model on the right in Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-52">5.2</a> places an important constraint on this conditional variation: the mean of f0 varies strictly along a straight line. So, to predict f0 given a certain perceived height, we slide our normal distribution along long the diagonal line in Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-52">5.2</a> to the proper x axis location. The y axis value of the line at this x axis location represents our predicted value (<span class="math inline">\(\mu\)</span>). The actual value of observations would then vary around this expected value in a normal distribution with a mean of 0 and a standard deviation equal to <span class="math inline">\(\sigma_{error}\)</span>.</p>
<div class="figure"><span id="fig:F5-52"></span>
<img src="05_files/figure-html/F5-52-1.png" alt="(left) A normal distribution fixed along a horizontal line. (right) A Normal distribution allowed to slide along a diagonal line." width="768" />
<p class="caption">
Figure 5.2: (left) A normal distribution fixed along a horizontal line. (right) A Normal distribution allowed to slide along a diagonal line.
</p>
</div>
</div>
<div id="models-with-a-single-slope-and-intercept" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Models with a single slope and intercept</h2>
<p>We can use the <code>brm</code> function to find the intercept and slope of the ‘best’ line through the points in our two-dimensional space (represented in the scatter plot). Our model formula will look like this:</p>
<p><code>f0 ~ pheight</code></p>
<p>Which tells <code>brms</code> to predict <code>f0</code> based on the values of <code>pheight</code> and an intercept which does not need to be explicitly included in the model formula. If the variable on the right hand side of the <code>~</code> is numeric, <code>brm</code> will treat it as a continuous predictor and predict f0 using a line.</p>
<div id="description-of-the-model-4" class="section level3" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Description of the model</h3>
<p>The structure of a regression model with a single continuous predictor (a ‘bivariate’ regression) is shown below. The first line says that we have a normally-distributed variable with an unknown mean that varies from trial to trial (<span class="math inline">\(\mu_{[i]}\)</span>). The variation in the mean parameter is along a line with an intercept equal to <span class="math inline">\(Intercept\)</span> and a slope of <span class="math inline">\(pheight\)</span> along the x axis.</p>
<p>Note that the predicted value (<span class="math inline">\(\mu_{[i]}\)</span>) and the predictor variable (<span class="math inline">\(x_{[i]}\)</span>) receive subscripts, as these change from trial to trial. The coefficients <strong>do not</strong> receive subscripts because these do not vary in this model. This model contains a single intercept and a single slope (i.e. it draws a single line) for <em>every</em> trial. Also note that we’re simply treating the slope and intercept as ‘fixed’ effects and specifying prior distributions.</p>
<p><span class="math display" id="eq:57">\[\begin{equation}
\begin{split}
\\
\textrm{Likelihood:} \\
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = Intercept + pheight \times x_{[i]}  \\ \\
\textrm{Priors:} \\
Intercept \sim t(3, 175, 100) \\
pheight \sim t(3, 0, 100) \\
\\
\end{split}
\tag{5.5}
\end{equation}\]</span></p>
<p>Here’s another two ways to think about this model: we’re making a line and then we add noise to it. Each of our observed values is just a line (representing systematic variation) and a random draw from an error distribution (<span class="math inline">\(\mathcal{N}(0,\sigma_{error})\)</span>) as below:</p>
<p><span class="math display" id="eq:58">\[
y_{[i]} = a + b * \mathrm{x_{[i]}} + \mathcal{N}(0,\sigma_{error})
\tag{5.6}
\]</span></p>
<p>Alternatively, we could place the formula for the line <em>inside</em> the normal distribution function. There is no particular reason to do this, but it is helpful to see it and realize that it’s the same thing as the representation above. In the equation below, we’re saying: the data is generated according to a normal distribution whose mean varies along a line (<span class="math inline">\(a + b * \mathrm{x_{[i]}}\)</span>), and we expect the variation around this line to have a standard deviation equal to <span class="math inline">\(\sigma_{error}\)</span>.</p>
<p><span class="math display" id="eq:59">\[
\mathcal{N}(a + b * \mathrm{x_{[i]}}, \sigma_{error})  \\
\tag{5.7}
\]</span></p>
<p>Regression models pick the intercept and slope for a line that results in the smallest value of <span class="math inline">\(\sigma_{error}\)</span>. This is why ‘regular’ regression is called <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">“ordinary least-squares”</a> regression, because it finds the solution that results in the ‘least squares’ (i.e., the smallest <span class="math inline">\((\sigma_{error})^2\)</span>) in the prediction errors.</p>
<p>In a multilevel model, the estimation of the ‘best’ slopes and intercepts for our lines can be substantially more complicated than in least-squares regression. However, in general the lines estimated by our regression models will tend to minimize the value of <span class="math inline">\(\sigma_{error}\)</span>, given our data and model structure.</p>
</div>
<div id="fitting-the-model-3" class="section level3" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Fitting the model</h3>
<p>We can use the <code>brm</code> function to find the intercept and slope of the ‘best’ line through the points in our two-dimensional space (represented in the scatter plot).</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span> (<span class="at">contrasts =</span> <span class="fu">c</span>(<span class="st">&quot;contr.sum&quot;</span>,<span class="st">&quot;cont.sum&quot;</span>))</span>
<span id="cb113-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself, or</span></span>
<span id="cb113-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-3" aria-hidden="true" tabindex="-1"></a><span class="co"># download pre-fit model from: </span></span>
<span id="cb113-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-4" aria-hidden="true" tabindex="-1"></a><span class="co"># github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb113-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-5" aria-hidden="true" tabindex="-1"></a><span class="co"># and load after placing in working directory</span></span>
<span id="cb113-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-6" aria-hidden="true" tabindex="-1"></a><span class="co"># single_line_model = readRDS (&#39;5_single_line_model.RDS&#39;)</span></span>
<span id="cb113-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb113-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-9" aria-hidden="true" tabindex="-1"></a>single_line_model <span class="ot">=</span></span>
<span id="cb113-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> pheight, <span class="at">data =</span> h95, <span class="at">chains=</span><span class="dv">1</span>, <span class="at">cores=</span><span class="dv">1</span>,  <span class="at">warmup=</span><span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">6000</span>,</span>
<span id="cb113-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 175, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb113-12"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-12" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb113-13"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-13" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma&quot;</span>)))</span>
<span id="cb113-14"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-14" aria-hidden="true" tabindex="-1"></a><span class="co"># save model</span></span>
<span id="cb113-15"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb113-15" aria-hidden="true" tabindex="-1"></a><span class="co"># saveRDS (single_line_model, &#39;5_single_line_model.RDS&#39;)</span></span></code></pre></div>
</div>
<div id="interpreting-the-model-2" class="section level3" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> Interpreting the model</h3>
<p>The model print statement is mostly the same as for our previous models. Our model contains only ‘fixed’ effects: an <code>Intercept</code>, indicating the intercept of our line, and <code>pheight</code> indicating the slope of f0 along the perceived height axis. We get credible intervals for our slope coefficient, and our model features an estimate of the error (<code>sigma</code>, <span class="math inline">\(\sigma_{error}\)</span>) around our line.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co"># inspect model</span></span>
<span id="cb114-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-2" aria-hidden="true" tabindex="-1"></a>single_line_model</span>
<span id="cb114-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-3" aria-hidden="true" tabindex="-1"></a><span class="do">##  Family: gaussian </span></span>
<span id="cb114-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-4" aria-hidden="true" tabindex="-1"></a><span class="do">##   Links: mu = identity; sigma = identity </span></span>
<span id="cb114-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Formula: f0 ~ pheight </span></span>
<span id="cb114-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-6" aria-hidden="true" tabindex="-1"></a><span class="do">##    Data: h95 (Number of observations: 278) </span></span>
<span id="cb114-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Samples: 1 chains, each with iter = 6000; warmup = 1000; thin = 1;</span></span>
<span id="cb114-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-8" aria-hidden="true" tabindex="-1"></a><span class="do">##          total post-warmup samples = 5000</span></span>
<span id="cb114-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-9" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb114-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Population-Level Effects: </span></span>
<span id="cb114-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-11" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb114-12"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept   588.68     16.42   556.41   620.73 1.00     5261     3935</span></span>
<span id="cb114-13"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-13" aria-hidden="true" tabindex="-1"></a><span class="do">## pheight      -6.36      0.27    -6.89    -5.84 1.00     5283     3962</span></span>
<span id="cb114-14"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-14" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb114-15"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-15" aria-hidden="true" tabindex="-1"></a><span class="do">## Family Specific Parameters: </span></span>
<span id="cb114-16"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-16" aria-hidden="true" tabindex="-1"></a><span class="do">##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb114-17"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-17" aria-hidden="true" tabindex="-1"></a><span class="do">## sigma    30.21      1.31    27.78    32.93 1.00     4562     3693</span></span>
<span id="cb114-18"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-18" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb114-19"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS</span></span>
<span id="cb114-20"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-20" aria-hidden="true" tabindex="-1"></a><span class="do">## and Tail_ESS are effective sample size measures, and Rhat is the potential</span></span>
<span id="cb114-21"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb114-21" aria-hidden="true" tabindex="-1"></a><span class="do">## scale reduction factor on split chains (at convergence, Rhat = 1).</span></span></code></pre></div>
<p>We can see that the line predicting perceived height as a function of f0 has an intercept of 589 and a slope for the <code>pheight</code> (perceived height) predictor of -6.4. The fact that the slope of the <code>pheight</code> predictor is -6.4 means that for every 1 inch increase in perceived height, we expect a <em>decrease</em> of 6.4 Hz in the f0 of the vowel that le to that perception. I draw this line on our set of points in Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-53">5.3</a>.</p>
<p>The slope is a <em>weight</em> that allows the line to accurately fit the points. In the absence of a slope, regression models would only work if there was a 1 to 1 relationship between the x and y variables. This would mean that for every 1 inch change in perceived height, we would see a 1 Hz change in f0. What are the odds of that? What are the odds that the things we measure will be in a 1 to 1 relationship like that in general? The odds are basically zero.</p>
<p>Instead, the slope (<span class="math inline">\(b\)</span> coefficient) on regression models allows a single unit change in the predictor to be associated with different units of change in the <span class="math inline">\(y\)</span> variable. In this case, a 1 unit change in perceived height (measured in inches) is associated with a 6 unit change in f0 (measured in Hz).</p>
<div class="figure"><span id="fig:F5-53"></span>
<img src="05_files/figure-html/F5-53-1.png" alt="(left) Points and best-fit line. (right) A zoomed-out view of the left panel shows the line intercept at y = 588.7 Hz." width="768" />
<p class="caption">
Figure 5.3: (left) Points and best-fit line. (right) A zoomed-out view of the left panel shows the line intercept at y = 588.7 Hz.
</p>
</div>
<p>The intercept is the value of your dependent variable (<span class="math inline">\(y\)</span>) when your predictor (<span class="math inline">\(x\)</span>) is equal to 0. In our model, the expected value of f0 is 588 Hz when the predicted height is 0 inches. These are not particularly meaningful values for either variable as the f0 is too high and people are never 0 inches tall. In the right panel of Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-53">5.3</a> we can see why we get this value: it is simply the y-axis “intercept” (zero crossing) of the line we drew through the points in the left panel.</p>
</div>
</div>
<div id="centering-predictors" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Centering predictors</h2>
<p>We can get more useful intercept values by simply centering our predictor variable(s). Centering a variable means subtracting the mean value from all observations. When this is done, each observation will now represent a deviation from 0, and the sum (and mean) of all the observations will equal zero. Since the intercept of the line is the value of the <span class="math inline">\(y\)</span> variable when the <span class="math inline">\(x\)</span> variable is equal to zero, centering our predictor makes the intercept equal to the value of <span class="math inline">\(y\)</span> when <span class="math inline">\(x\)</span> is equal to its mean (now zero).</p>
<p>Centering predictor variables affects the intercept of the model but does does not affect the slope or error estimates. Thus, centering is basically like choosing the ‘coding’ (e.g., sum coding vs. dummy coding) for lines, it affects how the information is represented in the model but not the information itself. As a result, centering can be tremendously useful in yielding more interpretable intercept estimates. Below, we center perceived height:</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co"># find mean perceived height</span></span>
<span id="cb115-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb115-2" aria-hidden="true" tabindex="-1"></a>mean_perceived_height <span class="ot">=</span> <span class="fu">mean</span>(h95<span class="sc">$</span>pheight)</span>
<span id="cb115-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb115-3" aria-hidden="true" tabindex="-1"></a>mean_perceived_height</span>
<span id="cb115-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb115-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 61.38813</span></span>
<span id="cb115-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb115-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb115-6" aria-hidden="true" tabindex="-1"></a><span class="co"># center perceived height</span></span>
<span id="cb115-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb115-7" aria-hidden="true" tabindex="-1"></a>h95<span class="sc">$</span>pheight_c <span class="ot">=</span> h95<span class="sc">$</span>pheight <span class="sc">-</span> mean_perceived_height</span></code></pre></div>
<p>And fit the same model using this centered predictor:</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself, or</span></span>
<span id="cb116-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-2" aria-hidden="true" tabindex="-1"></a><span class="co"># download pre-fit model from: </span></span>
<span id="cb116-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-3" aria-hidden="true" tabindex="-1"></a><span class="co"># github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb116-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-4" aria-hidden="true" tabindex="-1"></a><span class="co"># and load after placing in working directory</span></span>
<span id="cb116-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-5" aria-hidden="true" tabindex="-1"></a><span class="co"># single_line_model = readRDS (&#39;5_single_line_centered_model.RDS&#39;)</span></span>
<span id="cb116-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb116-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-8" aria-hidden="true" tabindex="-1"></a>single_line_centered_model <span class="ot">=</span></span>
<span id="cb116-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> pheight_c, <span class="at">data=</span>h95, <span class="at">chains=</span><span class="dv">1</span>,<span class="at">cores=</span><span class="dv">1</span>,<span class="at">warmup=</span><span class="dv">1000</span>,<span class="at">iter=</span><span class="dv">6000</span>,</span>
<span id="cb116-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 175, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb116-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-11" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb116-12"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-12" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma&quot;</span>)))</span>
<span id="cb116-13"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-13" aria-hidden="true" tabindex="-1"></a><span class="co"># save model</span></span>
<span id="cb116-14"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb116-14" aria-hidden="true" tabindex="-1"></a><span class="co"># saveRDS (single_line_centered_model, &#39;5_single_line_centered_model.RDS&#39;)</span></span></code></pre></div>
<p>We then inspect the fixed effects for this new model:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># inspect fixed effects</span></span>
<span id="cb117-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb117-2" aria-hidden="true" tabindex="-1"></a>brms<span class="sc">::</span><span class="fu">fixef</span> (single_line_centered_model)</span>
<span id="cb117-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb117-3" aria-hidden="true" tabindex="-1"></a><span class="do">##                   Estimate Est.Error       Q2.5      Q97.5</span></span>
<span id="cb117-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb117-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept        197.98743 1.7748526 194.531738 201.533945</span></span>
<span id="cb117-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb117-5" aria-hidden="true" tabindex="-1"></a><span class="do">## pheight_centered  -6.36766 0.2676307  -6.890297  -5.842301</span></span></code></pre></div>
<p>We can see that the slope coefficient provided by this model is the same as the last model: the slope of the line has not changed. However, our intercept value is now 198. This means that when out predictor is at its mean, we expect f0 to have a value of 198 Hz. The model <em>thinks</em> the mean is 0, but we <em>know</em> it is 61.4 inches, and the centering of the predictor does not affect our ability to interpret it such.</p>
<div class="figure"><span id="fig:F5-slope-n-centered"></span>
<img src="05_files/figure-html/F5-slope-n-centered-1.png" alt="(left) Best fit line for points predicted by perceived height. Horizontal and vertical lines indicated y and x variable means respectively. (right) Same as left but with a centered predictor. " width="768" />
<p class="caption">
Figure 5.4: (left) Best fit line for points predicted by perceived height. Horizontal and vertical lines indicated y and x variable means respectively. (right) Same as left but with a centered predictor.
</p>
</div>
<p>I’m going to center predictors often, simply out of convenience. However, the decision whether to center or not should really be based on the information you hope to get out of your model, just like the decision of which coding system to use for nominal variables.</p>
</div>
<div id="interactions-in-our-line-parameters" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Interactions in our line parameters</h2>
<p>Here’s something that we’ve sort of been tip-toeing around up to this point: group effects such as ‘boy’ and ‘girl’ are effectively ‘interaction’ terms. Remember that interactions are <em>conditional</em> effects. So, when we say “hey what’s the intercept on the horizontal line you use to model f0?”, the answer is actually “it depends on the group” (as seen in Figure @ref:(fig:F5-fig1)). In other words, the intercept in our model is <em>conditional</em> on group, which means the intercept of our model interacts with group. So, when we fit a model like:</p>
<p><code>f0 ~ group</code></p>
<p>The model could be thought of as something like:</p>
<p><code>f0 ~ Intercept + Intercept:group</code></p>
<p>This is because our model will estimate a ‘main effects’ (average) intercept term, and also estimate group-dependent deviations from the main effect (i.e., the <code>Intercept:group</code> interactions). By convention, we don’t actually specify our models like this, however, it’s useful to keep this perspective in mind to really understand the structure of your models.</p>
<p>Including a nominal predictor like <code>group</code> in our regression models has the effect of allowing for group-specific intercepts in our lines. Consider what happens when a continuous predictor like <code>pheight</code> is added to our model formula:</p>
<p><code>f0 ~ group + pheight</code> (or in our expanded format <code>f0 ~ Intercept + Intercept:group + pheight</code>)</p>
<p>This model only includes a slope ‘main effect’, or an <em>average</em> slope effects across all groups. We can see this because the formula does not contain any interactions with our continuous predictor <code>pheight</code>. As a result, the model does not include any way for the <code>pheight</code> slope to vary (e.g., between groups), an you cannot use this model to discuss variation in the slope term.</p>
<p>In the last chapter we discussed the fact that without interactions, shared slopes lead to parallel lines in interaction plots. The same principle applies here. If we draw a bunch of lines with different intercepts but a fixed slope, all the lines will be parallel.</p>
<p>If you want to know about the slope <em>conditional</em> on group, then you need to include a group by slope interaction in your model. We add this to out model formula:</p>
<p><code>f0 ~ group * pheight</code> or <code>f0 ~ group + pheight + pheight:group</code></p>
<p>Which could be expanded like this (in our inaccurate but pedagogically useful expansion of the Intercept term):</p>
<p><code>f0 ~ Intercept + Intercept:group + pheight + pheight:group</code></p>
<p>In plain English, this says: "predict f0 as a function of an intercept, group-dependent variation in Intercepts (modeled by the <code>Intercept:group</code> interactions), a mean overall slope (<code>pheight</code>), and group-dependent variation in slopes (modeled by the <code>pheight:group</code> interactions).</p>
<p>A model like the one above allows us to represent group-dependent variation in lines <em>and</em> intercepts. Effectively, this allows us to have entirely different lines representing the relationships between perceived height and f0 in our data.</p>
<p>In summary, if you have a continuous dependent variable (<span class="math inline">\(y\)</span>), a continuous predictor (<span class="math inline">\(x\)</span>), and a categorical predictor (<span class="math inline">\(A\)</span>), you can define models that:</p>
<ol style="list-style-type: decimal">
<li><code>y ~ x</code>: Include only one single line for all groups.</li>
<li><code>y ~ B</code>: Include different lines for each group but all slopes are 0.</li>
<li><code>y ~ x+B</code>: Include different lines for each group. Each group has its own unique intercept but they all share the same slope.</li>
<li><code>y ~ x*B</code>: Include different lines for each group. Each group has its own unique intercept and slope.</li>
</ol>
</div>
<div id="models-with-group-dependent-intercepts-but-shared-slopes" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> Models with group-dependent intercepts, but shared slopes</h2>
<p>In the previous sections we focused on models that imposed a single line for all groups. Here, we’re going to consider models that allow for differing intercepts between groups. We do this by including our vector specifying group membership <code>group</code> into our model formula:</p>
<p><code>f0 ~ group + pheight</code></p>
<p>The model above says: “model f0 as a function of perceived height, allowing for group-specific variation in the intercept”. Note that our model does <em>not</em> include the interaction between <code>pheight</code> and <code>group</code>. this is because this model includes only a single slope across all groups. As a result, these models represent our data with a set of parallel lines, one for each group.</p>
<p>In order to investigate different characteristics for our lines as a function of group, we effectively need to ‘cross’ our grouping variable with our continuous predictor. For example, imagine we are interested in the effect of lexical frequency on a lexical decision task, and we are interested in how this might vary as a function of age (teenagers vs. retirees). In general, we expect that the high frequency words will be identified faster, resulting in a line with a negative slope. We also expect the teenagers to respond faster meaning their “line” should have a lower intercept. It is unclear a priori whether the slopes of the lines representing the two groups should be different.</p>
<p>If we are interested in understanding if the lines <em>are</em> the same between groups, then it is important that we observe the two groups at approximately the same range of values for the continuous predictor. Imagine that we give only high-frequency words to teens and only low-frequency words to retirees. This is clearly similar to the example of giving coffee only to women and water only to men in the previous chapter. Doing something like this will clearly result in uncertainly with respect to the <em>source</em> of any differences between the groups. It is also important to provide a suitable range for the continuous predictor for all groups. There are an infinite number of lines that will go through any given point. The fewer points you have, and the closer together they are, the easier it is to draw lines that go through them.</p>
<p>So, ensuring that your continuous predictors have approximately the same range across all levels of any factors in your experiment provides many of the benefits of crossing categorical predictors, and should be done when possible.</p>
<div id="description-of-the-model-5" class="section level3" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Description of the model</h3>
<p>The model including group-specific intercepts is presented below. The only difference compared to the previous model is that this now includes a <span class="math inline">\(group\)</span> predictor similar to the one we used initially in Chapter 4. This predictor will allow our groups to be represented by different parallel lines with varying intercepts.</p>
<p><span class="math display" id="eq:510">\[\begin{equation}
\begin{split}
\\
\textrm{Likelihood:} \\
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = Intercept + group_{[\mathrm{group}_{[i]}]} + pheight \times x_{[i]}  \\ \\
\textrm{Priors:} \\
Intercept \sim t(3, 175, 100) \\
pheight \sim t(3, 0, 100) \\ 
group \sim t(3, 0, 100) \\ 
\\
\end{split}
\tag{5.8}
\end{equation}\]</span></p>
<p>Here’s another way to think about this model. In the model below we have <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> parameters that vary from trial to trial. The trial-specific intercept is equal to the overall intercept, and the group predictor for that trial. The slope terms does not actually vary from trial to trial in practice, since it simply equals our <span class="math inline">\(pheight\)</span> slope parameter.</p>
<p>Recall that I suggested that we could perform ‘ANOVA-like’ decompositions on our intercept predictors. Below, model coefficients which affect the intercept of our prediction lines are separated from those that affect our slopes. The formulation below makes it clear that our <span class="math inline">\(pheight\)</span> parameter basically functions as an ‘intercept’ for the slope of our predictor. When we incorporate group-specific slopes in our model in the next section, these will be represented as group-specific deviations in the equation predicting <span class="math inline">\(b_{[i]}\)</span> below.</p>
<p><span class="math display" id="eq:511">\[\begin{equation}
\begin{split}
\\
\textrm{Likelihood:} \\
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = a_{[i]} + b_{[i]} * x_{[i]}  \\ 
a_{[i]} = Intercept + group_{[\mathrm{group}_{[i]}]} \\
b_{[i]} = pheight \\ \\
\textrm{Priors:} \\
Intercept \sim t(3, 175, 100) \\
pheight \sim t(3, 0, 100) \\ 
group \sim t(3, 0, 100) \\ 
\\
\end{split}
\tag{5.9}
\end{equation}\]</span></p>
</div>
<div id="fitting-the-model-4" class="section level3" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Fitting the model</h3>
<p>We fit a model that contains the group predictor and also includes our continuous predictor, but not the interaction between the two:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself, or</span></span>
<span id="cb118-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-2" aria-hidden="true" tabindex="-1"></a><span class="co"># download pre-fit model from: </span></span>
<span id="cb118-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-3" aria-hidden="true" tabindex="-1"></a><span class="co"># github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb118-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-4" aria-hidden="true" tabindex="-1"></a><span class="co"># and load after placing in working directory</span></span>
<span id="cb118-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-5" aria-hidden="true" tabindex="-1"></a><span class="co"># single_line_model = readRDS (&#39;5_group_single_slope_model.RDS&#39;)</span></span>
<span id="cb118-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb118-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-8" aria-hidden="true" tabindex="-1"></a>group_single_slope_model <span class="ot">=</span></span>
<span id="cb118-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> group <span class="sc">+</span> pheight_c, </span>
<span id="cb118-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">data=</span>h95, <span class="at">chains=</span><span class="dv">1</span>,<span class="at">cores=</span><span class="dv">1</span>,<span class="at">warmup=</span><span class="dv">1000</span>,<span class="at">iter=</span><span class="dv">6000</span>,</span>
<span id="cb118-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 175, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb118-12"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-12" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb118-13"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-13" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma&quot;</span>)))</span>
<span id="cb118-14"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-14" aria-hidden="true" tabindex="-1"></a><span class="co"># save model</span></span>
<span id="cb118-15"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb118-15" aria-hidden="true" tabindex="-1"></a><span class="co"># saveRDS (group_single_slope_model, &#39;5_group_single_slope_model.RDS&#39;)</span></span></code></pre></div>
<p>For the sake of comparison, we will also fit a model with only group predictors and no continuous predictor (<code>pheight</code>). As noted above, this is effectively a model with a bunch of horizontal lines (slope = 0), one for each group.</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself, or</span></span>
<span id="cb119-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-2" aria-hidden="true" tabindex="-1"></a><span class="co"># download pre-fit model from: </span></span>
<span id="cb119-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-3" aria-hidden="true" tabindex="-1"></a><span class="co"># github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb119-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-4" aria-hidden="true" tabindex="-1"></a><span class="co"># and load after placing in working directory</span></span>
<span id="cb119-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-5" aria-hidden="true" tabindex="-1"></a><span class="co"># single_line_model = readRDS (&#39;5_group_intercepts_model.RDS&#39;)</span></span>
<span id="cb119-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb119-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-8" aria-hidden="true" tabindex="-1"></a>group_intercepts_model <span class="ot">=</span></span>
<span id="cb119-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> group, <span class="at">data=</span>h95, <span class="at">chains=</span><span class="dv">1</span>,<span class="at">cores=</span><span class="dv">1</span>,<span class="at">warmup=</span><span class="dv">1000</span>,<span class="at">iter=</span><span class="dv">6000</span>,</span>
<span id="cb119-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 175, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb119-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-11" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb119-12"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-12" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma&quot;</span>)))</span>
<span id="cb119-13"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-13" aria-hidden="true" tabindex="-1"></a><span class="co"># save model</span></span>
<span id="cb119-14"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb119-14" aria-hidden="true" tabindex="-1"></a><span class="co"># saveRDS (group_intercepts_model, &#39;5_group_intercepts_model.RDS&#39;)</span></span></code></pre></div>
</div>
<div id="the-effect-of-including-a-slope" class="section level3" number="5.6.3">
<h3><span class="header-section-number">5.6.3</span> The effect of including a slope</h3>
<p>It’s useful to think about the geometry of our models because then we can make pictures, which are usually much easier to interpret than coefficient values. The coefficient values in your model have a one-to-one relationship with a set of lines that make up a plot. Seeing (or imagining) what the picture might look like can go a long way towards understanding the meaning of your model parameters.</p>
<p>Below I recover the overall intercept, and the intercept for each group from our <code>group_intercepts_model</code>. Since this model contains no slope terms these values represent the intercepts of horizontal lines, one for each group (and overall).</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-1" aria-hidden="true" tabindex="-1"></a>group_intercepts_hypothesis <span class="ot">=</span> </span>
<span id="cb120-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hypothesis</span> (group_intercepts_model,</span>
<span id="cb120-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">hypothesis =</span> </span>
<span id="cb120-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-4" aria-hidden="true" tabindex="-1"></a>                <span class="fu">c</span>(<span class="st">&quot;Intercept = 0&quot;</span>,  <span class="co"># overall intercept</span></span>
<span id="cb120-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-5" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;Intercept + group1 = 0&quot;</span>,  <span class="co"># group 1 intercept</span></span>
<span id="cb120-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-6" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;Intercept + group2 = 0&quot;</span>,  <span class="co"># group 2 intercept</span></span>
<span id="cb120-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-7" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;Intercept + group3 = 0&quot;</span>,  <span class="co"># group 3 intercept</span></span>
<span id="cb120-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;Intercept -(group1+group2+group3) = 0&quot;</span>)) <span class="do">## group 4 intercept</span></span>
<span id="cb120-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-9" aria-hidden="true" tabindex="-1"></a>group_intercepts_hypothesis[[<span class="dv">1</span>]][,<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb120-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-10" aria-hidden="true" tabindex="-1"></a><span class="do">##   Estimate Est.Error CI.Lower CI.Upper</span></span>
<span id="cb120-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-11" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 207.7772  1.619998 204.5869 210.9643</span></span>
<span id="cb120-12"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-12" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 237.8620  3.388196 231.2805 244.3704</span></span>
<span id="cb120-13"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-13" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 240.5737  4.043656 232.7012 248.4879</span></span>
<span id="cb120-14"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-14" aria-hidden="true" tabindex="-1"></a><span class="do">## 4 132.0269  2.648429 126.8261 137.0310</span></span>
<span id="cb120-15"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb120-15" aria-hidden="true" tabindex="-1"></a><span class="do">## 5 220.6461  2.491914 215.6652 225.4884</span></span></code></pre></div>
<p>We can then recover the intercepts for each group from our <code>group_single_slope_model</code>. Again, we do this by adding each group effect to the overall Intercept. Unlike our previous model, this model <em>does</em> have a slope. This slope is shared by all of our group lines meaning these differ in their intercepts but not their slopes.</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb121-1" aria-hidden="true" tabindex="-1"></a>group_single_slope_hypothesis <span class="ot">=</span> </span>
<span id="cb121-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb121-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hypothesis</span> (group_single_slope_model,</span>
<span id="cb121-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb121-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">hypothesis =</span> </span>
<span id="cb121-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb121-4" aria-hidden="true" tabindex="-1"></a>                <span class="fu">c</span>(<span class="st">&quot;Intercept = 0&quot;</span>, <span class="co"># overall intercept</span></span>
<span id="cb121-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb121-5" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Intercept + group1 = 0&quot;</span>,  <span class="co"># group 1 intercept</span></span>
<span id="cb121-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb121-6" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Intercept + group2 = 0&quot;</span>,  <span class="co"># group 2 intercept</span></span>
<span id="cb121-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb121-7" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Intercept + group3 = 0&quot;</span>,  <span class="co"># group 3 intercept</span></span>
<span id="cb121-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb121-8" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Intercept + -(group1+group2+group3)=0&quot;</span>, <span class="co"># group 4 intercept</span></span>
<span id="cb121-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb121-9" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;pheight_c = 0&quot;</span>) <span class="co"># overall slope</span></span>
<span id="cb121-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb121-10" aria-hidden="true" tabindex="-1"></a>)   </span>
<span id="cb121-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb121-11" aria-hidden="true" tabindex="-1"></a>group_single_slope_hypothesis[[<span class="dv">1</span>]][,<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>]</span></code></pre></div>
<pre><code>##     Estimate Est.Error   CI.Lower   CI.Upper
## 1 199.179765 1.7911275 195.580187 202.805323
## 2 206.488554 4.9183377 196.650824 216.231669
## 3 203.383898 5.8259319 191.764627 214.944576
## 4 163.628055 4.5384288 154.794447 172.780375
## 5 223.218554 2.2955315 218.678988 227.655562
## 6  -4.267038 0.5208129  -5.306696  -3.266594</code></pre>
<p>In Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-55">5.5</a> I draw the the lines specified by our two models. On the left, the four group lines share a slope (that just happens to be zero). On the right, we see four lines with a shared slope that is <em>not</em> zero. It seems that these diagonal lines provide better fits for our data, and our <code>group_single_slope_model</code> lets us represent this.</p>
<div class="figure"><span id="fig:F5-55"></span>
<img src="05_files/figure-html/F5-55-1.png" alt="(left) Lines for each distribution in our no-slope model. (right) Lines for each distribution in our shared-slope model. Lines correspond to boys (yellow), girls (green), men (red), and women (blue)." width="768" />
<p class="caption">
Figure 5.5: (left) Lines for each distribution in our no-slope model. (right) Lines for each distribution in our shared-slope model. Lines correspond to boys (yellow), girls (green), men (red), and women (blue).
</p>
</div>
</div>
<div id="interpreting-group-effects-in-the-presence-of-a-continuous-predictor" class="section level3" number="5.6.4">
<h3><span class="header-section-number">5.6.4</span> Interpreting group effects in the presence of a continuous predictor</h3>
<p>The inclusion of a continuous predictor affects the interpretation of the group predictors in a model. When we only had a group predictor in the model, the group effects reflected differences between group means. This meant that if we added our group effect to our intercept, we expected that the result would be the group mean. This is seen in the left plot above. The black line represents the intercept, and the ‘effect’ for each group is the distance between the line for the group and the intercept. Obviously, if you take the intercept and add the distance to the male group (red line), the resulting line will be located at the mean for males.</p>
<p>However, the inclusion of continuous predictors means that the group effects can no longer be interpreted in this way. When you include a continuous predictor, the group effects <em>still</em> represent differences in the line intercepts for each group. However, since lines may have non-zero slopes, the intercepts of these lines may no longer correspond to their respective group means.</p>
<p>Here’s a more direct way to think about it: when lines share a slope, group effects change the spacing between parallel lines. If you look at the right panel of Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-55">5.5</a> and tilt your head 45 degrees to the right, its clear that the group effects are responsible for spacing out the parallel lines. This is the same thing the group effects are doing in the panel on the left. However, the <em>spacing</em> between the lines is different between the panels due to the inclusion of a slope in one model.</p>
<p>We’re going to compare the estimated group effects provided by the two models presented above (<code>group_intercepts_model</code>, and <code>group_single_slope_model</code>). Below, I use the <code>hypothesis</code> function to calculate the group effects according to each model.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-1" aria-hidden="true" tabindex="-1"></a>group_intercepts_effects <span class="ot">=</span> </span>
<span id="cb123-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hypothesis</span> (group_intercepts_model,</span>
<span id="cb123-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">hypothesis =</span> <span class="fu">c</span>(<span class="st">&quot;group1 = 0&quot;</span>, <span class="co"># group 1 effect</span></span>
<span id="cb123-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-4" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&quot;group2 = 0&quot;</span>, <span class="co"># group 2 effect</span></span>
<span id="cb123-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-5" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&quot;group3 = 0&quot;</span>, <span class="co"># group 3 effect</span></span>
<span id="cb123-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-6" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&quot;-(group1+group2+group3) = 0&quot;</span>)) <span class="co"># group 4 effect   </span></span>
<span id="cb123-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-7" aria-hidden="true" tabindex="-1"></a>group_intercepts_effects[[<span class="dv">1</span>]][,<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb123-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-8" aria-hidden="true" tabindex="-1"></a><span class="do">##    Estimate Est.Error   CI.Lower  CI.Upper</span></span>
<span id="cb123-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-9" aria-hidden="true" tabindex="-1"></a><span class="do">## 1  30.08481  2.896208  24.310787  35.74068</span></span>
<span id="cb123-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-10" aria-hidden="true" tabindex="-1"></a><span class="do">## 2  32.79653  3.260648  26.583129  39.21910</span></span>
<span id="cb123-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-11" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 -75.75030  2.444318 -80.537948 -70.93498</span></span>
<span id="cb123-12"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb123-12" aria-hidden="true" tabindex="-1"></a><span class="do">## 4  12.86896  2.358541   8.181246  17.45949</span></span></code></pre></div>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-2" aria-hidden="true" tabindex="-1"></a>group_single_slope_effects <span class="ot">=</span> </span>
<span id="cb124-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hypothesis</span> (group_single_slope_model,</span>
<span id="cb124-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">hypothesis =</span> <span class="fu">c</span>(<span class="st">&quot;group1 = 0&quot;</span>, <span class="co"># group 1 effect</span></span>
<span id="cb124-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-5" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&quot;group2 = 0&quot;</span>, <span class="co"># group 2 effect </span></span>
<span id="cb124-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-6" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&quot;group3 = 0&quot;</span>, <span class="co"># group 3 effect</span></span>
<span id="cb124-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-7" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&quot;-(group1+group2+group3) = 0&quot;</span>) <span class="co"># group 4 effect</span></span>
<span id="cb124-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-8" aria-hidden="true" tabindex="-1"></a>)   </span>
<span id="cb124-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-9" aria-hidden="true" tabindex="-1"></a>group_single_slope_effects[[<span class="dv">1</span>]][,<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb124-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-10" aria-hidden="true" tabindex="-1"></a><span class="do">##     Estimate Est.Error    CI.Lower  CI.Upper</span></span>
<span id="cb124-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-11" aria-hidden="true" tabindex="-1"></a><span class="do">## 1   7.308789  3.820567  -0.3534032  14.64993</span></span>
<span id="cb124-12"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-12" aria-hidden="true" tabindex="-1"></a><span class="do">## 2   4.204133  4.578811  -4.7655678  13.13831</span></span>
<span id="cb124-13"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-13" aria-hidden="true" tabindex="-1"></a><span class="do">## 3 -35.551710  5.396041 -46.0762439 -24.96786</span></span>
<span id="cb124-14"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb124-14" aria-hidden="true" tabindex="-1"></a><span class="do">## 4  24.038789  2.546818  19.0232649  29.19051</span></span></code></pre></div>
<p>We can use the <code>brmplot</code> function to visually inspect the differences between the group effects across the models. We see that the groups effects are much smaller when the continuous predictor is included. This is visually apparent in the tighter clustering of the lines in the right panel of Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-int-comparison">5.6</a>. By the way, since the group effects change the spacing of the lines for each group, in the absence of group effects we would just see four overlapping lines.</p>
<div class="figure"><span id="fig:F5-int-comparison"></span>
<img src="05_files/figure-html/F5-int-comparison-1.png" alt=" (left) Comparison of estimated group effects for the model without (blue) and with (red) the perceived height predictor. (middle) Line intercepts reflect the blue coefficients in the left panel (without perceived height). (right) the red coefficients in the left panel (with perceived height). Lines correspond to boys (yellow), girls (green), men (red), and women (blue)." width="768" />
<p class="caption">
Figure 5.6:  (left) Comparison of estimated group effects for the model without (blue) and with (red) the perceived height predictor. (middle) Line intercepts reflect the blue coefficients in the left panel (without perceived height). (right) the red coefficients in the left panel (with perceived height). Lines correspond to boys (yellow), girls (green), men (red), and women (blue).
</p>
</div>
<p>So how can we <em>interpret</em> the group effects when there is a continuous predictor? The group effects specify the difference in expected values for the dependent variable (<span class="math inline">\(\mu\)</span>, in our case <code>f0</code>) between groups, given <em>any fixed value of the x axis variable</em>, in this case perceived height.</p>
<p>To imagine this, pick any arbitrary location along the x-axis in the right panel of Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-int-comparison">5.6</a>. Then, find the predicted value for f0 for that location by sliding up the y axis until arriving at the black dotted line. The distance along the y axis between the black dotted line (the average line) and the group-specific lines (in different colors) is reflected in the red coefficients in the left panel of Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-int-comparison">5.6</a>.</p>
<p>Ok, but what do the effects <em>mean</em>? The groups effects tell us that <em>given a certain perceived height</em>, f0 is lower than expected when the speaker is an adult male, and higher than expected when the speaker is an adult female. In other words, if you think you are listening to a person who is <span class="math inline">\(x\)</span> inches tall, we predict that you heard an <span class="math inline">\(f0\)</span> of <span class="math inline">\(y\)</span>. However, if the speaker was a man then we predict <span class="math inline">\(y-40\)</span> and if the speaker was a woman we predict <span class="math inline">\(y+20\)</span> (based on the effects for the male and female groups for the slope model in the figure above). Importantly, this effect exists <em>independently</em> of the relationship between f0 and perceived height. This means that the spacing between lines is stable across values of the predictor (which is necessary for parallelism).</p>
<p>Consider the effects for girls and boys, which are near zero. When something has an effect near zero this means the ‘effect’ is similar to the intercept (or some other relevant parameter). In this case, the fact that the group effects for girls and boys are near zero tells us that the intercepts for the lines representing these groups of speakers are about the same as that of the overall intercept.</p>
<p>Keep in mind that the fact that the group effects are zero does not mean that the intercept for that group is zero. Instead it just means that the <em>difference</em> between the overall intercept and the group-specific intercept is zero.</p>
</div>
</div>
<div id="models-with-group-dependent-slopes-and-intercepts" class="section level2" number="5.7">
<h2><span class="header-section-number">5.7</span> Models with group-dependent slopes and intercepts</h2>
<p>The model above is limited because it is constrained to have the same slope across all the groups. If we want to include different slopes for each group, we must consider the <em>conditional</em> effect of perceived height given group. To do this, we need to include the interaction between group and perceived height in our model as in the formula below:</p>
<p><code>f0 ~ group * pheight</code>, or <code>f0 ~ group + pheight + pheight:group</code></p>
<p>The model above says: “model f0 as a function of perceived height, allowing for variation in intercepts and the effect for perceived height between groups”.</p>
<div id="description-of-the-model-6" class="section level3" number="5.7.1">
<h3><span class="header-section-number">5.7.1</span> Description of the model</h3>
<p>The ‘ANOVA-style’ decomposition re-introduced with the previous model becomes more useful now. Below we present the ‘expanded’ version of our prediction equation, in a format similar to that presented above. Note that each term that relates to the slope (<span class="math inline">\(pheight, pheight \colon group\)</span>) is independently multiplied with our predictor (<span class="math inline">\(x_{[i]}\)</span>).</p>
<p><span class="math display" id="eq:512">\[
\mu_{[i]} = Intercept + group_{[\mathrm{group}_{[i]}]} + pheight \times x_{[i]} + pheight \colon group_{[\mathrm{group}_{[i]}]} \times x_{[i]}
\tag{5.10}
\]</span></p>
<p>The above says that our expected value is equal to the intercept (<span class="math inline">\(Intercept\)</span>), the group predictor (<span class="math inline">\(group_{[\mathrm{group}_{[i]}]}\)</span>), the product of perceived height and the slope coefficient (<span class="math inline">\(pheight \times x_{[i]}\)</span>), and the product of perceived height and the interaction of the slope coefficient with group ((<span class="math inline">\(pheight \colon group_{[\mathrm{group}_{[i]}]} \times x_{[i]}\)</span>)).</p>
<p>Below, we can group intercept and slope terms in parenthesis. This formulation makes it clear that we expect intercepts and slopes to actually vary trial to trial (whenever the <code>group</code> predictor does).</p>
<p><span class="math display" id="eq:513">\[\begin{equation}
\begin{split}
\mu_{[i]} = (Intercept + group_{[\mathrm{group}_{[i]}]}) + (pheight + pheight \colon group_{[\mathrm{group}_{[i]}]}) \times x_{[i]}
\end{split}
\tag{5.11}
\end{equation}\]</span></p>
<p>We can take this one step further and break up our prediction equation into two steps. The three equations below say:</p>
<ul>
<li><p>Our expected f0 value varies according to trial-dependent intercept and slope parameters.</p></li>
<li><p>The intercept expected on a given trial is equal to the <span class="math inline">\(Intercept\)</span> (the intercept main effect) and the <span class="math inline">\(group\)</span> predictor (effectively, the <span class="math inline">\(Intercept:group\)</span> interaction).</p></li>
<li><p>The slope expected on a given trial is equal to the <span class="math inline">\(pheight\)</span> predictor (effectively, the slope ‘main effect’) and the <span class="math inline">\(pheight:group\)</span> interaction.</p></li>
</ul>
<p><span class="math display" id="eq:514">\[\begin{equation}
\begin{split}
\mu_{[i]} = a_{[i]} + b_{[i]} \times x_{[i]}  \\\\
a_{[i]} = Intercept + group_{[\mathrm{group}_{[i]}]} \\\\
b_{[i]} = pheight + height \colon group_{[\mathrm{group}_{[i]}]}) 
\end{split}
\tag{5.12}
\end{equation}\]</span></p>
<p>As our models get more and more complicated, it can help to organize them in this manner. By considering all of our predictors as either ‘main effects’ or ‘interaction’ terms for different predictor variables in our data, we can organize the consideration of how different predictors are expected to relate to outcomes. For example, the representation above makes it clear that the <span class="math inline">\(height \colon group\)</span> predictor can affect the slopes of our lines, but has no mechanism by which to affect our line intercepts.</p>
<p>We can represent our models in either of the following manners. This representation puts all our predictors directly in the prediction equation:</p>
<p><span class="math display" id="eq:515">\[\begin{equation}
\begin{split}
\textrm{Likelihood:} \\
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = Intercept + group_{[\mathrm{group}_{[i]}]} + pheight \times x_{[i]} + pheight \colon group \times x_{[i]}  \\ \\
\textrm{Priors:} \\
Intercept \sim t(3, 175, 100) \\
pheight \sim t(3, 0, 100) \\ 
group \sim t(3, 0, 100) \\ 
pheight \colon group \sim t(3, 0, 100) \\ 
\end{split}
\tag{5.13}
\end{equation}\]</span></p>
<p>While this representation reflects the decomposition of line intercepts and slopes into several component parts, but is otherwise an identical model:</p>
<p><span class="math display" id="eq:516">\[\begin{equation}
\begin{split}
\textrm{Likelihood:} \\
y_{[i]} \sim \mathcal{N}(\mu_{[i]},\sigma_{error}) \\
\mu_{[i]} = a_{[i]} + b_{[i]} \times x_{[i]}  \\ 
a_{[i]} = Intercept + group_{[\mathrm{group}_{[i]}]} \\
b_{[i]} = pheight + height \colon group_{[\mathrm{group}_{[i]}]} \\ \\
\textrm{Priors:} \\
Intercept \sim t(3, 175, 100) \\
pheight \sim t(3, 0, 100) \\ 
group \sim t(3, 0, 100) \\ 
pheight \colon group \sim t(3, 0, 100) \\ 
\end{split}
\tag{5.14}
\end{equation}\]</span></p>
</div>
<div id="fitting-the-model-5" class="section level3" number="5.7.2">
<h3><span class="header-section-number">5.7.2</span> Fitting the model</h3>
<p>We fit the model with group-dependent intercepts and slopes below:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself, or</span></span>
<span id="cb125-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="co"># download pre-fit model from: </span></span>
<span id="cb125-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="co"># github.com/santiagobarreda/stats-class/tree/master/models</span></span>
<span id="cb125-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-4" aria-hidden="true" tabindex="-1"></a><span class="co"># and load after placing in working directory</span></span>
<span id="cb125-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-5" aria-hidden="true" tabindex="-1"></a><span class="co"># single_line_model = readRDS (&#39;5_group_multi_slope_model.RDS&#39;)</span></span>
<span id="cb125-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb125-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-8" aria-hidden="true" tabindex="-1"></a>group_multi_slope_model <span class="ot">=</span></span>
<span id="cb125-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   f0 ~ group * pheight_c</span></span>
<span id="cb125-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> group <span class="sc">+</span> pheight_c <span class="sc">+</span> pheight_c<span class="sc">:</span>group, </span>
<span id="cb125-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">data=</span>h95, <span class="at">chains=</span><span class="dv">1</span>,<span class="at">cores=</span><span class="dv">1</span>,<span class="at">warmup=</span><span class="dv">1000</span>,<span class="at">iter=</span><span class="dv">6000</span>,</span>
<span id="cb125-12"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 175, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb125-13"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-13" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb125-14"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-14" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 100)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma&quot;</span>)))</span>
<span id="cb125-15"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-15" aria-hidden="true" tabindex="-1"></a><span class="co"># save model</span></span>
<span id="cb125-16"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb125-16" aria-hidden="true" tabindex="-1"></a><span class="co"># saveRDS (group_multi_slope_model, &#39;5_group_multi_slope_model.RDS&#39;)</span></span></code></pre></div>
</div>
<div id="interpreting-the-model-3" class="section level3" number="5.7.3">
<h3><span class="header-section-number">5.7.3</span> Interpreting the model</h3>
<p>We can inspect this model below and see that it contains a relatively large number of parameters. This is a necessary outcome of the complexity of our research question. The model we fit looks for an effect for perceived height on f0, and allows the line relating these variables to vary between groups. Necessarily, this will require the model to present you with 4 intercepts and 4 slopes (or equivalent information), one for each of four group lines. In fact, if we look below we see that our model has in fact estimated 8 fixed-effect coefficients: 4 slopes and 4 intercepts.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="co"># inspect fixed effects</span></span>
<span id="cb126-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb126-2" aria-hidden="true" tabindex="-1"></a>brms<span class="sc">::</span><span class="fu">fixef</span> (group_multi_slope_model)</span>
<span id="cb126-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb126-3" aria-hidden="true" tabindex="-1"></a><span class="do">##                    Estimate Est.Error        Q2.5       Q97.5</span></span>
<span id="cb126-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb126-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept        204.371640 4.3888322 195.7008343 213.0166893</span></span>
<span id="cb126-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb126-5" aria-hidden="true" tabindex="-1"></a><span class="do">## group1           -20.316517 7.9174154 -35.5379249  -4.9370418</span></span>
<span id="cb126-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb126-6" aria-hidden="true" tabindex="-1"></a><span class="do">## group2            17.311087 8.6955692   0.1498904  33.9660860</span></span>
<span id="cb126-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb126-7" aria-hidden="true" tabindex="-1"></a><span class="do">## group3           -14.990302 7.4367971 -29.3698773  -0.1998599</span></span>
<span id="cb126-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb126-8" aria-hidden="true" tabindex="-1"></a><span class="do">## pheight_c         -5.000915 0.5385537  -6.0671119  -3.9634977</span></span>
<span id="cb126-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb126-9" aria-hidden="true" tabindex="-1"></a><span class="do">## group1:pheight_c  -2.325756 1.0560357  -4.3494531  -0.2545608</span></span>
<span id="cb126-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb126-10" aria-hidden="true" tabindex="-1"></a><span class="do">## group2:pheight_c   2.840999 0.9771257   0.9543872   4.7543455</span></span>
<span id="cb126-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb126-11" aria-hidden="true" tabindex="-1"></a><span class="do">## group3:pheight_c  -2.728649 0.9960918  -4.7067134  -0.7419729</span></span></code></pre></div>
<p>We can recover the overall (main effects) intercept and slope directly from the model estimates. We can get the group-specific intercept and slopes by adding the ‘main effects’ and specific interactions.</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-1" aria-hidden="true" tabindex="-1"></a>group_multi_slope_hypothesis <span class="ot">=</span> </span>
<span id="cb127-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hypothesis</span> (group_multi_slope_model,</span>
<span id="cb127-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">hypothesis =</span> </span>
<span id="cb127-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-4" aria-hidden="true" tabindex="-1"></a>                <span class="fu">c</span>(<span class="st">&quot;Intercept = 0&quot;</span>, <span class="co"># overall intercept</span></span>
<span id="cb127-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-5" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Intercept + group1 = 0&quot;</span>, <span class="co"># group 1 mean</span></span>
<span id="cb127-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-6" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Intercept + group2 = 0&quot;</span>, <span class="co"># group 2 mean</span></span>
<span id="cb127-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-7" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Intercept + group3 = 0&quot;</span>, <span class="co"># group 3 mean</span></span>
<span id="cb127-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-8" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Intercept + -(group1+group2+group3) = 0&quot;</span>, <span class="co"># group 4 mean</span></span>
<span id="cb127-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-9" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;pheight_c = 0&quot;</span>, <span class="co"># overall slope</span></span>
<span id="cb127-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-10" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;pheight_c + group1:pheight_c = 0&quot;</span>, <span class="co"># group 1 slope</span></span>
<span id="cb127-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-11" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;pheight_c + group2:pheight_c = 0&quot;</span>, <span class="co"># group 2 slope</span></span>
<span id="cb127-12"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-12" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;pheight_c + group3:pheight_c = 0&quot;</span>, <span class="co"># group 3 slope</span></span>
<span id="cb127-13"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-13" aria-hidden="true" tabindex="-1"></a>                  <span class="co"># group 4 slope</span></span>
<span id="cb127-14"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-14" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;pheight_c +   </span></span>
<span id="cb127-15"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb127-15" aria-hidden="true" tabindex="-1"></a><span class="st">                  -(group1:pheight_c+group2:pheight_c+group3:pheight_c) = 0&quot;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-1" aria-hidden="true" tabindex="-1"></a>group_multi_slope_hypothesis[[<span class="dv">1</span>]][,<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb128-2"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="do">##      Estimate  Est.Error   CI.Lower     CI.Upper</span></span>
<span id="cb128-3"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-3" aria-hidden="true" tabindex="-1"></a><span class="do">## 1  204.371640  4.3888322 195.700834 213.01668927</span></span>
<span id="cb128-4"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 2  184.055122  9.6549946 165.203107 203.07234380</span></span>
<span id="cb128-5"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 3  221.682726 10.7287066 201.014970 242.32745786</span></span>
<span id="cb128-6"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 4  189.381338  8.8824783 171.980463 207.12968030</span></span>
<span id="cb128-7"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 5  222.367372  2.2426056 218.070029 226.80771577</span></span>
<span id="cb128-8"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-8" aria-hidden="true" tabindex="-1"></a><span class="do">## 6   -5.000915  0.5385537  -6.067112  -3.96349773</span></span>
<span id="cb128-9"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-9" aria-hidden="true" tabindex="-1"></a><span class="do">## 7   -7.326671  1.2577261  -9.761930  -4.84173802</span></span>
<span id="cb128-10"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-10" aria-hidden="true" tabindex="-1"></a><span class="do">## 8   -2.159917  1.1561613  -4.406119   0.04965291</span></span>
<span id="cb128-11"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-11" aria-hidden="true" tabindex="-1"></a><span class="do">## 9   -7.729564  1.1622074 -10.011286  -5.43739953</span></span>
<span id="cb128-12"><a href="continuous-predictors-and-their-interactions-with-factors.html#cb128-12" aria-hidden="true" tabindex="-1"></a><span class="do">## 10  -2.787509  0.6934192  -4.168745  -1.40028689</span></span></code></pre></div>
<p>The first four values above are intercepts, and the next four are slopes. These coefficients are presented in Figure <a href="continuous-predictors-and-their-interactions-with-factors.html#fig:F5-57">5.7</a>. There appear to be gender-specific patterns in the intercept and slope coefficients between our groups. This pattern is evident when we use the line coefficients to draw each group-dependent line in the panel on the right.</p>
<div class="figure"><span id="fig:F5-57"></span>
<img src="05_files/figure-html/F5-57-1.png" alt="(left) Group-specific intercepts. (middle) Group-specific slopes. (right) Lines for each group: boys (yellow), girls (green), men (red), and women (blue)." width="768" />
<p class="caption">
Figure 5.7: (left) Group-specific intercepts. (middle) Group-specific slopes. (right) Lines for each group: boys (yellow), girls (green), men (red), and women (blue).
</p>
</div>
<p>Below, we can see the incremental complexity of the models we have considered and how this complexity requires that our models have more and more coefficients. However, in this case the complexity is justified and reveals group-specific relationships between f0 and perceived height in our data.</p>
<div class="figure"><span id="fig:F5-group-slopes"></span>
<img src="05_files/figure-html/F5-group-slopes-1.png" alt="(left) Group-specific intercepts, slope is zero. (middle) Group-specific intercepts, slope is non-zero but fixed across groups. (right) Group-specific intercepts and group-specific slopes. In each panel, lines correspond to boys (yellow), girls (green), men (red), and women (blue)." width="768" />
<p class="caption">
Figure 5.8: (left) Group-specific intercepts, slope is zero. (middle) Group-specific intercepts, slope is non-zero but fixed across groups. (right) Group-specific intercepts and group-specific slopes. In each panel, lines correspond to boys (yellow), girls (green), men (red), and women (blue).
</p>
</div>
</div>
</div>
<div id="exercises-4" class="section level2" number="5.8">
<h2><span class="header-section-number">5.8</span> Exercises</h2>
<p>h95<span class="math inline">\(f0_c = h95\)</span>f0 - mean(h95<span class="math inline">\(f0) h95\)</span>adult = c(“adult”,“child”)[(h95<span class="math inline">\(group == &quot;b&quot; | h95\)</span>group == “g”)+1]
h95<span class="math inline">\(gender = c(&quot;female&quot;,&quot;male&quot;)[(h95\)</span>group == “b” | h95$group == “m”)+1]</p>
<p>set.seed (1)
height_perception_model =
brm (pheight ~ adult * gender * f0_c,
data=h95, chains=1,cores=1,warmup=1000,iter=6000,
prior = c(set_prior(“student_t(3, 60, 24)”, class = “Intercept”),
set_prior(“student_t(3, 0, 0.25)”, class = “b”),
set_prior(“student_t(3, 0, 24)”, class = “sigma”)))
# save model
# saveRDS (height_perception_model, ‘5_height_perception_model.RDS’)</p>
<p>plot (pheight ~ f0, data=h95, xlim=c(80,330), ylim=c(45,75),
ylab = “f0 (Hz)”, pch=16,col=cols[c(4,5,3,6)][factor(h95$group)],
xlab=“Perceived Height (inches)”)</p>

</div>
</div>
<!-- Default Statcounter code for statsbook
https://santiagobarreda.github.io/stats-class/ -->
<script type="text/javascript">
var sc_project=12454226; 
var sc_invisible=1; 
var sc_security="a1959418"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12454226/0/a1959418/1/"
alt="Web Analytics"></a></div></noscript>
<!-- End of Statcounter Code -->
            </section>

          </div>
        </div>
      </div>
<a href="comparing-many-groups-anova-and-interactions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="random-slopes-and-multiple-random-effects.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
